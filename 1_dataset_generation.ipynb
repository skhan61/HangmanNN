{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a62bd7e6",
   "metadata": {
    "papermill": {
     "duration": 0.002135,
     "end_time": "2023-11-24T22:23:42.367043",
     "exception": false,
     "start_time": "2023-11-24T22:23:42.364908",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "323a72c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T22:23:42.378753Z",
     "iopub.status.busy": "2023-11-24T22:23:42.378580Z",
     "iopub.status.idle": "2023-11-24T22:23:43.346735Z",
     "shell.execute_reply": "2023-11-24T22:23:43.346282Z"
    },
    "papermill": {
     "duration": 0.971674,
     "end_time": "2023-11-24T22:23:43.347691",
     "exception": false,
     "start_time": "2023-11-24T22:23:42.376017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from scr.dataset import *\n",
    "# from scr.game import *\n",
    "from scr.feature_engineering import *\n",
    "# from scr.plot_utils import *\n",
    "import gc\n",
    "from scr.utils import print_scenarios\n",
    "\n",
    "from pathlib import Path\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from scr.utils import read_words, save_words_to_file\n",
    "\n",
    "import sys\n",
    "# Custom library paths\n",
    "sys.path.extend(['../', './scr'])\n",
    "\n",
    "from scr.utils import set_seed\n",
    "from scr.utils import read_words\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Read and Shuffle Word List\n",
    "word_list = read_words('data/words_250000_train.txt') # , limit=10000)\n",
    "# word_list = read_words('data/250k.txt', limit=10000)\n",
    "\n",
    "random.shuffle(word_list)\n",
    "\n",
    "# Calculate Frequencies and Max Word Length\n",
    "word_frequencies = calculate_word_frequencies(word_list)\n",
    "char_frequency = calculate_char_frequencies(word_list)\n",
    "max_word_length = max(len(word) for word in word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e2750e",
   "metadata": {},
   "source": [
    "##### Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca8b7063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories '/media/sayem/510B93E12554BBD1/dataset/2500/train_parquets' and '/media/sayem/510B93E12554BBD1/dataset/2500/valid_parquets' have been recreated.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "NUM_STRATIFIED_SAMPLES = 25_000 # This will be overwritten by Papermill\n",
    "\n",
    "# Define the base directory and the paths for training and validation parquet files\n",
    "base_dataset_dir = Path(\"/media/sayem/510B93E12554BBD1/dataset/\")\n",
    "\n",
    "stratified_samples_dir = base_dataset_dir / str(NUM_STRATIFIED_SAMPLES)\n",
    "\n",
    "parquet_train_path = stratified_samples_dir / 'train_parquets'\n",
    "parquet_valid_path = stratified_samples_dir / 'valid_parquets'\n",
    "\n",
    "# Function to delete and recreate a directory\n",
    "def recreate_directory(path):\n",
    "    if path.exists():\n",
    "        shutil.rmtree(path)  # Delete the directory and its contents\n",
    "    path.mkdir(parents=True)  # Create the directory\n",
    "\n",
    "# Recreate the train and valid directories\n",
    "recreate_directory(parquet_train_path)\n",
    "recreate_directory(parquet_valid_path)\n",
    "\n",
    "print(f\"Directories '{parquet_train_path}' and '{parquet_valid_path}' have been recreated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8cc199b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T22:23:43.568919Z",
     "iopub.status.busy": "2023-11-24T22:23:43.568821Z",
     "iopub.status.idle": "2023-11-24T22:23:43.571482Z",
     "shell.execute_reply": "2023-11-24T22:23:43.571208Z"
    },
    "papermill": {
     "duration": 0.007294,
     "end_time": "2023-11-24T22:23:43.572518",
     "exception": false,
     "start_time": "2023-11-24T22:23:43.565224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227300"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc97d62d",
   "metadata": {},
   "source": [
    "##### Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef6ad69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing words saved in /media/sayem/510B93E12554BBD1/dataset/2500/testing_words.txt\n"
     ]
    }
   ],
   "source": [
    "# Define the total number of words and the number of test samples\n",
    "from scr.custom_sampler import *\n",
    "NUM_TEST_SAMPLES = 10_000\n",
    "\n",
    "# Assuming 'word_list' contains the 250,000 words\n",
    "# First, separate 10,000 words for the final testing set\n",
    "testing_words = stratified_sample_by_length_and_uniqueness(\n",
    "    word_list, \n",
    "    NUM_TEST_SAMPLES\n",
    ")\n",
    "\n",
    "# Define the file path for saving the testing words\n",
    "testing_words_file_path = stratified_samples_dir / \"testing_words.txt\"\n",
    "\n",
    "# Save the testing words to a file\n",
    "with open(testing_words_file_path, 'w') as file:\n",
    "    for word in testing_words:\n",
    "        file.write(word + '\\n')\n",
    "\n",
    "print(f\"Testing words saved in {testing_words_file_path}\")\n",
    "\n",
    "# Now, remove these testing samples from the original word list\n",
    "remaining_words = [word for word in word_list if word not in testing_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469a87ce",
   "metadata": {},
   "source": [
    "##### Stratified Sample Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41e486f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T22:23:43.579494Z",
     "iopub.status.busy": "2023-11-24T22:23:43.579377Z",
     "iopub.status.idle": "2023-11-24T22:23:43.640436Z",
     "shell.execute_reply": "2023-11-24T22:23:43.640019Z"
    },
    "papermill": {
     "duration": 0.065848,
     "end_time": "2023-11-24T22:23:43.641509",
     "exception": false,
     "start_time": "2023-11-24T22:23:43.575661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Statrified samples: 2500\n",
      "2554\n"
     ]
    }
   ],
   "source": [
    "## we are taking starified samples from train_words\n",
    "\n",
    "from scr.custom_sampler import \\\n",
    "    stratified_sample_by_length_and_frequency, \\\n",
    "        stratified_sample_by_length, stratified_sample_by_length_and_uniqueness\n",
    "\n",
    "print(f'Number of Statrified samples: {NUM_STRATIFIED_SAMPLES}')\n",
    "\n",
    "# sampled_words_by_length_and_frequency \\\n",
    "#     = stratified_sample_by_length_and_frequency(train_words, \\\n",
    "#     word_frequencies, \\\n",
    "#     NUM_STRATIFIED_SAMPLES)\n",
    "\n",
    "sampled_words_by_length = stratified_sample_by_length_and_uniqueness(remaining_words, \\\n",
    "    NUM_STRATIFIED_SAMPLES)\n",
    "\n",
    "print(len(sampled_words_by_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0d326f",
   "metadata": {
    "papermill": {
     "duration": 0.004373,
     "end_time": "2023-11-24T22:23:44.300659",
     "exception": false,
     "start_time": "2023-11-24T22:23:44.296286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Intial State Simulation Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae53fccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.game import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1415477e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'allMasked': '____________',\n",
       " 'early': '__________z_',\n",
       " 'quarterRevealed': 'm_________z_',\n",
       " 'midRevealed': 'm______e_ize',\n",
       " 'midLateRevealed': 'm_th___etize',\n",
       " 'lateRevealed': 'm_thopoetize',\n",
       " 'nearEnd': 'm_thopoetize'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word = \"mississippi\"\n",
    "word = \"mythopoetize\"\n",
    "# word = \"cat\"\n",
    "\n",
    "initial_states = process_word_for_six_states(word)\n",
    "\n",
    "initial_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c3da54c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T22:23:44.317155Z",
     "iopub.status.busy": "2023-11-24T22:23:44.317069Z",
     "iopub.status.idle": "2023-11-24T22:23:44.319452Z",
     "shell.execute_reply": "2023-11-24T22:23:44.319138Z"
    },
    "papermill": {
     "duration": 0.005907,
     "end_time": "2023-11-24T22:23:44.320079",
     "exception": false,
     "start_time": "2023-11-24T22:23:44.314172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(initial_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5cffa5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T22:23:44.326727Z",
     "iopub.status.busy": "2023-11-24T22:23:44.326580Z",
     "iopub.status.idle": "2023-11-24T22:23:44.329649Z",
     "shell.execute_reply": "2023-11-24T22:23:44.329220Z"
    },
    "papermill": {
     "duration": 0.007091,
     "end_time": "2023-11-24T22:23:44.330204",
     "exception": false,
     "start_time": "2023-11-24T22:23:44.323113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'allMasked': '____________',\n",
       " 'early': '__________z_',\n",
       " 'quarterRevealed': 'm_________z_',\n",
       " 'midRevealed': 'm______e_ize',\n",
       " 'midLateRevealed': 'm_th___etize',\n",
       " 'lateRevealed': 'm_thopoetize',\n",
       " 'nearEnd': 'm_thopoetize'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01da2152",
   "metadata": {
    "papermill": {
     "duration": 0.002642,
     "end_time": "2023-11-24T22:23:44.335321",
     "exception": false,
     "start_time": "2023-11-24T22:23:44.332679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Dataset Generation: Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3dfd089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Initial States:  {'allMasked': '___________', 'early': 'm__________', 'quarterRevealed': 'm__________', 'midRevealed': 'm_ss_ss____', 'midLateRevealed': 'm_ss_ss_pp_', 'lateRevealed': 'm_ss_ss_pp_', 'nearEnd': 'm_ss_ss_pp_'}\n"
     ]
    }
   ],
   "source": [
    "word = \"mississippi\"\n",
    "\n",
    "initial_states = process_word_for_six_states(word)\n",
    "\n",
    "# print(initial_states)\n",
    "# Print generated initial states\n",
    "print(\"Generated Initial States: \", initial_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f65e7334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Initial States:\n",
      "___________\n",
      "For initial state: ___________\n",
      "Guessed: 'm', New State: 'm__________', Correct: True\n",
      "Guessed: 's', New State: 'm_ss_ss____', Correct: True\n",
      "Guessed: 'i', New State: 'mississi__i', Correct: True\n",
      "Guessed: 'p', New State: 'mississippi', Correct: True\n",
      "__ss_ss____\n",
      "For initial state: __ss_ss____\n",
      "Guessed: 'q', New State: '__ss_ss____', Correct: False\n",
      "Guessed: 'p', New State: '__ss_ss_pp_', Correct: True\n",
      "Guessed: 'i', New State: '_ississippi', Correct: True\n",
      "Guessed: 'b', New State: '_ississippi', Correct: False\n",
      "Guessed: 'y', New State: '_ississippi', Correct: False\n",
      "Guessed: 't', New State: '_ississippi', Correct: False\n",
      "Guessed: 'm', New State: 'mississippi', Correct: True\n",
      "__ss_ss____\n",
      "For initial state: __ss_ss____\n",
      "Guessed: 'i', New State: '_ississi__i', Correct: True\n",
      "Guessed: 'v', New State: '_ississi__i', Correct: False\n",
      "Guessed: 'b', New State: '_ississi__i', Correct: False\n",
      "Guessed: 't', New State: '_ississi__i', Correct: False\n",
      "Guessed: 'k', New State: '_ississi__i', Correct: False\n",
      "Guessed: 'a', New State: '_ississi__i', Correct: False\n",
      "Guessed: 'p', New State: '_ississippi', Correct: True\n",
      "Guessed: 'd', New State: '_ississippi', Correct: False\n",
      "__ss_ss_pp_\n",
      "For initial state: __ss_ss_pp_\n",
      "Guessed: 'g', New State: '__ss_ss_pp_', Correct: False\n",
      "Guessed: 't', New State: '__ss_ss_pp_', Correct: False\n",
      "Guessed: 'm', New State: 'm_ss_ss_pp_', Correct: True\n",
      "Guessed: 'f', New State: 'm_ss_ss_pp_', Correct: False\n",
      "Guessed: 'y', New State: 'm_ss_ss_pp_', Correct: False\n",
      "Guessed: 'i', New State: 'mississippi', Correct: True\n",
      "_ississippi\n",
      "For initial state: _ississippi\n",
      "Guessed: 'm', New State: 'mississippi', Correct: True\n",
      "_ississippi\n",
      "For initial state: _ississippi\n",
      "Guessed: 'm', New State: 'mississippi', Correct: True\n",
      "_ississippi\n",
      "For initial state: _ississippi\n",
      "Guessed: 'm', New State: 'mississippi', Correct: True\n"
     ]
    }
   ],
   "source": [
    "from scr.game import simulate_game_progress, \\\n",
    "    play_game_with_a_word, process_word\n",
    "\n",
    "# Example word and initial state\n",
    "# Example usage\n",
    "word = \"mississippi\"\n",
    "# word = \"cat\"\n",
    "\n",
    "initial_states = process_word_for_six_states(word)\n",
    "\n",
    "# print(initial_states)\n",
    "# Print generated initial states\n",
    "print(\"Generated Initial States:\")\n",
    "for state_name, initial_state in initial_states.items():\n",
    "    # Simulate the game\n",
    "    print(initial_state)\n",
    "    print(f\"For initial state: {initial_state}\")\n",
    "    won, game_progress = simulate_game_progress(\n",
    "        model=None,  # Assuming model is not used in this example\n",
    "        word=word, \n",
    "        initial_state=initial_state, \n",
    "        char_frequency={},  # Assuming char_frequency is not used in this example\n",
    "        max_word_length=len(word), \n",
    "        device=None,  # Assuming device is not used in this example\n",
    "        max_attempts=6, \n",
    "        normalize=True,\n",
    "        difficulty=\"medium\", \n",
    "        outcome_preference='win'\n",
    "    )\n",
    "\n",
    "    # Display game progress\n",
    "    for step in game_progress:\n",
    "        print(f\"Guessed: '{step[0]}', New State: '{step[1]}', Correct: {step[2]}\")\n",
    "\n",
    "        # break\n",
    "\n",
    "    # break\n",
    "\n",
    "    # print(\"Game Result:\", \"Won\" if won else \"Lost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8955b2cc",
   "metadata": {},
   "source": [
    "##### Writing Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe2eb7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Words: 100%|██████████| 2043/2043 [00:06<00:00, 292.80it/s]\n",
      "Processing Words: 100%|██████████| 511/511 [00:01<00:00, 311.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Total games processed in training set: 85806\n",
      "Final Total games processed in validation set: 21462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming the function 'process_word_for_six_states' is defined elsewhere\n",
    "from scr.game import simulate_game_progress, process_word_for_six_states\n",
    "\n",
    "def process_batch_to_parquet(batch, file_path, start_game_counter):\n",
    "    game_counter = start_game_counter\n",
    "    data_for_parquet = []\n",
    "\n",
    "    for game_data in batch:\n",
    "        word, state_name, initial_state, difficulty, outcome, won, game_progress = game_data\n",
    "        if not game_progress:\n",
    "            continue\n",
    "\n",
    "        final_state = game_progress[-1][1]\n",
    "        guessed_states = [initial_state] + [state for _, state, _ in game_progress]\n",
    "        guessed_letters = [letter for letter, _, _ in game_progress]\n",
    "\n",
    "        data_for_parquet.append({\n",
    "            'game_id': game_counter,\n",
    "            'word': word,\n",
    "            'initial_state': initial_state,\n",
    "            'final_state': final_state,\n",
    "            'guessed_states': ','.join(guessed_states[:-1]),\n",
    "            'guessed_letters': ','.join(guessed_letters),\n",
    "            'game_state': state_name,\n",
    "            'difficulty': difficulty,\n",
    "            'outcome': outcome,\n",
    "            'word_length': len(word),\n",
    "            'won': won\n",
    "        })\n",
    "\n",
    "        game_counter += 1\n",
    "\n",
    "    df = pd.DataFrame(data_for_parquet)\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    pq.write_to_dataset(table, root_path=file_path, compression='snappy')\n",
    "\n",
    "    return game_counter\n",
    "\n",
    "def generate_batch_for_word(word):\n",
    "    batch = []\n",
    "    initial_states = process_word_for_six_states(word)\n",
    "    games_generated = 0  # Counter for games generated\n",
    "\n",
    "    for state_name, initial_state in initial_states.items():\n",
    "        for difficulty in [\"easy\", \"medium\", \"hard\"]:\n",
    "            for outcome in [\"win\", \"lose\"]:\n",
    "                won, game_progress = simulate_game_progress(\n",
    "                    model=None, word=word, initial_state=initial_state,\n",
    "                    char_frequency={}, max_word_length=len(word),\n",
    "                    device=None, max_attempts=6, normalize=True,\n",
    "                    difficulty=difficulty, outcome_preference=outcome\n",
    "                )\n",
    "                batch.append((word, state_name, initial_state, difficulty, outcome, won, game_progress))\n",
    "                games_generated += 1  # Increment game counter\n",
    "\n",
    "    return batch, games_generated\n",
    "\n",
    "\n",
    "def main_execution(words, parquet_train_path, parquet_valid_path, test_size=0.20):\n",
    "    train_game_counter = 0\n",
    "    valid_game_counter = 0\n",
    "    games_per_word = 6 * 3 * 2  # 6 states, 3 difficulties, 2 outcomes\n",
    "\n",
    "    train_words, valid_words = train_test_split(words, test_size=test_size)\n",
    "\n",
    "    # Process each word set\n",
    "    for word_set, path in [(train_words, parquet_train_path), (valid_words, parquet_valid_path)]:\n",
    "        total_words_processed = 0\n",
    "        total_games_generated = 0\n",
    "\n",
    "        for word in tqdm(word_set, desc=\"Processing Words\"):\n",
    "            batch, games_generated = generate_batch_for_word(word)\n",
    "\n",
    "            # Update word count and game count\n",
    "            total_words_processed += 1\n",
    "            total_games_generated += games_generated\n",
    "\n",
    "            # Update game counters\n",
    "            if word_set is train_words:\n",
    "                train_game_counter += games_generated\n",
    "                process_batch_to_parquet(batch, path, train_game_counter)\n",
    "            else:\n",
    "                valid_game_counter += games_generated\n",
    "                process_batch_to_parquet(batch, path, valid_game_counter)\n",
    "\n",
    "    print(f\"Final Total games processed in training set: {train_game_counter}\")\n",
    "    print(f\"Final Total games processed in validation set: {valid_game_counter}\")\n",
    "\n",
    "# Execute the main function\n",
    "main_execution(sampled_words_by_length, parquet_train_path, parquet_valid_path, test_size=0.20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a7795d",
   "metadata": {},
   "source": [
    "##### Checking Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "318f8ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parquet files: 2043\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Assuming parquet_train_path is already defined as a Path object\n",
    "# If not, define it here\n",
    "# parquet_train_path = Path('path_to_your_train_parquet_directory')\n",
    "\n",
    "# Use glob to find all Parquet files in the folder\n",
    "parquet_files = parquet_train_path.glob('*.parquet')\n",
    "\n",
    "# Count the number of files\n",
    "file_count = sum(1 for _ in parquet_files)\n",
    "\n",
    "print(f\"Number of Parquet files: {file_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb677b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of game sequences across all files: 85782\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Find all Parquet files in the directory\n",
    "parquet_files = list(parquet_train_path.glob('*.parquet'))\n",
    "\n",
    "if parquet_files:\n",
    "    total_game_sequences = 0\n",
    "\n",
    "    # Iterate over each file and sum the number of game sequences\n",
    "    for file in parquet_files:\n",
    "        df = pd.read_parquet(file)\n",
    "        total_game_sequences += len(df)\n",
    "\n",
    "    print(f\"Total number of game sequences across all files: {total_game_sequences}\")\n",
    "else:\n",
    "    print(\"No Parquet files found in the specified directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14ae9653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of games in the dataset: 85782\n",
      "Null values in each column:\n",
      "game_id            0\n",
      "word               0\n",
      "initial_state      0\n",
      "final_state        0\n",
      "guessed_states     0\n",
      "guessed_letters    0\n",
      "game_state         0\n",
      "difficulty         0\n",
      "outcome            0\n",
      "word_length        0\n",
      "won                0\n",
      "dtype: int64\n",
      "\n",
      "Summary statistics:\n",
      "            game_id   word_length\n",
      "count  85782.000000  85782.000000\n",
      "mean   42946.299538      9.549206\n",
      "std    24770.523971      3.281541\n",
      "min       42.000000      2.000000\n",
      "25%    21499.250000      7.000000\n",
      "50%    42944.500000      9.000000\n",
      "75%    64401.750000     11.000000\n",
      "max    85847.000000     25.000000\n",
      "\n",
      "Number of unique words: 2043\n",
      "\n",
      "Outcome distribution:\n",
      "outcome\n",
      "win     42891\n",
      "lose    42891\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Difficulty distribution:\n",
      "difficulty\n",
      "easy      28594\n",
      "medium    28594\n",
      "hard      28594\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Use glob to find all Parquet files in the folder\n",
    "parquet_files = parquet_train_path.glob('*.parquet')\n",
    "\n",
    "# Read and concatenate all Parquet files into a single DataFrame\n",
    "df = pd.concat([pd.read_parquet(file) for file in parquet_files], ignore_index=True)\n",
    "\n",
    "# # Display the first few rows of the DataFrame\n",
    "# print(df.head())\n",
    "\n",
    "# Get the total number of rows (games) in the DataFrame\n",
    "total_games = len(df)\n",
    "print(f\"Total number of games in the dataset: {total_games}\")\n",
    "\n",
    "# Additional checks and summary statistics\n",
    "print(\"Null values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Count the number of unique words or game states\n",
    "unique_words = df['word'].nunique()\n",
    "print(f\"\\nNumber of unique words: {unique_words}\")\n",
    "\n",
    "# Inspect the distribution of game outcomes, difficulties, etc.\n",
    "print(\"\\nOutcome distribution:\")\n",
    "print(df['outcome'].value_counts())\n",
    "\n",
    "print(\"\\nDifficulty distribution:\")\n",
    "print(df['difficulty'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d1359cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>word</th>\n",
       "      <th>initial_state</th>\n",
       "      <th>final_state</th>\n",
       "      <th>guessed_states</th>\n",
       "      <th>guessed_letters</th>\n",
       "      <th>game_state</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>outcome</th>\n",
       "      <th>word_length</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25116</td>\n",
       "      <td>amiability</td>\n",
       "      <td>__________</td>\n",
       "      <td>amiability</td>\n",
       "      <td>__________,______l___,____b_l___,a__ab_l___,a_...</td>\n",
       "      <td>l,b,a,i,x,y,m,d,s,t</td>\n",
       "      <td>allMasked</td>\n",
       "      <td>easy</td>\n",
       "      <td>win</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25117</td>\n",
       "      <td>amiability</td>\n",
       "      <td>__________</td>\n",
       "      <td>amiability</td>\n",
       "      <td>__________,_m________,_mi__i_i__,_mi_bi_i__,am...</td>\n",
       "      <td>m,i,b,a,l,t,y</td>\n",
       "      <td>allMasked</td>\n",
       "      <td>easy</td>\n",
       "      <td>lose</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25118</td>\n",
       "      <td>amiability</td>\n",
       "      <td>__________</td>\n",
       "      <td>__i__i_i__</td>\n",
       "      <td>__________,__________,__i__i_i__,__i__i_i__,__...</td>\n",
       "      <td>u,i,z,n,g,e,q</td>\n",
       "      <td>allMasked</td>\n",
       "      <td>medium</td>\n",
       "      <td>win</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25119</td>\n",
       "      <td>amiability</td>\n",
       "      <td>__________</td>\n",
       "      <td>a__a_____y</td>\n",
       "      <td>__________,__________,__________,__________,__...</td>\n",
       "      <td>p,f,k,s,y,a,v,d</td>\n",
       "      <td>allMasked</td>\n",
       "      <td>medium</td>\n",
       "      <td>lose</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25120</td>\n",
       "      <td>amiability</td>\n",
       "      <td>__________</td>\n",
       "      <td>__________</td>\n",
       "      <td>__________,__________,__________,__________,__...</td>\n",
       "      <td>j,n,s,c,q,z</td>\n",
       "      <td>allMasked</td>\n",
       "      <td>hard</td>\n",
       "      <td>win</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85777</th>\n",
       "      <td>4279</td>\n",
       "      <td>cheapjohn</td>\n",
       "      <td>_heapjohn</td>\n",
       "      <td>cheapjohn</td>\n",
       "      <td>_heapjohn</td>\n",
       "      <td>c</td>\n",
       "      <td>nearEnd</td>\n",
       "      <td>easy</td>\n",
       "      <td>lose</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85778</th>\n",
       "      <td>4280</td>\n",
       "      <td>cheapjohn</td>\n",
       "      <td>_heapjohn</td>\n",
       "      <td>cheapjohn</td>\n",
       "      <td>_heapjohn</td>\n",
       "      <td>c</td>\n",
       "      <td>nearEnd</td>\n",
       "      <td>medium</td>\n",
       "      <td>win</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85779</th>\n",
       "      <td>4281</td>\n",
       "      <td>cheapjohn</td>\n",
       "      <td>_heapjohn</td>\n",
       "      <td>cheapjohn</td>\n",
       "      <td>_heapjohn,_heapjohn,_heapjohn,_heapjohn,_heapj...</td>\n",
       "      <td>q,f,k,b,d,c</td>\n",
       "      <td>nearEnd</td>\n",
       "      <td>medium</td>\n",
       "      <td>lose</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85780</th>\n",
       "      <td>4282</td>\n",
       "      <td>cheapjohn</td>\n",
       "      <td>_heapjohn</td>\n",
       "      <td>cheapjohn</td>\n",
       "      <td>_heapjohn,_heapjohn,_heapjohn</td>\n",
       "      <td>k,l,c</td>\n",
       "      <td>nearEnd</td>\n",
       "      <td>hard</td>\n",
       "      <td>win</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85781</th>\n",
       "      <td>4283</td>\n",
       "      <td>cheapjohn</td>\n",
       "      <td>_heapjohn</td>\n",
       "      <td>cheapjohn</td>\n",
       "      <td>_heapjohn,_heapjohn,_heapjohn,_heapjohn,_heapj...</td>\n",
       "      <td>q,b,u,r,x,c</td>\n",
       "      <td>nearEnd</td>\n",
       "      <td>hard</td>\n",
       "      <td>lose</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85782 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       game_id        word initial_state final_state  \\\n",
       "0        25116  amiability    __________  amiability   \n",
       "1        25117  amiability    __________  amiability   \n",
       "2        25118  amiability    __________  __i__i_i__   \n",
       "3        25119  amiability    __________  a__a_____y   \n",
       "4        25120  amiability    __________  __________   \n",
       "...        ...         ...           ...         ...   \n",
       "85777     4279   cheapjohn     _heapjohn   cheapjohn   \n",
       "85778     4280   cheapjohn     _heapjohn   cheapjohn   \n",
       "85779     4281   cheapjohn     _heapjohn   cheapjohn   \n",
       "85780     4282   cheapjohn     _heapjohn   cheapjohn   \n",
       "85781     4283   cheapjohn     _heapjohn   cheapjohn   \n",
       "\n",
       "                                          guessed_states      guessed_letters  \\\n",
       "0      __________,______l___,____b_l___,a__ab_l___,a_...  l,b,a,i,x,y,m,d,s,t   \n",
       "1      __________,_m________,_mi__i_i__,_mi_bi_i__,am...        m,i,b,a,l,t,y   \n",
       "2      __________,__________,__i__i_i__,__i__i_i__,__...        u,i,z,n,g,e,q   \n",
       "3      __________,__________,__________,__________,__...      p,f,k,s,y,a,v,d   \n",
       "4      __________,__________,__________,__________,__...          j,n,s,c,q,z   \n",
       "...                                                  ...                  ...   \n",
       "85777                                          _heapjohn                    c   \n",
       "85778                                          _heapjohn                    c   \n",
       "85779  _heapjohn,_heapjohn,_heapjohn,_heapjohn,_heapj...          q,f,k,b,d,c   \n",
       "85780                      _heapjohn,_heapjohn,_heapjohn                k,l,c   \n",
       "85781  _heapjohn,_heapjohn,_heapjohn,_heapjohn,_heapj...          q,b,u,r,x,c   \n",
       "\n",
       "      game_state difficulty outcome  word_length    won  \n",
       "0      allMasked       easy     win           10   True  \n",
       "1      allMasked       easy    lose           10   True  \n",
       "2      allMasked     medium     win           10  False  \n",
       "3      allMasked     medium    lose           10  False  \n",
       "4      allMasked       hard     win           10  False  \n",
       "...          ...        ...     ...          ...    ...  \n",
       "85777    nearEnd       easy    lose            9   True  \n",
       "85778    nearEnd     medium     win            9   True  \n",
       "85779    nearEnd     medium    lose            9   True  \n",
       "85780    nearEnd       hard     win            9   True  \n",
       "85781    nearEnd       hard    lose            9   True  \n",
       "\n",
       "[85782 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# # Replace this with the path to your Parquet file\n",
    "# parquet_file_path = 'path/to/your/HangmanData.parquet'\n",
    "\n",
    "# Read the Parquet file\n",
    "df = pd.read_parquet(parquet_train_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3a8c199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of games in the dataset: 85782\n",
      "game_id            0\n",
      "word               0\n",
      "initial_state      0\n",
      "final_state        0\n",
      "guessed_states     0\n",
      "guessed_letters    0\n",
      "game_state         0\n",
      "difficulty         0\n",
      "outcome            0\n",
      "word_length        0\n",
      "won                0\n",
      "dtype: int64\n",
      "            game_id   word_length\n",
      "count  85782.000000  85782.000000\n",
      "mean   42946.299538      9.549206\n",
      "std    24770.523971      3.281541\n",
      "min       42.000000      2.000000\n",
      "25%    21499.250000      7.000000\n",
      "50%    42944.500000      9.000000\n",
      "75%    64401.750000     11.000000\n",
      "max    85847.000000     25.000000\n",
      "Number of unique words: 2043\n",
      "outcome\n",
      "win     42891\n",
      "lose    42891\n",
      "Name: count, dtype: int64\n",
      "difficulty\n",
      "easy      28594\n",
      "medium    28594\n",
      "hard      28594\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get the total number of rows (games) in the DataFrame\n",
    "total_games = len(df)\n",
    "\n",
    "print(f\"Total number of games in the dataset: {total_games}\")\n",
    "\n",
    "# Additional checks you might want to perform:\n",
    "# - Check for any null values or anomalies in the data\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# - Get a summary of the DataFrame\n",
    "print(df.describe())\n",
    "\n",
    "# - Count the number of unique words or game states\n",
    "unique_words = df['word'].nunique()\n",
    "print(f\"Number of unique words: {unique_words}\")\n",
    "\n",
    "# - Inspect the distribution of game outcomes, difficulties, etc.\n",
    "print(df['outcome'].value_counts())\n",
    "print(df['difficulty'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd332aa",
   "metadata": {},
   "source": [
    "##### Checking the Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dfe3329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>word</th>\n",
       "      <th>initial_state</th>\n",
       "      <th>final_state</th>\n",
       "      <th>guessed_states</th>\n",
       "      <th>guessed_letters</th>\n",
       "      <th>game_state</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>outcome</th>\n",
       "      <th>word_length</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5040</td>\n",
       "      <td>encup</td>\n",
       "      <td>_____</td>\n",
       "      <td>encup</td>\n",
       "      <td>_____,__c__,e_c__,e_cu_,encu_</td>\n",
       "      <td>c,e,u,n,p</td>\n",
       "      <td>allMasked</td>\n",
       "      <td>easy</td>\n",
       "      <td>win</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5041</td>\n",
       "      <td>encup</td>\n",
       "      <td>_____</td>\n",
       "      <td>encup</td>\n",
       "      <td>_____,__c__,e_c__,e_c_p,e_cup,e_cup,e_cup</td>\n",
       "      <td>c,e,p,u,y,d,n</td>\n",
       "      <td>allMasked</td>\n",
       "      <td>easy</td>\n",
       "      <td>lose</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5042</td>\n",
       "      <td>encup</td>\n",
       "      <td>_____</td>\n",
       "      <td>encup</td>\n",
       "      <td>_____,_____,___u_,___up,__cup,__cup,e_cup,e_cup</td>\n",
       "      <td>b,u,p,c,q,e,k,n</td>\n",
       "      <td>allMasked</td>\n",
       "      <td>medium</td>\n",
       "      <td>win</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5043</td>\n",
       "      <td>encup</td>\n",
       "      <td>_____</td>\n",
       "      <td>encup</td>\n",
       "      <td>_____,_n___,_n__p,_n__p,_n__p,en__p,en_up</td>\n",
       "      <td>n,p,b,w,e,u,c</td>\n",
       "      <td>allMasked</td>\n",
       "      <td>medium</td>\n",
       "      <td>lose</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5044</td>\n",
       "      <td>encup</td>\n",
       "      <td>_____</td>\n",
       "      <td>___u_</td>\n",
       "      <td>_____,___u_,___u_,___u_,___u_,___u_,___u_</td>\n",
       "      <td>u,s,l,i,f,w,d</td>\n",
       "      <td>allMasked</td>\n",
       "      <td>hard</td>\n",
       "      <td>win</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21445</th>\n",
       "      <td>14401</td>\n",
       "      <td>unpetticoated</td>\n",
       "      <td>unpettico_ted</td>\n",
       "      <td>unpetticoated</td>\n",
       "      <td>unpettico_ted</td>\n",
       "      <td>a</td>\n",
       "      <td>nearEnd</td>\n",
       "      <td>easy</td>\n",
       "      <td>lose</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21446</th>\n",
       "      <td>14402</td>\n",
       "      <td>unpetticoated</td>\n",
       "      <td>unpettico_ted</td>\n",
       "      <td>unpetticoated</td>\n",
       "      <td>unpettico_ted</td>\n",
       "      <td>a</td>\n",
       "      <td>nearEnd</td>\n",
       "      <td>medium</td>\n",
       "      <td>win</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21447</th>\n",
       "      <td>14403</td>\n",
       "      <td>unpetticoated</td>\n",
       "      <td>unpettico_ted</td>\n",
       "      <td>unpetticoated</td>\n",
       "      <td>unpettico_ted,unpettico_ted,unpettico_ted,unpe...</td>\n",
       "      <td>k,z,s,y,a</td>\n",
       "      <td>nearEnd</td>\n",
       "      <td>medium</td>\n",
       "      <td>lose</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21448</th>\n",
       "      <td>14404</td>\n",
       "      <td>unpetticoated</td>\n",
       "      <td>unpettico_ted</td>\n",
       "      <td>unpetticoated</td>\n",
       "      <td>unpettico_ted,unpettico_ted</td>\n",
       "      <td>v,a</td>\n",
       "      <td>nearEnd</td>\n",
       "      <td>hard</td>\n",
       "      <td>win</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21449</th>\n",
       "      <td>14405</td>\n",
       "      <td>unpetticoated</td>\n",
       "      <td>unpettico_ted</td>\n",
       "      <td>unpetticoated</td>\n",
       "      <td>unpettico_ted</td>\n",
       "      <td>a</td>\n",
       "      <td>nearEnd</td>\n",
       "      <td>hard</td>\n",
       "      <td>lose</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21450 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       game_id           word  initial_state    final_state  \\\n",
       "0         5040          encup          _____          encup   \n",
       "1         5041          encup          _____          encup   \n",
       "2         5042          encup          _____          encup   \n",
       "3         5043          encup          _____          encup   \n",
       "4         5044          encup          _____          ___u_   \n",
       "...        ...            ...            ...            ...   \n",
       "21445    14401  unpetticoated  unpettico_ted  unpetticoated   \n",
       "21446    14402  unpetticoated  unpettico_ted  unpetticoated   \n",
       "21447    14403  unpetticoated  unpettico_ted  unpetticoated   \n",
       "21448    14404  unpetticoated  unpettico_ted  unpetticoated   \n",
       "21449    14405  unpetticoated  unpettico_ted  unpetticoated   \n",
       "\n",
       "                                          guessed_states  guessed_letters  \\\n",
       "0                          _____,__c__,e_c__,e_cu_,encu_        c,e,u,n,p   \n",
       "1              _____,__c__,e_c__,e_c_p,e_cup,e_cup,e_cup    c,e,p,u,y,d,n   \n",
       "2        _____,_____,___u_,___up,__cup,__cup,e_cup,e_cup  b,u,p,c,q,e,k,n   \n",
       "3              _____,_n___,_n__p,_n__p,_n__p,en__p,en_up    n,p,b,w,e,u,c   \n",
       "4              _____,___u_,___u_,___u_,___u_,___u_,___u_    u,s,l,i,f,w,d   \n",
       "...                                                  ...              ...   \n",
       "21445                                      unpettico_ted                a   \n",
       "21446                                      unpettico_ted                a   \n",
       "21447  unpettico_ted,unpettico_ted,unpettico_ted,unpe...        k,z,s,y,a   \n",
       "21448                        unpettico_ted,unpettico_ted              v,a   \n",
       "21449                                      unpettico_ted                a   \n",
       "\n",
       "      game_state difficulty outcome  word_length    won  \n",
       "0      allMasked       easy     win            5   True  \n",
       "1      allMasked       easy    lose            5   True  \n",
       "2      allMasked     medium     win            5   True  \n",
       "3      allMasked     medium    lose            5   True  \n",
       "4      allMasked       hard     win            5  False  \n",
       "...          ...        ...     ...          ...    ...  \n",
       "21445    nearEnd       easy    lose           13   True  \n",
       "21446    nearEnd     medium     win           13   True  \n",
       "21447    nearEnd     medium    lose           13   True  \n",
       "21448    nearEnd       hard     win           13   True  \n",
       "21449    nearEnd       hard    lose           13   True  \n",
       "\n",
       "[21450 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# # Replace this with the path to your Parquet file\n",
    "# parquet_file_path = 'path/to/your/HangmanData.parquet'\n",
    "\n",
    "# Read the Parquet file\n",
    "df = pd.read_parquet(parquet_valid_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08449596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of games in the dataset: 21450\n",
      "game_id            0\n",
      "word               0\n",
      "initial_state      0\n",
      "final_state        0\n",
      "guessed_states     0\n",
      "guessed_letters    0\n",
      "game_state         0\n",
      "difficulty         0\n",
      "outcome            0\n",
      "word_length        0\n",
      "won                0\n",
      "dtype: int64\n",
      "            game_id   word_length\n",
      "count  21450.000000  21450.000000\n",
      "mean   10776.533007      9.372587\n",
      "std     6195.075458      3.168436\n",
      "min       42.000000      1.000000\n",
      "25%     5416.250000      7.000000\n",
      "50%    10778.500000      9.000000\n",
      "75%    16140.750000     11.000000\n",
      "max    21503.000000     29.000000\n",
      "Number of unique words: 511\n",
      "outcome\n",
      "win     10725\n",
      "lose    10725\n",
      "Name: count, dtype: int64\n",
      "difficulty\n",
      "easy      7150\n",
      "medium    7150\n",
      "hard      7150\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get the total number of rows (games) in the DataFrame\n",
    "total_games = len(df)\n",
    "\n",
    "print(f\"Total number of games in the dataset: {total_games}\")\n",
    "\n",
    "# Additional checks you might want to perform:\n",
    "# - Check for any null values or anomalies in the data\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# - Get a summary of the DataFrame\n",
    "print(df.describe())\n",
    "\n",
    "# - Count the number of unique words or game states\n",
    "unique_words = df['word'].nunique()\n",
    "print(f\"Number of unique words: {unique_words}\")\n",
    "\n",
    "# - Inspect the distribution of game outcomes, difficulties, etc.\n",
    "print(df['outcome'].value_counts())\n",
    "print(df['difficulty'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1057e0",
   "metadata": {},
   "source": [
    "##### Reading Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cbe602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets directly from the saved parquet files\n",
    "train_dataset = HangmanDataset(parquet_train_path)\n",
    "valid_dataset = HangmanDataset(parquet_valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e7696bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'game_id': 25116,\n",
       " 'word': 'amiability',\n",
       " 'initial_state': ['__________'],\n",
       " 'final_state': 'amiability',\n",
       " 'guessed_states': ['__________',\n",
       "  '______l___',\n",
       "  '____b_l___',\n",
       "  'a__ab_l___',\n",
       "  'a_iabili__',\n",
       "  'a_iabili__',\n",
       "  'a_iabili_y',\n",
       "  'amiabili_y',\n",
       "  'amiabili_y',\n",
       "  'amiabili_y'],\n",
       " 'guessed_letters': ['l', 'b', 'a', 'i', 'x', 'y', 'm', 'd', 's', 't'],\n",
       " 'game_state': 'allMasked',\n",
       " 'difficulty': 'easy',\n",
       " 'outcome': 'win',\n",
       " 'word_length': 10,\n",
       " 'won': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7b5fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=512, \n",
    "                          collate_fn=custom_collate_fn, \n",
    "                          shuffle=True, \n",
    "                          num_workers=2,  # Adjust based on your system\n",
    "                          prefetch_factor=2)  # Adjust based on your needs\n",
    "                          \n",
    "val_loader = DataLoader(valid_dataset, batch_size=512, \n",
    "                          collate_fn=custom_collate_fn, \n",
    "                          shuffle=True, \n",
    "                          num_workers=15,  # Adjust based on your system\n",
    "                          prefetch_factor=2)  # Adjust based on your needs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optiver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "/home/sayem/Desktop/Hangman/1_a_dataset_generation.ipynb",
   "output_path": "/home/sayem/Desktop/Hangman/1_a_dataset_generation.ipynb",
   "parameters": {},
   "start_time": "2023-11-24T22:23:41.671735",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
