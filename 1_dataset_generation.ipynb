{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a62bd7e6",
   "metadata": {
    "papermill": {
     "duration": 0.002135,
     "end_time": "2023-11-24T22:23:42.367043",
     "exception": false,
     "start_time": "2023-11-24T22:23:42.364908",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "323a72c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T22:23:42.378753Z",
     "iopub.status.busy": "2023-11-24T22:23:42.378580Z",
     "iopub.status.idle": "2023-11-24T22:23:43.346735Z",
     "shell.execute_reply": "2023-11-24T22:23:43.346282Z"
    },
    "papermill": {
     "duration": 0.971674,
     "end_time": "2023-11-24T22:23:43.347691",
     "exception": false,
     "start_time": "2023-11-24T22:23:42.376017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from scr.dataset import *\n",
    "# from scr.game import *\n",
    "from scr.feature_engineering import *\n",
    "# from scr.plot_utils import *\n",
    "import gc\n",
    "from scr.utils import print_scenarios\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from scr.utils import read_words, save_words_to_file\n",
    "\n",
    "import sys\n",
    "# Custom library paths\n",
    "sys.path.extend(['../', './scr'])\n",
    "\n",
    "from scr.utils import set_seed\n",
    "from scr.utils import read_words\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Read and Shuffle Word List\n",
    "word_list = read_words('data/words_250000_train.txt') # , limit=10000)\n",
    "# word_list = read_words('data/250k.txt', limit=10000)\n",
    "\n",
    "random.shuffle(word_list)\n",
    "\n",
    "\n",
    "# Calculate Frequencies and Max Word Length\n",
    "word_frequencies = calculate_word_frequencies(word_list)\n",
    "char_frequency = calculate_char_frequencies(word_list)\n",
    "max_word_length = max(len(word) for word in word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ef82d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import h5py\n",
    "# import json\n",
    "\n",
    "# # Sample Hangman game data\n",
    "# games_data = [\n",
    "#     {\n",
    "#         'guessed_states': ['___b____e', 'a_aba___e', 'anaba__ne', 'anaba_ine'],\n",
    "#         'guessed_letters': ['a', 'n', 'i', 's'],\n",
    "#         'word': 'anabasine',\n",
    "#         'initial_state': '___b_____',\n",
    "#         'attributes': {'game_state': 'early', 'difficulty': 'easy', 'outcome': 'win', \n",
    "#                           'word_length': 9}\n",
    "#     },\n",
    "#     {\n",
    "#         'guessed_states': ['__c______', '_a_a_____'],\n",
    "#         'guessed_letters': ['c', 'a'],\n",
    "#         'word': 'cacophony',\n",
    "#         'initial_state': '__c______',\n",
    "#         'attributes': {'game_state': 'mid', 'difficulty': 'hard', 'outcome': 'lose', \n",
    "#                             'word_length': 9}\n",
    "#     }\n",
    "    \n",
    "#     # ... more games\n",
    "# ]\n",
    "\n",
    "# # Creating the HDF5 file\n",
    "# with h5py.File('HangmanData.h5', 'w') as f:\n",
    "#     for i, game in enumerate(games_data):\n",
    "#         # Create a group for each game\n",
    "#         game_group = f.create_group(f'game_{i+1}')\n",
    "\n",
    "#         # Serialize and store each part of the game data\n",
    "#         for key, value in game.items():\n",
    "#             if isinstance(value, dict):\n",
    "#                 # If the value is a dictionary, serialize it to JSON\n",
    "#                 value = json.dumps(value)\n",
    "#             game_group.create_dataset(key, data=value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e2750e",
   "metadata": {},
   "source": [
    "##### Data reading and Params Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca8b7063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories '/media/sayem/510B93E12554BBD1/dataset/100/train_parquets' and '/media/sayem/510B93E12554BBD1/dataset/100/valid_parquets' have been recreated.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "NUM_STRATIFIED_SAMPLES = 100 # This will be overwritten by Papermill\n",
    "\n",
    "# Define the base directory and the paths for training and validation parquet files\n",
    "base_dataset_dir = Path(\"/media/sayem/510B93E12554BBD1/dataset/\")\n",
    "\n",
    "stratified_samples_dir = base_dataset_dir / str(NUM_STRATIFIED_SAMPLES)\n",
    "\n",
    "parquet_train_path = stratified_samples_dir / 'train_parquets'\n",
    "parquet_valid_path = stratified_samples_dir / 'valid_parquets'\n",
    "\n",
    "# Function to delete and recreate a directory\n",
    "def recreate_directory(path):\n",
    "    if path.exists():\n",
    "        shutil.rmtree(path)  # Delete the directory and its contents\n",
    "    path.mkdir(parents=True)  # Create the directory\n",
    "\n",
    "# Recreate the train and valid directories\n",
    "recreate_directory(parquet_train_path)\n",
    "recreate_directory(parquet_valid_path)\n",
    "\n",
    "print(f\"Directories '{parquet_train_path}' and '{parquet_valid_path}' have been recreated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8cc199b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T22:23:43.568919Z",
     "iopub.status.busy": "2023-11-24T22:23:43.568821Z",
     "iopub.status.idle": "2023-11-24T22:23:43.571482Z",
     "shell.execute_reply": "2023-11-24T22:23:43.571208Z"
    },
    "papermill": {
     "duration": 0.007294,
     "end_time": "2023-11-24T22:23:43.572518",
     "exception": false,
     "start_time": "2023-11-24T22:23:43.565224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227300"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469a87ce",
   "metadata": {},
   "source": [
    "##### Stratified Sample Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41e486f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T22:23:43.579494Z",
     "iopub.status.busy": "2023-11-24T22:23:43.579377Z",
     "iopub.status.idle": "2023-11-24T22:23:43.640436Z",
     "shell.execute_reply": "2023-11-24T22:23:43.640019Z"
    },
    "papermill": {
     "duration": 0.065848,
     "end_time": "2023-11-24T22:23:43.641509",
     "exception": false,
     "start_time": "2023-11-24T22:23:43.575661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Statrified samples: 100\n",
      "230\n"
     ]
    }
   ],
   "source": [
    "## we are taking starified samples from train_words\n",
    "\n",
    "from scr.custom_sampler import \\\n",
    "    stratified_sample_by_length_and_frequency, \\\n",
    "        stratified_sample_by_length, stratified_sample_by_length_and_uniqueness\n",
    "\n",
    "print(f'Number of Statrified samples: {NUM_STRATIFIED_SAMPLES}')\n",
    "\n",
    "# sampled_words_by_length_and_frequency \\\n",
    "#     = stratified_sample_by_length_and_frequency(train_words, \\\n",
    "#     word_frequencies, \\\n",
    "#     NUM_STRATIFIED_SAMPLES)\n",
    "\n",
    "sampled_words_by_length = stratified_sample_by_length_and_uniqueness(word_list, \\\n",
    "    NUM_STRATIFIED_SAMPLES)\n",
    "\n",
    "\n",
    "print(len(sampled_words_by_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0d326f",
   "metadata": {
    "papermill": {
     "duration": 0.004373,
     "end_time": "2023-11-24T22:23:44.300659",
     "exception": false,
     "start_time": "2023-11-24T22:23:44.296286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Intial State Simulation Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae53fccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.game import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1415477e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'allMasked': '____________',\n",
       " 'early': '____o_o_____',\n",
       " 'quarterRevealed': '____o_o__i__',\n",
       " 'midRevealed': '_y__o_o__iz_',\n",
       " 'midLateRevealed': 'my__opo__iz_',\n",
       " 'lateRevealed': 'myt_opoetize',\n",
       " 'nearEnd': 'myt_opoetize'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word = \"mississippi\"\n",
    "word = \"mythopoetize\"\n",
    "# word = \"cat\"\n",
    "\n",
    "initial_states = process_word_for_six_states(word)\n",
    "\n",
    "initial_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c3da54c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T22:23:44.317155Z",
     "iopub.status.busy": "2023-11-24T22:23:44.317069Z",
     "iopub.status.idle": "2023-11-24T22:23:44.319452Z",
     "shell.execute_reply": "2023-11-24T22:23:44.319138Z"
    },
    "papermill": {
     "duration": 0.005907,
     "end_time": "2023-11-24T22:23:44.320079",
     "exception": false,
     "start_time": "2023-11-24T22:23:44.314172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(initial_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5cffa5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T22:23:44.326727Z",
     "iopub.status.busy": "2023-11-24T22:23:44.326580Z",
     "iopub.status.idle": "2023-11-24T22:23:44.329649Z",
     "shell.execute_reply": "2023-11-24T22:23:44.329220Z"
    },
    "papermill": {
     "duration": 0.007091,
     "end_time": "2023-11-24T22:23:44.330204",
     "exception": false,
     "start_time": "2023-11-24T22:23:44.323113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'allMasked': '____________',\n",
       " 'early': '____o_o_____',\n",
       " 'quarterRevealed': '____o_o__i__',\n",
       " 'midRevealed': '_y__o_o__iz_',\n",
       " 'midLateRevealed': 'my__opo__iz_',\n",
       " 'lateRevealed': 'myt_opoetize',\n",
       " 'nearEnd': 'myt_opoetize'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01da2152",
   "metadata": {
    "papermill": {
     "duration": 0.002642,
     "end_time": "2023-11-24T22:23:44.335321",
     "exception": false,
     "start_time": "2023-11-24T22:23:44.332679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Dataset Generation: Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3dfd089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Initial States:  {'allMasked': '___________', 'early': '________pp_', 'quarterRevealed': '________pp_', 'midRevealed': '_i__i__ippi', 'midLateRevealed': '_ississippi', 'lateRevealed': '_ississippi', 'nearEnd': '_ississippi'}\n"
     ]
    }
   ],
   "source": [
    "word = \"mississippi\"\n",
    "\n",
    "initial_states = process_word_for_six_states(word)\n",
    "\n",
    "# print(initial_states)\n",
    "# Print generated initial states\n",
    "print(\"Generated Initial States: \", initial_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f65e7334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Initial States:\n",
      "___________\n",
      "For initial state: ___________\n",
      "Guessed: 's', New State: '__ss_ss____', Correct: True\n",
      "Guessed: 'r', New State: '__ss_ss____', Correct: False\n",
      "Guessed: 'l', New State: '__ss_ss____', Correct: False\n",
      "Guessed: 'p', New State: '__ss_ss_pp_', Correct: True\n",
      "Guessed: 'g', New State: '__ss_ss_pp_', Correct: False\n",
      "Guessed: 'm', New State: 'm_ss_ss_pp_', Correct: True\n",
      "Guessed: 'i', New State: 'mississippi', Correct: True\n",
      "__ss_ss____\n",
      "For initial state: __ss_ss____\n",
      "Guessed: 'h', New State: '__ss_ss____', Correct: False\n",
      "Guessed: 'o', New State: '__ss_ss____', Correct: False\n",
      "Guessed: 'z', New State: '__ss_ss____', Correct: False\n",
      "Guessed: 'm', New State: 'm_ss_ss____', Correct: True\n",
      "Guessed: 'i', New State: 'mississi__i', Correct: True\n",
      "Guessed: 'c', New State: 'mississi__i', Correct: False\n",
      "Guessed: 'b', New State: 'mississi__i', Correct: False\n",
      "Guessed: 'e', New State: 'mississi__i', Correct: False\n",
      "__ss_ss____\n",
      "For initial state: __ss_ss____\n",
      "Guessed: 'p', New State: '__ss_ss_pp_', Correct: True\n",
      "Guessed: 'e', New State: '__ss_ss_pp_', Correct: False\n",
      "Guessed: 'i', New State: '_ississippi', Correct: True\n",
      "Guessed: 'd', New State: '_ississippi', Correct: False\n",
      "Guessed: 'b', New State: '_ississippi', Correct: False\n",
      "Guessed: 'y', New State: '_ississippi', Correct: False\n",
      "Guessed: 'm', New State: 'mississippi', Correct: True\n",
      "__ss_ss_pp_\n",
      "For initial state: __ss_ss_pp_\n",
      "Guessed: 'v', New State: '__ss_ss_pp_', Correct: False\n",
      "Guessed: 'y', New State: '__ss_ss_pp_', Correct: False\n",
      "Guessed: 'm', New State: 'm_ss_ss_pp_', Correct: True\n",
      "Guessed: 'h', New State: 'm_ss_ss_pp_', Correct: False\n",
      "Guessed: 'i', New State: 'mississippi', Correct: True\n",
      "_ississippi\n",
      "For initial state: _ississippi\n",
      "Guessed: 'm', New State: 'mississippi', Correct: True\n",
      "_ississippi\n",
      "For initial state: _ississippi\n",
      "Guessed: 'm', New State: 'mississippi', Correct: True\n",
      "_ississippi\n",
      "For initial state: _ississippi\n",
      "Guessed: 'm', New State: 'mississippi', Correct: True\n"
     ]
    }
   ],
   "source": [
    "from scr.game import simulate_game_progress, \\\n",
    "    play_game_with_a_word, process_word\n",
    "\n",
    "# Example word and initial state\n",
    "# Example usage\n",
    "word = \"mississippi\"\n",
    "# word = \"cat\"\n",
    "\n",
    "initial_states = process_word_for_six_states(word)\n",
    "\n",
    "# print(initial_states)\n",
    "# Print generated initial states\n",
    "print(\"Generated Initial States:\")\n",
    "for state_name, initial_state in initial_states.items():\n",
    "    # Simulate the game\n",
    "    print(initial_state)\n",
    "    print(f\"For initial state: {initial_state}\")\n",
    "    won, game_progress = simulate_game_progress(\n",
    "        model=None,  # Assuming model is not used in this example\n",
    "        word=word, \n",
    "        initial_state=initial_state, \n",
    "        char_frequency={},  # Assuming char_frequency is not used in this example\n",
    "        max_word_length=len(word), \n",
    "        device=None,  # Assuming device is not used in this example\n",
    "        max_attempts=6, \n",
    "        normalize=True,\n",
    "        difficulty=\"medium\", \n",
    "        outcome_preference='win'\n",
    "    )\n",
    "\n",
    "    # Display game progress\n",
    "    for step in game_progress:\n",
    "        print(f\"Guessed: '{step[0]}', New State: '{step[1]}', Correct: {step[2]}\")\n",
    "\n",
    "        # break\n",
    "\n",
    "    # break\n",
    "\n",
    "    # print(\"Game Result:\", \"Won\" if won else \"Lost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8955b2cc",
   "metadata": {},
   "source": [
    "##### Writing Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe2eb7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Words: 100%|██████████| 184/184 [00:02<00:00, 82.55it/s]\n",
      "Processing Words: 100%|██████████| 46/46 [00:00<00:00, 82.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Total games processed in training set: 7728\n",
      "Final Total games processed in validation set: 1932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming the function 'process_word_for_six_states' is defined elsewhere\n",
    "from scr.game import simulate_game_progress, process_word_for_six_states\n",
    "\n",
    "def process_batch_to_parquet(batch, file_path, start_game_counter):\n",
    "    game_counter = start_game_counter\n",
    "    data_for_parquet = []\n",
    "\n",
    "    for game_data in batch:\n",
    "        word, state_name, initial_state, difficulty, outcome, won, game_progress = game_data\n",
    "        if not game_progress:\n",
    "            continue\n",
    "\n",
    "        final_state = game_progress[-1][1]\n",
    "        guessed_states = [initial_state] + [state for _, state, _ in game_progress]\n",
    "        guessed_letters = [letter for letter, _, _ in game_progress]\n",
    "\n",
    "        data_for_parquet.append({\n",
    "            'game_id': game_counter,\n",
    "            'word': word,\n",
    "            'initial_state': initial_state,\n",
    "            'final_state': final_state,\n",
    "            'guessed_states': ','.join(guessed_states[:-1]),\n",
    "            'guessed_letters': ','.join(guessed_letters),\n",
    "            'game_state': state_name,\n",
    "            'difficulty': difficulty,\n",
    "            'outcome': outcome,\n",
    "            'word_length': len(word),\n",
    "            'won': won\n",
    "        })\n",
    "\n",
    "        game_counter += 1\n",
    "\n",
    "    df = pd.DataFrame(data_for_parquet)\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    pq.write_to_dataset(table, root_path=file_path, compression='snappy')\n",
    "\n",
    "    return game_counter\n",
    "\n",
    "def generate_batch_for_word(word):\n",
    "    batch = []\n",
    "    initial_states = process_word_for_six_states(word)\n",
    "    games_generated = 0  # Counter for games generated\n",
    "\n",
    "    for state_name, initial_state in initial_states.items():\n",
    "        for difficulty in [\"easy\", \"medium\", \"hard\"]:\n",
    "            for outcome in [\"win\", \"lose\"]:\n",
    "                won, game_progress = simulate_game_progress(\n",
    "                    model=None, word=word, initial_state=initial_state,\n",
    "                    char_frequency={}, max_word_length=len(word),\n",
    "                    device=None, max_attempts=6, normalize=True,\n",
    "                    difficulty=difficulty, outcome_preference=outcome\n",
    "                )\n",
    "                batch.append((word, state_name, initial_state, difficulty, outcome, won, game_progress))\n",
    "                games_generated += 1  # Increment game counter\n",
    "\n",
    "    return batch, games_generated\n",
    "\n",
    "\n",
    "def main_execution(words, parquet_train_path, parquet_valid_path, test_size=0.20):\n",
    "    train_game_counter = 0\n",
    "    valid_game_counter = 0\n",
    "    games_per_word = 6 * 3 * 2  # 6 states, 3 difficulties, 2 outcomes\n",
    "\n",
    "    train_words, valid_words = train_test_split(words, test_size=test_size)\n",
    "\n",
    "    # Process each word set\n",
    "    for word_set, path in [(train_words, parquet_train_path), (valid_words, parquet_valid_path)]:\n",
    "        total_words_processed = 0\n",
    "        total_games_generated = 0\n",
    "\n",
    "        for word in tqdm(word_set, desc=\"Processing Words\"):\n",
    "            batch, games_generated = generate_batch_for_word(word)\n",
    "\n",
    "            # Update word count and game count\n",
    "            total_words_processed += 1\n",
    "            total_games_generated += games_generated\n",
    "\n",
    "            # Update game counters\n",
    "            if word_set is train_words:\n",
    "                train_game_counter += games_generated\n",
    "                process_batch_to_parquet(batch, path, train_game_counter)\n",
    "            else:\n",
    "                valid_game_counter += games_generated\n",
    "                process_batch_to_parquet(batch, path, valid_game_counter)\n",
    "\n",
    "    print(f\"Final Total games processed in training set: {train_game_counter}\")\n",
    "    print(f\"Final Total games processed in validation set: {valid_game_counter}\")\n",
    "\n",
    "# Execute the main function\n",
    "main_execution(sampled_words_by_length, parquet_train_path, parquet_valid_path, test_size=0.20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a7795d",
   "metadata": {},
   "source": [
    "##### Checking Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "318f8ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parquet files: 184\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Assuming parquet_train_path is already defined as a Path object\n",
    "# If not, define it here\n",
    "# parquet_train_path = Path('path_to_your_train_parquet_directory')\n",
    "\n",
    "# Use glob to find all Parquet files in the folder\n",
    "parquet_files = parquet_train_path.glob('*.parquet')\n",
    "\n",
    "# Count the number of files\n",
    "file_count = sum(1 for _ in parquet_files)\n",
    "\n",
    "print(f\"Number of Parquet files: {file_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb677b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of game sequences across all files: 7668\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Find all Parquet files in the directory\n",
    "parquet_files = list(parquet_train_path.glob('*.parquet'))\n",
    "\n",
    "if parquet_files:\n",
    "    total_game_sequences = 0\n",
    "\n",
    "    # Iterate over each file and sum the number of game sequences\n",
    "    for file in parquet_files:\n",
    "        df = pd.read_parquet(file)\n",
    "        total_game_sequences += len(df)\n",
    "\n",
    "    print(f\"Total number of game sequences across all files: {total_game_sequences}\")\n",
    "else:\n",
    "    print(\"No Parquet files found in the specified directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14ae9653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of games in the dataset: 7668\n",
      "Null values in each column:\n",
      "game_id            0\n",
      "word               0\n",
      "initial_state      0\n",
      "final_state        0\n",
      "guessed_states     0\n",
      "guessed_letters    0\n",
      "game_state         0\n",
      "difficulty         0\n",
      "outcome            0\n",
      "word_length        0\n",
      "won                0\n",
      "dtype: int64\n",
      "\n",
      "Summary statistics:\n",
      "           game_id  word_length\n",
      "count  7668.000000  7668.000000\n",
      "mean   3912.241784    13.090767\n",
      "std    2233.193521     5.716223\n",
      "min      42.000000     1.000000\n",
      "25%    1958.750000     8.000000\n",
      "50%    3923.500000    12.000000\n",
      "75%    5840.250000    18.000000\n",
      "max    7769.000000    27.000000\n",
      "\n",
      "Number of unique words: 184\n",
      "\n",
      "Outcome distribution:\n",
      "outcome\n",
      "win     3834\n",
      "lose    3834\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Difficulty distribution:\n",
      "difficulty\n",
      "easy      2556\n",
      "medium    2556\n",
      "hard      2556\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Use glob to find all Parquet files in the folder\n",
    "parquet_files = parquet_train_path.glob('*.parquet')\n",
    "\n",
    "# Read and concatenate all Parquet files into a single DataFrame\n",
    "df = pd.concat([pd.read_parquet(file) for file in parquet_files], ignore_index=True)\n",
    "\n",
    "# # Display the first few rows of the DataFrame\n",
    "# print(df.head())\n",
    "\n",
    "# Get the total number of rows (games) in the DataFrame\n",
    "total_games = len(df)\n",
    "print(f\"Total number of games in the dataset: {total_games}\")\n",
    "\n",
    "# Additional checks and summary statistics\n",
    "print(\"Null values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Count the number of unique words or game states\n",
    "unique_words = df['word'].nunique()\n",
    "print(f\"\\nNumber of unique words: {unique_words}\")\n",
    "\n",
    "# Inspect the distribution of game outcomes, difficulties, etc.\n",
    "print(\"\\nOutcome distribution:\")\n",
    "print(df['outcome'].value_counts())\n",
    "\n",
    "print(\"\\nDifficulty distribution:\")\n",
    "print(df['difficulty'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d1359cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>word</th>\n",
       "      <th>initial_state</th>\n",
       "      <th>final_state</th>\n",
       "      <th>guessed_states</th>\n",
       "      <th>guessed_letters</th>\n",
       "      <th>game_state</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>outcome</th>\n",
       "      <th>word_length</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6006</td>\n",
       "      <td>overindustrializing</td>\n",
       "      <td>___________________</td>\n",
       "      <td>overindustrializing</td>\n",
       "      <td>___________________,_________t_________,___r__...</td>\n",
       "      <td>t,r,h,m,q,a,o,f,e,s,i,l,z,n,d,v,u,g</td>\n",
       "      <td>allMasked</td>\n",
       "      <td>easy</td>\n",
       "      <td>win</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6007</td>\n",
       "      <td>overindustrializing</td>\n",
       "      <td>___________________</td>\n",
       "      <td>overindustrializing</td>\n",
       "      <td>___________________,_________t_________,_____n...</td>\n",
       "      <td>t,n,a,s,f,r,i,m,u,z,w,o,c,e,d,h,g,v,l</td>\n",
       "      <td>allMasked</td>\n",
       "      <td>easy</td>\n",
       "      <td>lose</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6008</td>\n",
       "      <td>overindustrializing</td>\n",
       "      <td>___________________</td>\n",
       "      <td>o__r_ndu_tr_a____n_</td>\n",
       "      <td>___________________,_________t_________,______...</td>\n",
       "      <td>t,m,r,a,d,o,b,u,w,n,k,p,h</td>\n",
       "      <td>allMasked</td>\n",
       "      <td>medium</td>\n",
       "      <td>win</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6009</td>\n",
       "      <td>overindustrializing</td>\n",
       "      <td>___________________</td>\n",
       "      <td>overindustrializing</td>\n",
       "      <td>___________________,_________t_________,______...</td>\n",
       "      <td>t,u,s,y,i,v,b,p,q,l,a,o,d,n,e,g,z,h,r</td>\n",
       "      <td>allMasked</td>\n",
       "      <td>medium</td>\n",
       "      <td>lose</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6010</td>\n",
       "      <td>overindustrializing</td>\n",
       "      <td>___________________</td>\n",
       "      <td>__e__n__s___a____n_</td>\n",
       "      <td>___________________,_____n___________n_,_____n...</td>\n",
       "      <td>n,k,e,b,a,p,s,j,x,f</td>\n",
       "      <td>allMasked</td>\n",
       "      <td>hard</td>\n",
       "      <td>win</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7663</th>\n",
       "      <td>3775</td>\n",
       "      <td>scientificophilosophical</td>\n",
       "      <td>scientificophi_osophica_</td>\n",
       "      <td>scientificophilosophical</td>\n",
       "      <td>scientificophi_osophica_</td>\n",
       "      <td>l</td>\n",
       "      <td>nearEnd</td>\n",
       "      <td>easy</td>\n",
       "      <td>lose</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7664</th>\n",
       "      <td>3776</td>\n",
       "      <td>scientificophilosophical</td>\n",
       "      <td>scientificophi_osophica_</td>\n",
       "      <td>scientificophilosophical</td>\n",
       "      <td>scientificophi_osophica_</td>\n",
       "      <td>l</td>\n",
       "      <td>nearEnd</td>\n",
       "      <td>medium</td>\n",
       "      <td>win</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7665</th>\n",
       "      <td>3777</td>\n",
       "      <td>scientificophilosophical</td>\n",
       "      <td>scientificophi_osophica_</td>\n",
       "      <td>scientificophilosophical</td>\n",
       "      <td>scientificophi_osophica_,scientificophi_osophica_</td>\n",
       "      <td>z,l</td>\n",
       "      <td>nearEnd</td>\n",
       "      <td>medium</td>\n",
       "      <td>lose</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7666</th>\n",
       "      <td>3778</td>\n",
       "      <td>scientificophilosophical</td>\n",
       "      <td>scientificophi_osophica_</td>\n",
       "      <td>scientificophilosophical</td>\n",
       "      <td>scientificophi_osophica_</td>\n",
       "      <td>l</td>\n",
       "      <td>nearEnd</td>\n",
       "      <td>hard</td>\n",
       "      <td>win</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667</th>\n",
       "      <td>3779</td>\n",
       "      <td>scientificophilosophical</td>\n",
       "      <td>scientificophi_osophica_</td>\n",
       "      <td>scientificophilosophical</td>\n",
       "      <td>scientificophi_osophica_</td>\n",
       "      <td>l</td>\n",
       "      <td>nearEnd</td>\n",
       "      <td>hard</td>\n",
       "      <td>lose</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7668 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      game_id                      word             initial_state  \\\n",
       "0        6006       overindustrializing       ___________________   \n",
       "1        6007       overindustrializing       ___________________   \n",
       "2        6008       overindustrializing       ___________________   \n",
       "3        6009       overindustrializing       ___________________   \n",
       "4        6010       overindustrializing       ___________________   \n",
       "...       ...                       ...                       ...   \n",
       "7663     3775  scientificophilosophical  scientificophi_osophica_   \n",
       "7664     3776  scientificophilosophical  scientificophi_osophica_   \n",
       "7665     3777  scientificophilosophical  scientificophi_osophica_   \n",
       "7666     3778  scientificophilosophical  scientificophi_osophica_   \n",
       "7667     3779  scientificophilosophical  scientificophi_osophica_   \n",
       "\n",
       "                   final_state  \\\n",
       "0          overindustrializing   \n",
       "1          overindustrializing   \n",
       "2          o__r_ndu_tr_a____n_   \n",
       "3          overindustrializing   \n",
       "4          __e__n__s___a____n_   \n",
       "...                        ...   \n",
       "7663  scientificophilosophical   \n",
       "7664  scientificophilosophical   \n",
       "7665  scientificophilosophical   \n",
       "7666  scientificophilosophical   \n",
       "7667  scientificophilosophical   \n",
       "\n",
       "                                         guessed_states  \\\n",
       "0     ___________________,_________t_________,___r__...   \n",
       "1     ___________________,_________t_________,_____n...   \n",
       "2     ___________________,_________t_________,______...   \n",
       "3     ___________________,_________t_________,______...   \n",
       "4     ___________________,_____n___________n_,_____n...   \n",
       "...                                                 ...   \n",
       "7663                           scientificophi_osophica_   \n",
       "7664                           scientificophi_osophica_   \n",
       "7665  scientificophi_osophica_,scientificophi_osophica_   \n",
       "7666                           scientificophi_osophica_   \n",
       "7667                           scientificophi_osophica_   \n",
       "\n",
       "                            guessed_letters game_state difficulty outcome  \\\n",
       "0       t,r,h,m,q,a,o,f,e,s,i,l,z,n,d,v,u,g  allMasked       easy     win   \n",
       "1     t,n,a,s,f,r,i,m,u,z,w,o,c,e,d,h,g,v,l  allMasked       easy    lose   \n",
       "2                 t,m,r,a,d,o,b,u,w,n,k,p,h  allMasked     medium     win   \n",
       "3     t,u,s,y,i,v,b,p,q,l,a,o,d,n,e,g,z,h,r  allMasked     medium    lose   \n",
       "4                       n,k,e,b,a,p,s,j,x,f  allMasked       hard     win   \n",
       "...                                     ...        ...        ...     ...   \n",
       "7663                                      l    nearEnd       easy    lose   \n",
       "7664                                      l    nearEnd     medium     win   \n",
       "7665                                    z,l    nearEnd     medium    lose   \n",
       "7666                                      l    nearEnd       hard     win   \n",
       "7667                                      l    nearEnd       hard    lose   \n",
       "\n",
       "      word_length    won  \n",
       "0              19   True  \n",
       "1              19   True  \n",
       "2              19  False  \n",
       "3              19   True  \n",
       "4              19  False  \n",
       "...           ...    ...  \n",
       "7663           24   True  \n",
       "7664           24   True  \n",
       "7665           24   True  \n",
       "7666           24   True  \n",
       "7667           24   True  \n",
       "\n",
       "[7668 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# # Replace this with the path to your Parquet file\n",
    "# parquet_file_path = 'path/to/your/HangmanData.parquet'\n",
    "\n",
    "# Read the Parquet file\n",
    "df = pd.read_parquet(parquet_train_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3a8c199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of games in the dataset: 7668\n",
      "game_id            0\n",
      "word               0\n",
      "initial_state      0\n",
      "final_state        0\n",
      "guessed_states     0\n",
      "guessed_letters    0\n",
      "game_state         0\n",
      "difficulty         0\n",
      "outcome            0\n",
      "word_length        0\n",
      "won                0\n",
      "dtype: int64\n",
      "           game_id  word_length\n",
      "count  7668.000000  7668.000000\n",
      "mean   3912.241784    13.090767\n",
      "std    2233.193521     5.716223\n",
      "min      42.000000     1.000000\n",
      "25%    1958.750000     8.000000\n",
      "50%    3923.500000    12.000000\n",
      "75%    5840.250000    18.000000\n",
      "max    7769.000000    27.000000\n",
      "Number of unique words: 184\n",
      "outcome\n",
      "win     3834\n",
      "lose    3834\n",
      "Name: count, dtype: int64\n",
      "difficulty\n",
      "easy      2556\n",
      "medium    2556\n",
      "hard      2556\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get the total number of rows (games) in the DataFrame\n",
    "total_games = len(df)\n",
    "\n",
    "print(f\"Total number of games in the dataset: {total_games}\")\n",
    "\n",
    "# Additional checks you might want to perform:\n",
    "# - Check for any null values or anomalies in the data\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# - Get a summary of the DataFrame\n",
    "print(df.describe())\n",
    "\n",
    "# - Count the number of unique words or game states\n",
    "unique_words = df['word'].nunique()\n",
    "print(f\"Number of unique words: {unique_words}\")\n",
    "\n",
    "# - Inspect the distribution of game outcomes, difficulties, etc.\n",
    "print(df['outcome'].value_counts())\n",
    "print(df['difficulty'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd332aa",
   "metadata": {},
   "source": [
    "##### Checking the Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dfe3329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>word</th>\n",
       "      <th>initial_state</th>\n",
       "      <th>final_state</th>\n",
       "      <th>guessed_states</th>\n",
       "      <th>guessed_letters</th>\n",
       "      <th>game_state</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>outcome</th>\n",
       "      <th>word_length</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1176</td>\n",
       "      <td>publicheartedness</td>\n",
       "      <td>_________________</td>\n",
       "      <td>publicheartedness</td>\n",
       "      <td>_________________,_________________,_______e__...</td>\n",
       "      <td>f,e,r,a,t,i,z,d,l,n,b,c,p,u,h,s</td>\n",
       "      <td>allMasked</td>\n",
       "      <td>easy</td>\n",
       "      <td>win</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1177</td>\n",
       "      <td>publicheartedness</td>\n",
       "      <td>_________________</td>\n",
       "      <td>publicheartedness</td>\n",
       "      <td>_________________,___l_____________,___l______...</td>\n",
       "      <td>l,j,a,r,t,s,q,u,p,e,c,i,d,h,b,n</td>\n",
       "      <td>allMasked</td>\n",
       "      <td>easy</td>\n",
       "      <td>lose</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1178</td>\n",
       "      <td>publicheartedness</td>\n",
       "      <td>_________________</td>\n",
       "      <td>pu_lic__art____ss</td>\n",
       "      <td>_________________,_________________,_____c____...</td>\n",
       "      <td>j,c,l,s,y,a,k,t,r,i,o,z,p,u,m</td>\n",
       "      <td>allMasked</td>\n",
       "      <td>medium</td>\n",
       "      <td>win</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1179</td>\n",
       "      <td>publicheartedness</td>\n",
       "      <td>_________________</td>\n",
       "      <td>p_______a___dn___</td>\n",
       "      <td>_________________,_________________,p_________...</td>\n",
       "      <td>f,p,d,x,k,w,n,v,a,z</td>\n",
       "      <td>allMasked</td>\n",
       "      <td>medium</td>\n",
       "      <td>lose</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1180</td>\n",
       "      <td>publicheartedness</td>\n",
       "      <td>_________________</td>\n",
       "      <td>_________________</td>\n",
       "      <td>_________________,_________________,__________...</td>\n",
       "      <td>q,w,o,x,v,y</td>\n",
       "      <td>allMasked</td>\n",
       "      <td>hard</td>\n",
       "      <td>win</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>1843</td>\n",
       "      <td>hypogastrium</td>\n",
       "      <td>hypoga_trium</td>\n",
       "      <td>hypogastrium</td>\n",
       "      <td>hypoga_trium</td>\n",
       "      <td>s</td>\n",
       "      <td>nearEnd</td>\n",
       "      <td>easy</td>\n",
       "      <td>lose</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>1844</td>\n",
       "      <td>hypogastrium</td>\n",
       "      <td>hypoga_trium</td>\n",
       "      <td>hypogastrium</td>\n",
       "      <td>hypoga_trium</td>\n",
       "      <td>s</td>\n",
       "      <td>nearEnd</td>\n",
       "      <td>medium</td>\n",
       "      <td>win</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>1845</td>\n",
       "      <td>hypogastrium</td>\n",
       "      <td>hypoga_trium</td>\n",
       "      <td>hypogastrium</td>\n",
       "      <td>hypoga_trium</td>\n",
       "      <td>s</td>\n",
       "      <td>nearEnd</td>\n",
       "      <td>medium</td>\n",
       "      <td>lose</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>1846</td>\n",
       "      <td>hypogastrium</td>\n",
       "      <td>hypoga_trium</td>\n",
       "      <td>hypogastrium</td>\n",
       "      <td>hypoga_trium,hypoga_trium,hypoga_trium,hypoga_...</td>\n",
       "      <td>b,j,w,s</td>\n",
       "      <td>nearEnd</td>\n",
       "      <td>hard</td>\n",
       "      <td>win</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>1847</td>\n",
       "      <td>hypogastrium</td>\n",
       "      <td>hypoga_trium</td>\n",
       "      <td>hypoga_trium</td>\n",
       "      <td>hypoga_trium,hypoga_trium,hypoga_trium,hypoga_...</td>\n",
       "      <td>n,z,b,k,v,q</td>\n",
       "      <td>nearEnd</td>\n",
       "      <td>hard</td>\n",
       "      <td>lose</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1908 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      game_id               word      initial_state        final_state  \\\n",
       "0        1176  publicheartedness  _________________  publicheartedness   \n",
       "1        1177  publicheartedness  _________________  publicheartedness   \n",
       "2        1178  publicheartedness  _________________  pu_lic__art____ss   \n",
       "3        1179  publicheartedness  _________________  p_______a___dn___   \n",
       "4        1180  publicheartedness  _________________  _________________   \n",
       "...       ...                ...                ...                ...   \n",
       "1903     1843       hypogastrium       hypoga_trium       hypogastrium   \n",
       "1904     1844       hypogastrium       hypoga_trium       hypogastrium   \n",
       "1905     1845       hypogastrium       hypoga_trium       hypogastrium   \n",
       "1906     1846       hypogastrium       hypoga_trium       hypogastrium   \n",
       "1907     1847       hypogastrium       hypoga_trium       hypoga_trium   \n",
       "\n",
       "                                         guessed_states  \\\n",
       "0     _________________,_________________,_______e__...   \n",
       "1     _________________,___l_____________,___l______...   \n",
       "2     _________________,_________________,_____c____...   \n",
       "3     _________________,_________________,p_________...   \n",
       "4     _________________,_________________,__________...   \n",
       "...                                                 ...   \n",
       "1903                                       hypoga_trium   \n",
       "1904                                       hypoga_trium   \n",
       "1905                                       hypoga_trium   \n",
       "1906  hypoga_trium,hypoga_trium,hypoga_trium,hypoga_...   \n",
       "1907  hypoga_trium,hypoga_trium,hypoga_trium,hypoga_...   \n",
       "\n",
       "                      guessed_letters game_state difficulty outcome  \\\n",
       "0     f,e,r,a,t,i,z,d,l,n,b,c,p,u,h,s  allMasked       easy     win   \n",
       "1     l,j,a,r,t,s,q,u,p,e,c,i,d,h,b,n  allMasked       easy    lose   \n",
       "2       j,c,l,s,y,a,k,t,r,i,o,z,p,u,m  allMasked     medium     win   \n",
       "3                 f,p,d,x,k,w,n,v,a,z  allMasked     medium    lose   \n",
       "4                         q,w,o,x,v,y  allMasked       hard     win   \n",
       "...                               ...        ...        ...     ...   \n",
       "1903                                s    nearEnd       easy    lose   \n",
       "1904                                s    nearEnd     medium     win   \n",
       "1905                                s    nearEnd     medium    lose   \n",
       "1906                          b,j,w,s    nearEnd       hard     win   \n",
       "1907                      n,z,b,k,v,q    nearEnd       hard    lose   \n",
       "\n",
       "      word_length    won  \n",
       "0              17   True  \n",
       "1              17   True  \n",
       "2              17  False  \n",
       "3              17  False  \n",
       "4              17  False  \n",
       "...           ...    ...  \n",
       "1903           12   True  \n",
       "1904           12   True  \n",
       "1905           12   True  \n",
       "1906           12   True  \n",
       "1907           12  False  \n",
       "\n",
       "[1908 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# # Replace this with the path to your Parquet file\n",
    "# parquet_file_path = 'path/to/your/HangmanData.parquet'\n",
    "\n",
    "# Read the Parquet file\n",
    "df = pd.read_parquet(parquet_valid_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08449596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of games in the dataset: 1908\n",
      "game_id            0\n",
      "word               0\n",
      "initial_state      0\n",
      "final_state        0\n",
      "guessed_states     0\n",
      "guessed_letters    0\n",
      "game_state         0\n",
      "difficulty         0\n",
      "outcome            0\n",
      "word_length        0\n",
      "won                0\n",
      "dtype: int64\n",
      "           game_id  word_length\n",
      "count  1908.000000  1908.000000\n",
      "mean   1010.481132    13.625786\n",
      "std     560.681541     6.718507\n",
      "min      42.000000     3.000000\n",
      "25%     518.750000     9.000000\n",
      "50%    1019.500000    13.000000\n",
      "75%    1496.250000    18.000000\n",
      "max    1973.000000    29.000000\n",
      "Number of unique words: 46\n",
      "outcome\n",
      "win     954\n",
      "lose    954\n",
      "Name: count, dtype: int64\n",
      "difficulty\n",
      "easy      636\n",
      "medium    636\n",
      "hard      636\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get the total number of rows (games) in the DataFrame\n",
    "total_games = len(df)\n",
    "\n",
    "print(f\"Total number of games in the dataset: {total_games}\")\n",
    "\n",
    "# Additional checks you might want to perform:\n",
    "# - Check for any null values or anomalies in the data\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# - Get a summary of the DataFrame\n",
    "print(df.describe())\n",
    "\n",
    "# - Count the number of unique words or game states\n",
    "unique_words = df['word'].nunique()\n",
    "print(f\"Number of unique words: {unique_words}\")\n",
    "\n",
    "# - Inspect the distribution of game outcomes, difficulties, etc.\n",
    "print(df['outcome'].value_counts())\n",
    "print(df['difficulty'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1057e0",
   "metadata": {},
   "source": [
    "##### Reading Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cbe602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets directly from the saved parquet files\n",
    "train_dataset = HangmanDataset(parquet_train_path)\n",
    "valid_dataset = HangmanDataset(parquet_valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e7696bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'game_id': 6006,\n",
       " 'word': 'overindustrializing',\n",
       " 'initial_state': ['___________________'],\n",
       " 'final_state': 'overindustrializing',\n",
       " 'guessed_states': ['___________________',\n",
       "  '_________t_________',\n",
       "  '___r_____tr________',\n",
       "  '___r_____tr________',\n",
       "  '___r_____tr________',\n",
       "  '___r_____tr________',\n",
       "  '___r_____tr_a______',\n",
       "  'o__r_____tr_a______',\n",
       "  'o__r_____tr_a______',\n",
       "  'o_er_____tr_a______',\n",
       "  'o_er____str_a______',\n",
       "  'o_eri___stria_i_i__',\n",
       "  'o_eri___striali_i__',\n",
       "  'o_eri___strializi__',\n",
       "  'o_erin__strializin_',\n",
       "  'o_erind_strializin_',\n",
       "  'overind_strializin_',\n",
       "  'overindustrializin_'],\n",
       " 'guessed_letters': ['t',\n",
       "  'r',\n",
       "  'h',\n",
       "  'm',\n",
       "  'q',\n",
       "  'a',\n",
       "  'o',\n",
       "  'f',\n",
       "  'e',\n",
       "  's',\n",
       "  'i',\n",
       "  'l',\n",
       "  'z',\n",
       "  'n',\n",
       "  'd',\n",
       "  'v',\n",
       "  'u',\n",
       "  'g'],\n",
       " 'game_state': 'allMasked',\n",
       " 'difficulty': 'easy',\n",
       " 'outcome': 'win',\n",
       " 'word_length': 19,\n",
       " 'won': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7b5fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=512, \n",
    "                          collate_fn=custom_collate_fn, \n",
    "                          shuffle=True, \n",
    "                          num_workers=15,  # Adjust based on your system\n",
    "                          prefetch_factor=2)  # Adjust based on your needs\n",
    "                          \n",
    "val_loader = DataLoader(valid_dataset, batch_size=512, \n",
    "                          collate_fn=custom_collate_fn, \n",
    "                          shuffle=True, \n",
    "                          num_workers=15,  # Adjust based on your system\n",
    "                          prefetch_factor=2)  # Adjust based on your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d23f8357",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataset:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4327865f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7668"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optiver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "/home/sayem/Desktop/Hangman/1_a_dataset_generation.ipynb",
   "output_path": "/home/sayem/Desktop/Hangman/1_a_dataset_generation.ipynb",
   "parameters": {},
   "start_time": "2023-11-24T22:23:41.671735",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
