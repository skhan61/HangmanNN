{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a62bd7e6",
   "metadata": {
    "papermill": {
     "duration": 0.002135,
     "end_time": "2023-11-24T22:23:42.367043",
     "exception": false,
     "start_time": "2023-11-24T22:23:42.364908",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323a72c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T22:23:42.378753Z",
     "iopub.status.busy": "2023-11-24T22:23:42.378580Z",
     "iopub.status.idle": "2023-11-24T22:23:43.346735Z",
     "shell.execute_reply": "2023-11-24T22:23:43.346282Z"
    },
    "papermill": {
     "duration": 0.971674,
     "end_time": "2023-11-24T22:23:43.347691",
     "exception": false,
     "start_time": "2023-11-24T22:23:42.376017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from scr.dataset import *\n",
    "from scr.game import *\n",
    "from scr.plot_utils import *\n",
    "import gc\n",
    "from scr.utils import print_scenarios\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from scr.feature_engineering import \\\n",
    "    calculate_char_frequencies, calculate_word_frequencies\n",
    "from scr.utils import read_words, save_words_to_file\n",
    "\n",
    "import sys\n",
    "# Custom library paths\n",
    "sys.path.extend(['../', './scr'])\n",
    "\n",
    "from scr.utils import set_seed\n",
    "from scr.utils import read_words\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Read and Shuffle Word List\n",
    "word_list = read_words('data/words_250000_train.txt') # , limit=10000)\n",
    "# word_list = read_words('data/250k.txt', limit=10000)\n",
    "random.shuffle(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data reading and Params Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    " #### Papermil if need\n",
    " \n",
    "NUM_STRATIFIED_SAMPLES = 25000 # This will be overwritten by Papermill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945ee9c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T22:23:43.360693Z",
     "iopub.status.busy": "2023-11-24T22:23:43.360496Z",
     "iopub.status.idle": "2023-11-24T22:23:43.362839Z",
     "shell.execute_reply": "2023-11-24T22:23:43.362546Z"
    },
    "papermill": {
     "duration": 0.012935,
     "end_time": "2023-11-24T22:23:43.363813",
     "exception": false,
     "start_time": "2023-11-24T22:23:43.350878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dataset_dir = Path(f\"/media/sayem/510B93E12554BBD1/dataset/{NUM_STRATIFIED_SAMPLES}\")\n",
    "\n",
    "\n",
    "print(\"NUM_STRATIFIED_SAMPLES:\", NUM_STRATIFIED_SAMPLES)\n",
    "print(\"base_dataset_dir:\", base_dataset_dir)\n",
    "\n",
    "# Import necessary library\n",
    "from pathlib import Path\n",
    "\n",
    "# # Validate if parameters are provided\n",
    "# if NUM_STRATIFIED_SAMPLES is None or base_dataset_dir is None:\n",
    "#     raise ValueError(\"NUM_STRATIFIED_SAMPLES and base_dataset_dir must be provided.\")\n",
    "\n",
    "# Define the base directory on the specified drive\n",
    "base_dataset_dir = Path(base_dataset_dir)\n",
    "\n",
    "# Ensuring the directory exists\n",
    "base_dataset_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create a subdirectory for pickle files\n",
    "pkls_dir = base_dataset_dir / 'pkl'\n",
    "pkls_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d927a799",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T22:23:43.391740Z",
     "iopub.status.busy": "2023-11-24T22:23:43.391624Z",
     "iopub.status.idle": "2023-11-24T22:23:43.560403Z",
     "shell.execute_reply": "2023-11-24T22:23:43.559962Z"
    },
    "papermill": {
     "duration": 0.173511,
     "end_time": "2023-11-24T22:23:43.561690",
     "exception": false,
     "start_time": "2023-11-24T22:23:43.388179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting Dataset Function\n",
    "import random\n",
    "\n",
    "def split_dataset(word_list, train_ratio=0.8):\n",
    "    total_words = len(word_list)\n",
    "    train_size = int(total_words * train_ratio)\n",
    "    random.shuffle(word_list)\n",
    "    return word_list[:train_size], word_list[train_size:]\n",
    "\n",
    "# Splitting the word list\n",
    "train_words, test_words = split_dataset(word_list)\n",
    "\n",
    "# Save split datasets to files\n",
    "save_words_to_file(train_words, base_dataset_dir / 'train_words.txt')\n",
    "save_words_to_file(test_words, base_dataset_dir / 'test_words.txt')\n",
    "\n",
    "# Calculate Frequencies and Max Word Length\n",
    "word_frequencies = calculate_word_frequencies(train_words)\n",
    "char_frequency = calculate_char_frequencies(train_words)\n",
    "max_word_length = max(len(word) for word in train_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cc199b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T22:23:43.568919Z",
     "iopub.status.busy": "2023-11-24T22:23:43.568821Z",
     "iopub.status.idle": "2023-11-24T22:23:43.571482Z",
     "shell.execute_reply": "2023-11-24T22:23:43.571208Z"
    },
    "papermill": {
     "duration": 0.007294,
     "end_time": "2023-11-24T22:23:43.572518",
     "exception": false,
     "start_time": "2023-11-24T22:23:43.565224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(train_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stratified Sample Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e486f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T22:23:43.579494Z",
     "iopub.status.busy": "2023-11-24T22:23:43.579377Z",
     "iopub.status.idle": "2023-11-24T22:23:43.640436Z",
     "shell.execute_reply": "2023-11-24T22:23:43.640019Z"
    },
    "papermill": {
     "duration": 0.065848,
     "end_time": "2023-11-24T22:23:43.641509",
     "exception": false,
     "start_time": "2023-11-24T22:23:43.575661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## we are taking starified samples from train_words\n",
    "\n",
    "from scr.custom_sampler import \\\n",
    "    stratified_sample_by_length_and_frequency, \\\n",
    "        stratified_sample_by_length, stratified_sample_by_length_and_uniqueness\n",
    "\n",
    "print(f'Number of Statrified samples: {NUM_STRATIFIED_SAMPLES}')\n",
    "\n",
    "# sampled_words_by_length_and_frequency \\\n",
    "#     = stratified_sample_by_length_and_frequency(train_words, \\\n",
    "#     word_frequencies, \\\n",
    "#     NUM_STRATIFIED_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a004382",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T22:23:43.805581Z",
     "iopub.status.busy": "2023-11-24T22:23:43.805340Z",
     "iopub.status.idle": "2023-11-24T22:23:44.145395Z",
     "shell.execute_reply": "2023-11-24T22:23:44.145033Z"
    },
    "papermill": {
     "duration": 0.366615,
     "end_time": "2023-11-24T22:23:44.146430",
     "exception": false,
     "start_time": "2023-11-24T22:23:43.779815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scr.plot_utils import analyze_hangman_sample_practicality\n",
    "\n",
    "representation_evaluation, unique_inclusion = analyze_hangman_sample_practicality(\n",
    "    word_list, \n",
    "    stratified_sample_by_length_and_uniqueness, \n",
    "    NUM_STRATIFIED_SAMPLES\n",
    ")\n",
    "\n",
    "\n",
    "sampled_words_by_length = stratified_sample_by_length_and_uniqueness(word_list, \\\n",
    "    NUM_STRATIFIED_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab53c5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T22:23:44.209725Z",
     "iopub.status.busy": "2023-11-24T22:23:44.209635Z",
     "iopub.status.idle": "2023-11-24T22:23:44.211224Z",
     "shell.execute_reply": "2023-11-24T22:23:44.210997Z"
    },
    "papermill": {
     "duration": 0.004707,
     "end_time": "2023-11-24T22:23:44.211810",
     "exception": false,
     "start_time": "2023-11-24T22:23:44.207103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sampled_words_by_length_and_frequency \\\n",
    "#     = stratified_sample_by_length_and_frequency(train_words, \\\n",
    "#     word_frequencies, \\\n",
    "#     NUM_STRATIFIED_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0d326f",
   "metadata": {
    "papermill": {
     "duration": 0.004373,
     "end_time": "2023-11-24T22:23:44.300659",
     "exception": false,
     "start_time": "2023-11-24T22:23:44.296286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Intial State Simulation Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word = \"mississippi\"\n",
    "word = \"mythopoetize\"\n",
    "# word = \"cat\"\n",
    "\n",
    "initial_states = process_word_for_six_states(word)\n",
    "\n",
    "initial_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2648f21f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T22:23:44.307917Z",
     "iopub.status.busy": "2023-11-24T22:23:44.307806Z",
     "iopub.status.idle": "2023-11-24T22:23:44.310853Z",
     "shell.execute_reply": "2023-11-24T22:23:44.310583Z"
    },
    "papermill": {
     "duration": 0.006444,
     "end_time": "2023-11-24T22:23:44.311540",
     "exception": false,
     "start_time": "2023-11-24T22:23:44.305096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scr.game import simulate_game_progress, play_game_with_a_word, process_word\n",
    "\n",
    "# Example word and initial state\n",
    "# Example usage\n",
    "word = \"mississippi\"\n",
    "# word = \"cat\"\n",
    "\n",
    "initial_states = process_word_for_six_states(word)\n",
    "\n",
    "# print(initial_states)\n",
    "# Print generated initial states\n",
    "print(\"Generated Initial States:\")\n",
    "for state_name, initial_state in initial_states.items():\n",
    "    # Simulate the game\n",
    "    print(initial_state)\n",
    "    print(f\"For initial state: {initial_state}\")\n",
    "    won, game_progress = simulate_game_progress(\n",
    "        model=None,  # Assuming model is not used in this example\n",
    "        word=word, \n",
    "        initial_state=initial_state, \n",
    "        char_frequency={},  # Assuming char_frequency is not used in this example\n",
    "        max_word_length=len(word), \n",
    "        device=None,  # Assuming device is not used in this example\n",
    "        max_attempts=6, \n",
    "        normalize=True,\n",
    "        difficulty=\"medium\", \n",
    "        outcome_preference='win'\n",
    "    )\n",
    "\n",
    "    # Display game progress\n",
    "    for step in game_progress:\n",
    "        print(f\"Guessed: '{step[0]}', New State: '{step[1]}', Correct: {step[2]}\")\n",
    "\n",
    "        # break\n",
    "\n",
    "    # break\n",
    "\n",
    "    # print(\"Game Result:\", \"Won\" if won else \"Lost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3da54c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T22:23:44.317155Z",
     "iopub.status.busy": "2023-11-24T22:23:44.317069Z",
     "iopub.status.idle": "2023-11-24T22:23:44.319452Z",
     "shell.execute_reply": "2023-11-24T22:23:44.319138Z"
    },
    "papermill": {
     "duration": 0.005907,
     "end_time": "2023-11-24T22:23:44.320079",
     "exception": false,
     "start_time": "2023-11-24T22:23:44.314172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(initial_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cffa5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T22:23:44.326727Z",
     "iopub.status.busy": "2023-11-24T22:23:44.326580Z",
     "iopub.status.idle": "2023-11-24T22:23:44.329649Z",
     "shell.execute_reply": "2023-11-24T22:23:44.329220Z"
    },
    "papermill": {
     "duration": 0.007091,
     "end_time": "2023-11-24T22:23:44.330204",
     "exception": false,
     "start_time": "2023-11-24T22:23:44.323113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "initial_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01da2152",
   "metadata": {
    "papermill": {
     "duration": 0.002642,
     "end_time": "2023-11-24T22:23:44.335321",
     "exception": false,
     "start_time": "2023-11-24T22:23:44.332679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Dataset Generation: Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"mississippi\"\n",
    "\n",
    "initial_states = process_word_for_six_states(word)\n",
    "# print(initial_states)\n",
    "# Print generated initial states\n",
    "print(\"Generated Initial States: \", initial_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### one way to generate the dataset\n",
    "iteration = 0 \n",
    "for word in tqdm(sampled_words_by_length, miniters=2, leave=False, mininterval=2.0): \n",
    "    \n",
    "    all_scenarios = []\n",
    "    \n",
    "    game_states = process_word_for_six_states(word)\n",
    "\n",
    "    for state_name, initial_state in game_states.items():\n",
    "        for difficulty in [\"easy\", \"medium\", \"hard\"]:\n",
    "            for outcome in [\"win\", \"lose\"]:\n",
    "                won, game_progress = simulate_game_progress(\n",
    "                    model=None, \n",
    "                    word=word, \n",
    "                    initial_state=initial_state, \n",
    "                    char_frequency=char_frequency, \n",
    "                    max_word_length=max_word_length, \n",
    "                    device=device, \n",
    "                    max_attempts=6, \n",
    "                    normalize=True, \n",
    "                    difficulty=difficulty, \n",
    "                    outcome_preference=outcome\n",
    "                )\n",
    "\n",
    "                scenario = {\n",
    "                    'word': word,\n",
    "                    'state': state_name,  # Added 'state' key\n",
    "                    'difficulty': difficulty,\n",
    "                    'outcome': outcome, \n",
    "                    'initial_state': initial_state,\n",
    "                    'data': (won, game_progress),\n",
    "                    'word_length': len(word)\n",
    "                }\n",
    "                all_scenarios.append(scenario)\n",
    "\n",
    "    #             break\n",
    "    #         break\n",
    "    #     break\n",
    "    # break\n",
    "\n",
    "    # Create a directory for the current strarified samples\n",
    "    \n",
    "    current_batch_dir = pkls_dir / str(iteration)\n",
    "    current_batch_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # print(all_scenarios)\n",
    "\n",
    "    # print(current_batch_dir)\n",
    "\n",
    "    for scenario in all_scenarios:\n",
    "        try:\n",
    "            game_states = [scenario['data']]\n",
    "            \n",
    "            difficulty = scenario['difficulty']\n",
    "            outcome = scenario['outcome']\n",
    "            state = scenario['state']\n",
    "            initial_state = scenario['initial_state']  # This should be the correct scope\n",
    "            word_len = scenario['word_length']\n",
    "            file_path \\\n",
    "                = current_batch_dir \\\n",
    "                    / f\"{word}-from-{initial_state}-{state}-{difficulty}-{outcome}-{word_len}.pkl\"\n",
    "\n",
    "            # print(f\"Saving scenario for {word}: {file_path}\")\n",
    "\n",
    "            with open(file_path, 'wb') as file:\n",
    "                pickle.dump(game_states, file)\n",
    "\n",
    "            # print(f\"Saved {file_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving {file_path}: {e}\")\n",
    "\n",
    "    # Clear memory\n",
    "    del all_scenarios # , sampled_scenarios\n",
    "\n",
    "    # Manual garbage collection\n",
    "    gc.collect()\n",
    "\n",
    "    # train_words = [word for word in train_words if word not in sampled_words]\n",
    "    # print(len(train_words))\n",
    "    # print(iteration)\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkls_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c679a2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "##### Reading Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ee26b1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "pkl_list = []\n",
    "\n",
    "for batch_dir in sorted(pkls_dir.iterdir(), \\\n",
    "    key=lambda x: int(x.name) if x.name.isdigit() else float('inf')):\n",
    "\n",
    "    if batch_dir.is_dir():\n",
    "        pkl_files = list(batch_dir.glob(\"*.pkl\"))\n",
    "\n",
    "        for pkl_file in pkl_files:\n",
    "            with open(pkl_file, 'rb') as file:\n",
    "                game_data = pickle.load(file)\n",
    "\n",
    "                parts = pkl_file.stem.split('-from-')\n",
    "                word, remaining = parts[0], parts[1]\n",
    "                remaining_parts = remaining.split('-')\n",
    "                initial_state = remaining_parts[0]\n",
    "                state_name = remaining_parts[1]\n",
    "                difficulty = remaining_parts[2]\n",
    "                outcome = remaining_parts[3]\n",
    "                word_len = remaining_parts[4]\n",
    "\n",
    "                for data in game_data:\n",
    "                    game_won, guesses = data\n",
    "                    scenario = {\n",
    "                        'word': word,\n",
    "                        'state': state_name,\n",
    "                        'difficulty': difficulty,\n",
    "                        'outcome': outcome,\n",
    "                        'initial_state': initial_state,\n",
    "                        'data': (game_won, guesses),\n",
    "                        'word_length' : word_len\n",
    "\n",
    "                    }\n",
    "                    pkl_list.append((pkl_file, scenario))\n",
    "\n",
    "# Example usage\n",
    "index_to_access = 1000\n",
    "if index_to_access < len(pkl_list):\n",
    "    file_path, scenario = pkl_list[index_to_access]\n",
    "    print(f\"Contents of {file_path}:\")\n",
    "    # Assuming print_scenarios is a defined function\n",
    "    print_scenarios([scenario])\n",
    "else:\n",
    "    print(f\"No pickle file at index {index_to_access}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optiver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "/home/sayem/Desktop/Hangman/1_a_dataset_generation.ipynb",
   "output_path": "/home/sayem/Desktop/Hangman/1_a_dataset_generation.ipynb",
   "parameters": {},
   "start_time": "2023-11-24T22:23:41.671735",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
