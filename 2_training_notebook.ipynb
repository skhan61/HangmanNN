{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "import sys\n",
    "# Custom library paths\n",
    "sys.path.extend(['../', './scr'])\n",
    "\n",
    "from scr.utils import set_seed\n",
    "from scr.utils import read_words\n",
    "from pathlib import Path\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from scr.feature_engineering import \\\n",
    "    calculate_char_frequencies, calculate_word_frequencies\n",
    "from scr.utils import read_words, save_words_to_file\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from scr.dataset import *\n",
    "from scr.game import *\n",
    "from scr.plot_utils import *\n",
    "\n",
    "import gc\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "from scr.utils import print_scenarios\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Read and Shuffle Word List\n",
    "word_list = read_words('data/words_250000_train.txt') # , limit=10000)\n",
    "# word_list = read_words('data/250k.txt', limit=10000)\n",
    "random.shuffle(word_list)\n",
    "\n",
    "# base_dataset_dir = Path('dataset/pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 181840 train words from dataset/15000/train_words.txt\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "NUM_STRATIFIED_SAMPLES = 15000\n",
    "\n",
    "# # Define the base directory\n",
    "base_dataset_dir = Path(f'./dataset/{NUM_STRATIFIED_SAMPLES}')\n",
    "# base_dataset_dir = Path(f\"/media/sayem/510B93E12554BBD1/dataset/{NUM_STRATIFIED_SAMPLES}\")\n",
    "\n",
    "# Ensuring the base directory and 'pkl' subdirectory exist\n",
    "base_dataset_dir.mkdir(parents=True, exist_ok=True)\n",
    "pkls_dir = base_dataset_dir / 'pkl'\n",
    "pkls_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Paths to the words files\n",
    "train_words_file_path = base_dataset_dir / 'train_words.txt'\n",
    "test_words_file_path = base_dataset_dir / 'test_words.txt'\n",
    "\n",
    "# Read the words from the files\n",
    "try:\n",
    "    train_words = read_words(train_words_file_path)\n",
    "    print(f\"Loaded {len(train_words)} train words from {train_words_file_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {train_words_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('dataset/15000')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dataset_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For inference\n",
    "from scr.feature_engineering import *\n",
    "\n",
    "word_frequencies = calculate_word_frequencies(word_list)\n",
    "char_frequency = calculate_char_frequencies(word_list)\n",
    "max_word_length = max(len(word) for word in word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.simple_model import SimpleLSTM\n",
    "from scr.base_model import BaseModel\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from scr.feature_engineering import *\n",
    "\n",
    "# max_word_length = 29 # TODO will remove later\n",
    "# Instantiate and test the model\n",
    "config = {\n",
    "    'embedding_dim': 200,\n",
    "    'hidden_dim': 256,\n",
    "    'num_layers': 2,\n",
    "    'vocab_size': 27,\n",
    "    'max_word_length': max_word_length,\n",
    "    'input_feature_size': 5,\n",
    "    'use_embedding': True,\n",
    "    'miss_linear_dim': 50\n",
    "}\n",
    "\n",
    "model = SimpleLSTM(config)\n",
    "optimizer = model.optimizer\n",
    "\n",
    "# Assuming 'model' is your trained model instance\n",
    "model.save_model(file_path='models/model.pth')\n",
    "\n",
    "# Assuming the saved model file is 'models/model.pth'\n",
    "model_file_path = 'models/model.pth'\n",
    "\n",
    "# Specify the device to load the model onto\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model\n",
    "loaded_model = BaseModel.load_model(SimpleLSTM, model_file_path)\n",
    "# Now `loaded_model` is an instance of `SimpleLSTM` with the state and config loaded\n",
    "\n",
    "model = loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset Loading and train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('dataset/15000/pkl')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkls_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631806\n"
     ]
    }
   ],
   "source": [
    "from scr.dataset import ProcessedHangmanDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "from scr.model_training import *\n",
    "\n",
    "# # Load the dataset\n",
    "processed_dataset = ProcessedHangmanDataset(pkls_dir, \\\n",
    "    char_frequency, max_word_length, samples_limit=None)\n",
    "print(len(processed_dataset)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['gratulat_rily', 'gratulat_rily'],\n",
       " ['m', 'o'],\n",
       " {'word': 'gratulatorily',\n",
       "  'initial_state': 'gratulat_rily',\n",
       "  'game_state': 'lateRevealed',\n",
       "  'difficulty': 'hard',\n",
       "  'outcome': 'win',\n",
       "  'word_length': '13'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PyTorch dataset to a list for train_test_split\n",
    "dataset_list = [processed_dataset[i] for i in range(len(processed_dataset))]\n",
    "\n",
    "# Perform an 80%-20% train-test split\n",
    "train_data, val_data = train_test_split(dataset_list, \\\n",
    "    test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "del dataset_list\n",
    "\n",
    "batch_size = 128 # hyperparams\n",
    "\n",
    "custom_sampler = ProportionalWordLengthSampler(train_data, batch_size)\n",
    "train_loader = DataLoader(train_data, batch_sampler=custom_sampler, \\\n",
    "    collate_fn=processed_dataset.custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for batch in train_loader:\n",
    "    i = i + 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/sayem/Desktop/Hangman/2_training_notebook.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sayem/Desktop/Hangman/2_training_notebook.ipynb#Y106sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m5\u001b[39m:  \u001b[39m# Check the first 5 batches\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sayem/Desktop/Hangman/2_training_notebook.ipynb#Y106sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sayem/Desktop/Hangman/2_training_notebook.ipynb#Y106sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m plot_word_length_distribution(batch, i)\n",
      "\u001b[1;32m/home/sayem/Desktop/Hangman/2_training_notebook.ipynb Cell 15\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sayem/Desktop/Hangman/2_training_notebook.ipynb#Y106sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_word_length_distribution\u001b[39m(batch, batch_idx):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sayem/Desktop/Hangman/2_training_notebook.ipynb#Y106sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     word_lengths \u001b[39m=\u001b[39m [info[\u001b[39m'\u001b[39m\u001b[39mword_length\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m _, _, info \u001b[39min\u001b[39;00m batch]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sayem/Desktop/Hangman/2_training_notebook.ipynb#Y106sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     counter \u001b[39m=\u001b[39m Counter(word_lengths)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sayem/Desktop/Hangman/2_training_notebook.ipynb#Y106sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     plt\u001b[39m.\u001b[39mbar(counter\u001b[39m.\u001b[39mkeys(), counter\u001b[39m.\u001b[39mvalues())\n",
      "\u001b[1;32m/home/sayem/Desktop/Hangman/2_training_notebook.ipynb Cell 15\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sayem/Desktop/Hangman/2_training_notebook.ipynb#Y106sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_word_length_distribution\u001b[39m(batch, batch_idx):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sayem/Desktop/Hangman/2_training_notebook.ipynb#Y106sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     word_lengths \u001b[39m=\u001b[39m [info[\u001b[39m'\u001b[39m\u001b[39mword_length\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m _, _, info \u001b[39min\u001b[39;00m batch]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sayem/Desktop/Hangman/2_training_notebook.ipynb#Y106sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     counter \u001b[39m=\u001b[39m Counter(word_lengths)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sayem/Desktop/Hangman/2_training_notebook.ipynb#Y106sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     plt\u001b[39m.\u001b[39mbar(counter\u001b[39m.\u001b[39mkeys(), counter\u001b[39m.\u001b[39mvalues())\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "def plot_word_length_distribution(batch, batch_idx):\n",
    "    word_lengths = [info['word_length'] for _, _, info in batch]\n",
    "    counter = Counter(word_lengths)\n",
    "    plt.bar(counter.keys(), counter.values())\n",
    "    plt.title(f\"Word Length Distribution in Batch {batch_idx}\")\n",
    "    plt.xlabel(\"Word Length\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "# Iterate over a few batches\n",
    "for i, batch in enumerate(train_loader):\n",
    "    if i >= 5:  # Check the first 5 batches\n",
    "        break\n",
    "    plot_word_length_distribution(batch, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Data Balance Sanity check\n",
    "# from scr.dataset import *\n",
    "\n",
    "# analyze_dataset_sanity(processed_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Data Balance Sanity check\n",
    "# from scr.dataset import *\n",
    "\n",
    "# analyze_word_length_balance(processed_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Untrained Model Performence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = processed_dataset.create_val_loader(val_data)\n",
    "\n",
    "# Call the validation function\n",
    "validation_results = validate_hangman(model, val_loader, \\\n",
    "    char_frequency, max_word_length, device)\n",
    "\n",
    "# Access the results\n",
    "character_level_results = validation_results[\"character_level\"]\n",
    "game_simulation_results = validation_results[\"game_simulation\"]\n",
    "\n",
    "from scr.plot_utils import *\n",
    "\n",
    "save_path = Path(f\"plots/{batch_size}_{NUM_STRATIFIED_SAMPLES}_untrained_model_performence_word_stats_plot.png\")\n",
    "plot_word_stats(game_simulation_results[\"length_stats\"], save_path)\n",
    "\n",
    "# # Print results for character-level validation\n",
    "# print(\"Character Level Validation:\")\n",
    "print(f\"Average Loss: {character_level_results['avg_loss']}\")\n",
    "print(f\"Miss Penalty: {character_level_results['avg_miss_penalty']}\")\n",
    "# print(f\"Character Accuracy: {character_level_results['char_accuracy']}\")\n",
    "# print(f\"Word Accuracy: {character_level_results['word_accuracy']}\")\n",
    "# print(\"Word Statistics:\", character_level_results[\"word_stats\"])  # Updated key\n",
    "\n",
    "# # Print results for game simulation\n",
    "# print(\"\\nGame Simulation:\")\n",
    "print(f\"Win Rate: {game_simulation_results['win_rate']}\")\n",
    "print(f\"Average Attempts: {game_simulation_results['average_attempts']}\")\n",
    "print(f\"Total Games: {game_simulation_results['total_games']}\")\n",
    "print(f\"Total Wins: {game_simulation_results['total_wins']}\")\n",
    "print(f\"Total Losses: {game_simulation_results['total_losses']}\")\n",
    "# print(\"Word Stats:\", game_simulation_results[\"game_stats\"])\n",
    "# print(\"Word Length Stats:\", game_simulation_results[\"length_stats\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "def train_model(model, train_loader, val_loader, \\\n",
    "    num_epochs, optimizer, scheduler=None, device=device):\n",
    "    # train_loader = DataLoader(train_data, batch_size=batch_size, \\\n",
    "    #     collate_fn=custom_collate_fn)\n",
    "    # val_loader = DataLoader(val_data, batch_size=batch_size, \\\n",
    "    #     collate_fn=custom_collate_fn)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_miss_penalty = train_on_data_loader(model, train_loader, device, optimizer)\n",
    "        \n",
    "        validation_results = validate_hangman(model, val_loader, \\\n",
    "            char_frequency, max_word_length, device)\n",
    "\n",
    "        # Access the results\n",
    "        character_level_results = validation_results[\"character_level\"]\n",
    "        game_simulation_results = validation_results[\"game_simulation\"]\n",
    "\n",
    "        # scheduler.step(val_loss)  # Adjust LR based on validation loss\n",
    "\n",
    "        print(f\"Epoch {epoch}: Training Loss: {train_loss}, Miss Penalty: \\\n",
    "{train_miss_penalty}, Validation Loss: {character_level_results['avg_loss']}, \\\n",
    "Validation Miss Penalty: {character_level_results['avg_miss_penalty']}, Validation win rate: {game_simulation_results['win_rate']}\")\n",
    "        # Save model checkpoints if needed\n",
    "\n",
    "\n",
    "train_model(model, train_loader, val_loader, num_epochs, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# import torch\n",
    "# from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# def train_model(model, train_data, val_data, num_epochs, optimizer, scheduler, device):\n",
    "#     train_loader = DataLoader(train_data, batch_size=batch_size, \\\n",
    "#         collate_fn=custom_collate_fn)\n",
    "#     val_loader = DataLoader(val_data, batch_size=batch_size, \\\n",
    "#         collate_fn=custom_collate_fn)\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         train_loss, train_miss_penalty = train_epoch(model, train_loader, \\\n",
    "#             optimizer, device)\n",
    "#         val_loss, val_miss_penalty = validate_epoch(model, \\\n",
    "#             val_loader, device)\n",
    "\n",
    "#         scheduler.step(val_loss)  # Adjust LR based on validation loss\n",
    "\n",
    "#         print(f\"Epoch {epoch}: Training Loss: {train_loss}, Miss Penalty: \\\n",
    "#             {train_miss_penalty}, Validation Loss: {val_loss}, Validation Miss Penalty: {val_miss_penalty}\")\n",
    "#         # Save model checkpoints if needed\n",
    "\n",
    "# def k_fold_cross_validate(model, dataset, k, num_epochs, optimizer, scheduler_class, device):\n",
    "#     kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "#     for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "#         print(f\"Fold {fold}\")\n",
    "#         train_subset = Subset(dataset, train_idx)\n",
    "#         val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "#         # Initialize a new model for each fold\n",
    "#         model = SimpleLSTM(config)\n",
    "#         model.to(device)\n",
    "#         optimizer = model.optimizer\n",
    "#         scheduler = scheduler_class(optimizer)\n",
    "\n",
    "#         train_subset = Subset(dataset, train_idx)\n",
    "#         val_subset = Subset(dataset, val_idx)\n",
    "#         train_model(model, train_subset, val_subset, num_epochs, optimizer, scheduler, device)\n",
    "\n",
    "\n",
    "#         train_model(model, train_subset, val_subset, num_epochs, optimizer, scheduler, device)\n",
    "\n",
    "# # Usage example\n",
    "# num_epochs = 10\n",
    "# batch_size = 64\n",
    "# scheduler_class = torch.optim.lr_scheduler.ReduceLROnPlateau  # Example scheduler class\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# k_fold_cross_validate(model, processed_dataset, \\\n",
    "#     5, num_epochs, optimizer, scheduler_class, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trained Model Performence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = processed_dataset.create_val_loader(val_data)\n",
    "\n",
    "\n",
    "# Call the validation function\n",
    "validation_results = validate_hangman(model, val_loader, \\\n",
    "    char_frequency, max_word_length, device)\n",
    "\n",
    "# Access the results\n",
    "character_level_results = validation_results[\"character_level\"]\n",
    "game_simulation_results = validation_results[\"game_simulation\"]\n",
    "\n",
    "from scr.plot_utils import *\n",
    "\n",
    "save_path = Path(f\"plots/{batch_size}_{NUM_STRATIFIED_SAMPLES}_trained_model_performence_word_stats_plot.png\")\n",
    "plot_word_stats(game_simulation_results[\"length_stats\"], save_path)\n",
    "\n",
    "# # Print results for character-level validation\n",
    "# print(\"Character Level Validation:\")\n",
    "print(f\"Average Loss: {character_level_results['avg_loss']}\")\n",
    "print(f\"Miss Penalty: {character_level_results['avg_miss_penalty']}\")\n",
    "# print(f\"Character Accuracy: {character_level_results['char_accuracy']}\")\n",
    "# print(f\"Word Accuracy: {character_level_results['word_accuracy']}\")\n",
    "# print(\"Word Statistics:\", character_level_results[\"word_stats\"])  # Updated key\n",
    "\n",
    "# # Print results for game simulation\n",
    "# print(\"\\nGame Simulation:\")\n",
    "print(f\"Win Rate: {game_simulation_results['win_rate']}\")\n",
    "print(f\"Average Attempts: {game_simulation_results['average_attempts']}\")\n",
    "print(f\"Total Games: {game_simulation_results['total_games']}\")\n",
    "print(f\"Total Wins: {game_simulation_results['total_wins']}\")\n",
    "print(f\"Total Losses: {game_simulation_results['total_losses']}\")\n",
    "# print(\"Word Stats:\", game_simulation_results[\"game_stats\"])\n",
    "# print(\"Word Length Stats:\", game_simulation_results[\"length_stats\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_features_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_features_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, device):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "    total_miss_penalty = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        if batch[0] is None:\n",
    "            continue  # Skip empty batches\n",
    "\n",
    "        game_states_batch, lengths_batch, missed_chars_batch, labels_batch = batch\n",
    "        game_states_batch, lengths_batch, missed_chars_batch = \\\n",
    "            game_states_batch.to(device), lengths_batch, missed_chars_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(game_states_batch, lengths_batch, missed_chars_batch)\n",
    "        model_output_shape = outputs.shape\n",
    "        reshaped_labels = pad_and_reshape_labels(labels_batch, model_output_shape).to(device)\n",
    "\n",
    "        loss, miss_penalty = model.calculate_loss(outputs, reshaped_labels, \\\n",
    "                                                  lengths_batch, missed_chars_batch, 27)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_miss_penalty += miss_penalty.item()  # Accumulate miss penalty\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    avg_miss_penalty = total_miss_penalty / len(data_loader)\n",
    "    return avg_loss, avg_miss_penalty  # Return average loss and miss penalty\n",
    "\n",
    "\n",
    "\n",
    "def validate_epoch(model, data_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    total_miss_penalty = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            if batch[0] is None:\n",
    "                continue  # Skip empty batches\n",
    "\n",
    "\n",
    "            game_states_batch, lengths_batch, missed_chars_batch, labels_batch = batch\n",
    "            game_states_batch, lengths_batch, missed_chars_batch = \\\n",
    "                game_states_batch.to(device), lengths_batch, missed_chars_batch.to(device)\n",
    "\n",
    "            outputs = model(game_states_batch, lengths_batch, missed_chars_batch)\n",
    "            model_output_shape = outputs.shape\n",
    "            reshaped_labels = pad_and_reshape_labels(labels_batch, model_output_shape).to(device)\n",
    "\n",
    "            loss, miss_penalty = model.calculate_loss(outputs, reshaped_labels, \\\n",
    "                                                      lengths_batch, missed_chars_batch, 27)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            total_miss_penalty += miss_penalty.item()  # Accumulate miss penalty\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    avg_miss_penalty = total_miss_penalty / len(data_loader)\n",
    "    return avg_loss, avg_miss_penalty  # \n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "#     val_loss = validate_epoch(model, val_loader, device)\n",
    "    \n",
    "#     print(f\"Epoch {epoch}: Training Loss: {train_loss}, Validation Loss: {val_loss}\")\n",
    "#     # You can add code to save model checkpoints if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "def train_model(model, train_data, val_data, num_epochs, optimizer, scheduler, device):\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, \\\n",
    "        collate_fn=custom_collate_fn)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, \\\n",
    "        collate_fn=custom_collate_fn)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_miss_penalty = train_epoch(model, train_loader, \\\n",
    "            optimizer, device)\n",
    "        val_loss, val_miss_penalty = validate_epoch(model, \\\n",
    "            val_loader, device)\n",
    "\n",
    "        scheduler.step(val_loss)  # Adjust LR based on validation loss\n",
    "\n",
    "        print(f\"Epoch {epoch}: Training Loss: {train_loss}, Miss Penalty: \\\n",
    "            {train_miss_penalty}, Validation Loss: {val_loss}, Validation Miss Penalty: {val_miss_penalty}\")\n",
    "        # Save model checkpoints if needed\n",
    "\n",
    "def k_fold_cross_validate(model, dataset, k, num_epochs, optimizer, scheduler_class, device):\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "        print(f\"Fold {fold}\")\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "        # Initialize a new model for each fold\n",
    "        model = SimpleLSTM(config)\n",
    "        model.to(device)\n",
    "        optimizer = model.optimizer\n",
    "        scheduler = scheduler_class(optimizer)\n",
    "\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "        train_model(model, train_subset, val_subset, num_epochs, optimizer, scheduler, device)\n",
    "\n",
    "\n",
    "        train_model(model, train_subset, val_subset, num_epochs, optimizer, scheduler, device)\n",
    "\n",
    "# Usage example\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "scheduler_class = torch.optim.lr_scheduler.ReduceLROnPlateau  # Example scheduler class\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "k_fold_cross_validate(model, processed_dataset, \\\n",
    "    5, num_epochs, optimizer, scheduler_class, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.dataset import ProcessedHangmanDataset\n",
    "from scr.custom_sampler import PerformanceBasedSampler\n",
    "\n",
    "\n",
    "print(f\"Total number of data points in the dataset: {len(processed_dataset)}\")\n",
    "\n",
    "# Initialize the sampler\n",
    "sampler = PerformanceBasedSampler(\n",
    "    processed_dataset, \n",
    "    performance_metrics,\n",
    "    max_word_length=max_word_length\n",
    ")\n",
    "\n",
    "print(f\"Sampler created with {len(sampler)} indices.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices = list(sampler)[:10]  # Get the first 10 sampled indices\n",
    "print(\"Sampled indices:\", sample_indices)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    data_point = processed_dataset[idx]\n",
    "    print(f\"Data at index {idx}: {data_point}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.utils import print_scenarios\n",
    "\n",
    "def process_pkl_files(base_dir):\n",
    "    pkl_list = []\n",
    "\n",
    "    # Iterate over all batch directories\n",
    "    for batch_dir in sorted(base_dir.iterdir(), key=lambda x: int(x.name) if x.name.isdigit() else float('inf')):\n",
    "        if batch_dir.is_dir():\n",
    "            # List all .pkl files in the current batch directory\n",
    "            pkl_files = list(batch_dir.glob(\"*.pkl\"))\n",
    "\n",
    "            for pkl_file in pkl_files:\n",
    "                try:\n",
    "                    with open(pkl_file, 'rb') as file:\n",
    "                        game_data = pickle.load(file)\n",
    "                except IOError as e:\n",
    "                    print(f\"Error reading file {pkl_file}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                # Processing each pickle file\n",
    "                pkl_list.extend(process_pkl_file(pkl_file, game_data))\n",
    "\n",
    "    return pkl_list\n",
    "\n",
    "def process_pkl_file(pkl_file, game_data):\n",
    "    file_scenarios = []\n",
    "    for data in game_data:\n",
    "        game_won, guesses = data\n",
    "        word, initial_state, difficulty, outcome = extract_info_from_filename(pkl_file)\n",
    "        \n",
    "        # Create a scenario dictionary for each data tuple\n",
    "        scenario = {\n",
    "            'word': word,\n",
    "            'difficulty': difficulty,\n",
    "            'outcome': outcome,\n",
    "            'data': (game_won, guesses)\n",
    "        }\n",
    "        file_scenarios.append((pkl_file, scenario))  # Add scenario to the list\n",
    "\n",
    "    return file_scenarios\n",
    "\n",
    "def extract_info_from_filename(pkl_file):\n",
    "    parts = pkl_file.stem.split('_from_')\n",
    "    word_and_state = parts[0].split('_')\n",
    "    word = '_'.join(word_and_state[:-1])\n",
    "    initial_state = word_and_state[-1]\n",
    "    difficulty, outcome = parts[1].split('_')[-2:]\n",
    "    return word, initial_state, difficulty, outcome\n",
    "\n",
    "# def print_scenarios(scenarios):\n",
    "#     # Assuming this function is defined elsewhere\n",
    "#     pass\n",
    "\n",
    "# Process all pickle files\n",
    "pkl_list = process_pkl_files(base_dataset_dir)\n",
    "\n",
    "# Accessing an individual pickle file's content by index\n",
    "index_to_access = 0  # Change this index to access different files\n",
    "if index_to_access < len(pkl_list):\n",
    "    file_path, scenario = pkl_list[index_to_access]\n",
    "    print(f\"Contents of {file_path}:\")\n",
    "    print_scenarios([scenario])  # Wrap scenario in a list for the function\n",
    "else:\n",
    "    print(f\"No pickle file at index {index_to_access}\")\n",
    "\n",
    "No pickle file at index 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_list = []\n",
    "\n",
    "# Iterate over all batch directories\n",
    "for batch_dir in sorted(base_dataset_dir.iterdir(), \\\n",
    "    key=lambda x: int(x.name) if x.name.isdigit() else float('inf')):\n",
    "    if batch_dir.is_dir():\n",
    "        # List all .pkl files in the current batch directory\n",
    "        pkl_files = list(batch_dir.glob(\"*.pkl\"))\n",
    "\n",
    "        for pkl_file in pkl_files:\n",
    "            with open(pkl_file, 'rb') as file:\n",
    "                game_data = pickle.load(file)\n",
    "                # Extract information from file name\n",
    "                parts = pkl_file.stem.split('_from_')\n",
    "                word_and_statet = parts[0].split('_')\n",
    "                word = '_'.join(word_and_state[:-1])\n",
    "                initial_state = word_and_state[-1]\n",
    "                difficulty, outcome = parts[1].split('_')[-2:]\n",
    "\n",
    "                # Assuming game_data is a list of tuples (game_won, guesses)\n",
    "                for data in game_data:\n",
    "                    game_won, guesses = data\n",
    "                    # Create a scenario dictionary for each data tuple\n",
    "                    scenario = {\n",
    "                        'word': word,\n",
    "                        'difficulty': difficulty,\n",
    "                        'outcome': outcome,\n",
    "                        'data': (game_won, guesses)\n",
    "                    }\n",
    "                    pkl_list.append((pkl_file, scenario))  # Add scenario to the list\n",
    "\n",
    "# Accessing an individual pickle file's content by index\n",
    "index_to_access = 0  # Change this index to access different files\n",
    "if index_to_access < len(pkl_list):\n",
    "    file_path, scenario = pkl_list[index_to_access]\n",
    "    print(f\"Contents of {file_path}:\")\n",
    "    print_scenarios([scenario])  # Wrap scenario in a list for the function\n",
    "else:\n",
    "    print(f\"No pickle file at index {index_to_access}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optiver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
