{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "import random\n",
    "from collections import Counter\n",
    "from scr.utils import read_words\n",
    "import gc\n",
    "\n",
    "\n",
    "import sys\n",
    "# Custom library paths\n",
    "sys.path.extend(['../', './scr'])\n",
    "\n",
    "from scr.utils import set_seed\n",
    "from scr.utils import read_words\n",
    "\n",
    "# set_seed(42)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Reading and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from scr.utils import *\n",
    "\n",
    "NUM_STRATIFIED_SAMPLES = 1000\n",
    "\n",
    "# # Check current working directory\n",
    "# current_dir = os.getcwd()\n",
    "# print(\"Current Working Directory:\", current_dir)\n",
    "\n",
    "# Define the base directory where you want to save the dataset\n",
    "base_dataset_dir = Path(f'./dataset/{NUM_STRATIFIED_SAMPLES}')\n",
    "# Ensure the base directory exists\n",
    "base_dataset_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pkls_dir = base_dataset_dir / 'pkl'\n",
    "pkls_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Adjust these paths if necessary\n",
    "train_words_path = base_dataset_dir / 'train_words.txt'\n",
    "test_words_path = base_dataset_dir / 'test_words.txt'\n",
    "val_words_path = base_dataset_dir / 'val_words.txt'\n",
    "\n",
    "# Check if files exist before reading\n",
    "if train_words_path.exists():\n",
    "    train_words = read_words(train_words_path)\n",
    "else:\n",
    "    print(f\"File not found: {train_words_path}\")\n",
    "\n",
    "if test_words_path.exists():\n",
    "    test_words = read_words(test_words_path)\n",
    "else:\n",
    "    print(f\"File not found: {test_words_path}\")\n",
    "\n",
    "if val_words_path.exists():\n",
    "    val_words = read_words(val_words_path)\n",
    "else:\n",
    "    print(f\"File not found: {val_words_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing Single Word inferece Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For inference\n",
    "from scr.feature_engineering import *\n",
    "\n",
    "# from scr.feature_engineering import build_feature_set, \\\n",
    "#     process_single_word_inference, calculate_char_frequencies, \\\n",
    "#         calculate_word_frequencies\n",
    "from scr.utils import *\n",
    "\n",
    "word_list = read_words('data/words_250000_train.txt')\n",
    "word_frequencies = calculate_word_frequencies(word_list)\n",
    "char_frequency = calculate_char_frequencies(word_list)\n",
    "max_word_length = max(len(word) for word in word_list)\n",
    "\n",
    "# Example usage\n",
    "# Example usage\n",
    "game_state = \"_pp_e\"\n",
    "max_seq_length = 6  # Set this to the maximum number of turns in your game\n",
    "\n",
    "# Now include max_seq_length in the function call\n",
    "# for testing the function\n",
    "sequence_features, sequence_missed_chars = \\\n",
    "    process_game_sequence([game_state], char_frequency, max_word_length, max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_missed_chars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_missed_characters([game_state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "# Reshaping to separate features\n",
    "reshaped_features = sequence_features.view(batch_size, max_seq_length, max_word_length, -1)\n",
    "# Extracting the character indices\n",
    "char_indices = reshaped_features[:, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of processing a batch of games\n",
    "batch_of_games = [['_ppl_']]\n",
    "char_frequency = calculate_char_frequencies(word_list)\n",
    "max_word_length = max_word_length  # Assuming this is the maximum word length\n",
    "max_seq_length = max_seq_length  # Maximum number of states (guesses) per game\n",
    "\n",
    "# Example of processing a batch of games\n",
    "batch_features, batch_missed_characters = process_batch_of_games(batch_of_games, \\\n",
    "    char_frequency, max_word_length, max_seq_length)\n",
    "print(batch_features.shape)  # Expected shape: [2, 6, max_word_length * num_features]\n",
    "print(batch_missed_characters.shape)  # Expected shape: [2, 6, len(char_to_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 1\n",
    "# # Reshaping to separate features\n",
    "# reshaped_features = batch_features.view(batch_size, max_seq_length, max_word_length, -1)\n",
    "# # Extracting the character indices\n",
    "# char_indices = reshaped_features[:, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of processing a batch of games\n",
    "batch_of_games = [['_ppl_', 'appl_', 'apple'], ['_a__l_', 'ba__l_', 'ball_'], ['_a__l_', 'ba__l_', 'ball_']]\n",
    "# batch_of_games = [['_ppl_']]\n",
    "batch_size = len(batch_of_games)\n",
    "char_frequency = calculate_char_frequencies(word_list)\n",
    "max_word_length = max_word_length  # Assuming this is the maximum word length\n",
    "max_seq_length = max_seq_length  # Maximum number of states (guesses) per game\n",
    "\n",
    "# Example of processing a batch of games\n",
    "batch_features, batch_missed_characters \\\n",
    "    = process_batch_of_games(batch_of_games, \\\n",
    "        char_frequency, max_word_length, max_seq_length)\n",
    "print(batch_features.shape)  # Expected shape: [2, 6, max_word_length * num_features]\n",
    "print(batch_missed_characters.shape)  # Expected shape: [2, 6, len(char_to_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping to separate features\n",
    "reshaped_features = batch_features.view(batch_size, \\\n",
    "    max_seq_length, max_word_length, -1)\n",
    "# Extracting the character indices\n",
    "char_indices = reshaped_features[:, :, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# # Mock input dimensions\n",
    "# batch_size = 2\n",
    "# max_seq_length = 6\n",
    "# max_word_length = 5\n",
    "# num_features = 5  # Number of features per word (excluding character index)\n",
    "# vocab_size = 27  # Assuming vocabulary size of 26 letters + 1 for padding/unknown\n",
    "\n",
    "# # Creating mock input data\n",
    "# batch_features = torch.rand(batch_size, max_seq_length, max_word_length * num_features)  # Expected shape: [batch size, max seq len, max_word_length * num_features]\n",
    "# x_lens = torch.tensor([max_seq_length] * batch_size, dtype=torch.long)  # Assuming all sequences have max length\n",
    "# miss_chars = torch.rand(batch_size, max_seq_length, vocab_size)  # Expected shape: [batch size, max seq len, len(char_to_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# # Mock input dimensions\n",
    "# batch_size = 1\n",
    "# max_seq_length = 6\n",
    "vocab_size = 27  # Assuming vocabulary size of 26 letters + 1 for padding/unknown\n",
    "\n",
    "# Function to generate random labels\n",
    "def generate_dummy_labels(batch_size, max_seq_length, vocab_size):\n",
    "    labels = torch.zeros(batch_size, max_seq_length, vocab_size)\n",
    "    for i in range(batch_size):\n",
    "        for j in range(max_seq_length):\n",
    "            # Randomly select a character index for each game state\n",
    "            char_idx = torch.randint(0, vocab_size, (1,))\n",
    "            labels[i, j, char_idx] = 1  # Set the corresponding character position to 1\n",
    "    return labels\n",
    "\n",
    "# Generate dummy labels\n",
    "dummy_labels = generate_dummy_labels(batch_size, max_seq_length, vocab_size)\n",
    "# print(dummy_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_missed_characters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lens = torch.tensor([max_seq_length] * batch_size, dtype=torch.long)\n",
    "\n",
    "x_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.simple_model import SimpleLSTM\n",
    "\n",
    "# Instantiate and test the model\n",
    "config = {\n",
    "    'embedding_dim': 200,\n",
    "    'hidden_dim': 256,\n",
    "    'num_layers': 2,\n",
    "    'vocab_size': 27,\n",
    "    'max_word_length': max_word_length,\n",
    "    'input_feature_size': 5,\n",
    "    'use_embedding': True,\n",
    "    'miss_linear_dim': 50\n",
    "}\n",
    "\n",
    "model = SimpleLSTM(config)\n",
    "output = model(batch_features, x_lens, batch_missed_characters)\n",
    "with torch.no_grad():\n",
    "    output = model(batch_features, x_lens, batch_missed_characters)\n",
    "    print(\"Output shape:\", output.shape)\n",
    "\n",
    "model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming the same dimensions as your batch_features and x_lens\n",
    "batch_size = batch_features.size(0)\n",
    "print(f'batch size: ', batch_size)\n",
    "seq_len = max(x_lens)\n",
    "print(f'len seq: ', seq_len)\n",
    "\n",
    "# Generate random labels\n",
    "# The labels are integers in the range [0, vocab_size - 1]\n",
    "labels = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
    "\n",
    "# print(f'labels: ', labels.shape)\n",
    "\n",
    "# Ensure labels are on the same device as the model\n",
    "labels = labels.to(model.device)\n",
    "\n",
    "# Now calculate the loss using the model's calculate_loss method\n",
    "loss, miss_penalty = model.calculate_loss(output, output, \\\n",
    "    x_lens, batch_missed_characters, vocab_size)\n",
    "print(f\"Loss: {loss.item()}, Miss Penalty: {miss_penalty.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of processing a batch of games\n",
    "batch_of_games = [['apple']]\n",
    "char_frequency = calculate_char_frequencies(word_list)\n",
    "max_word_length = max_word_length  # Assuming this is the maximum word length\n",
    "max_seq_length = max_seq_length  # Maximum number of states (guesses) per game\n",
    "batch_size = len(batch_of_games)\n",
    "print(f'batch size: ', batch_size)\n",
    "# Example of processing a batch of games\n",
    "batch_features, batch_missed_characters = process_batch_of_games(batch_of_games, \\\n",
    "    char_frequency, max_word_length, max_seq_length)\n",
    "print(batch_features.shape)  # Expected shape: [2, 6, max_word_length * num_features]\n",
    "print(batch_missed_characters.shape)  # Expected shape: [2, 6, len(char_to_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming each game in the batch has the same number of turns\n",
    "number_of_turns_per_game = 6  # replace with the actual number if different\n",
    "\n",
    "# # Create x_lens tensor\n",
    "x_lens = torch.tensor([number_of_turns_per_game] * batch_size)\n",
    "print(x_lens)\n",
    "with torch.no_grad():\n",
    "    # Call the forward method\n",
    "    output = model(batch_features, x_lens, batch_missed_characters)\n",
    "\n",
    "print(\"Output Shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.game import guess_character, guess\n",
    "\n",
    "# Define the game state\n",
    "game_state = '___'  # The current state of the word being guessed\n",
    "\n",
    "# Define dummy guessed letters (if any have been guessed)\n",
    "guessed_letters = []  # No letters guessed yet\n",
    "\n",
    "# Call the guess function\n",
    "char = guess(model, game_state, char_frequency, \\\n",
    "        max_word_length, device, guessed_letters)\n",
    "\n",
    "# Print the guessed character\n",
    "print(\"Guessed Character:\", char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Playing Games Untrain NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.game import play_game_with_a_word\n",
    "game_state = 'apple'\n",
    "won, final_word, attempts = play_game_with_a_word(model, game_state, char_frequency, \\\n",
    "    max_word_length, device, max_attempts=6, normalize=True)\n",
    "\n",
    "print(won, final_word, attempts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['apple', 'kale', 'moon', 'missisippi']\n",
    "set_seed(42)\n",
    "\n",
    "# Model interacting with my/dummy api\n",
    "# For validation\n",
    "for word in words:\n",
    "    print(word)\n",
    "    won, final_word, attempts = play_game_with_a_word(\n",
    "        model, word, char_frequency, \\\n",
    "        max_word_length, device, max_attempts=6, normalize=True)\n",
    "\n",
    "    print(won, final_word, attempts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building Dataset From States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_list = []\n",
    "\n",
    "for batch_dir in sorted(pkls_dir.iterdir(), key=lambda x: int(x.name) \\\n",
    "    if x.name.isdigit() else float('inf')):\n",
    "    if batch_dir.is_dir():\n",
    "        pkl_files = list(batch_dir.glob(\"*.pkl\"))\n",
    "\n",
    "        for pkl_file in pkl_files:\n",
    "            with open(pkl_file, 'rb') as file:\n",
    "                game_data = pickle.load(file)\n",
    "\n",
    "                # print(game_data)\n",
    "\n",
    "                # Splitting the file name\n",
    "                parts = pkl_file.stem.split('_from_')\n",
    "                word = parts[0]  # Extracting the word\n",
    "                # Further splitting to extract initial state, difficulty, and outcome\n",
    "                remaining = parts[1].split('_')\n",
    "                initial_state = '_'.join(remaining[:-2])  # Joining to form the initial state\n",
    "                # print(initial_state)\n",
    "                difficulty, outcome = remaining[-2], remaining[-1]\n",
    "\n",
    "                for data in game_data:\n",
    "                    game_won, guesses = data\n",
    "                    scenario = {\n",
    "                        'word': word,\n",
    "                        'initial_state': initial_state,\n",
    "                        'difficulty': difficulty,\n",
    "                        'outcome': outcome,\n",
    "                        'data': (game_won, guesses)\n",
    "                    }\n",
    "                    pkl_list.append((pkl_file, scenario))\n",
    "\n",
    "index_to_access = 1000\n",
    "if index_to_access < len(pkl_list):\n",
    "    file_path, scenario = pkl_list[index_to_access]\n",
    "    print(f\"Contents of {file_path}:\")\n",
    "    print()\n",
    "    print_scenarios([scenario])\n",
    "else:\n",
    "    print(f\"No pickle file at index {index_to_access}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(pkl_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkls_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.dataset import ProcessedHangmanDataset\n",
    "\n",
    "# # Load the dataset\n",
    "processed_dataset = ProcessedHangmanDataset(pkls_dir, \\\n",
    "    char_frequency, max_word_length, mode = 'individual') # an individual game state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(processed_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.dataset import ProcessedHangmanDataset\n",
    "\n",
    "# # Load the dataset\n",
    "processed_dataset = ProcessedHangmanDataset(pkls_dir, \\\n",
    "    char_frequency, max_word_length, mode = 'sequence') # an individual game state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 1  # You can adjust this according to your requirements\n",
    "\n",
    "# Create the DataLoader\n",
    "data_loader = DataLoader(processed_dataset, \\\n",
    "    batch_size=batch_size, collate_fn=processed_dataset.collate_fn)\n",
    "\n",
    "# Now, data_loader is ready to be used in your training loop or data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_feature_sets_batch, padded_labels_batch, seq_lengths = next(iter(data_loader))\n",
    "padded_feature_sets_batch.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_feature_sets_batch, padded_labels_batch, seq_lengths = next(iter(data_loader))\n",
    "padded_feature_sets_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(padded_feature_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(data_loader):\n",
    "    print(batch[0][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_on_data_loader(model, data_loader, device=device):\n",
    "    total_actual_penalty = 0\n",
    "    total_miss_penalty = 0\n",
    "    total_batches = 0\n",
    "\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        inputs, labels, miss_chars, lengths, original_words = batch\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        miss_chars = miss_chars.to(device)\n",
    "        # lengths = lengths.to(device)  # Uncomment this if lengths need to be on the device\n",
    "\n",
    "        outputs = model(inputs, lengths, miss_chars)\n",
    "       \n",
    "        actual_penalty, miss_penalty = model.calculate_loss(outputs, labels, \\\n",
    "            lengths, miss_chars, vocab_size=27)\n",
    "\n",
    "    \n",
    "        total_actual_penalty += actual_penalty.item()\n",
    "        total_miss_penalty += miss_penalty.item()\n",
    "        total_batches += 1\n",
    "\n",
    "        model.optimizer.zero_grad()\n",
    "        actual_penalty.backward()\n",
    "        model.optimizer.step()\n",
    "\n",
    "    avg_actual_penalty = total_actual_penalty / total_batches \\\n",
    "        if total_batches > 0 else 0\n",
    "    avg_miss_penalty = total_miss_penalty / total_batches \\\n",
    "        if total_batches > 0 else 0\n",
    "    return avg_actual_penalty, avg_miss_penalty\n",
    "\n",
    "\n",
    "    avg_actual_penalty = total_actual_penalty / total_batches \\\n",
    "        if total_batches > 0 else 0\n",
    "    avg_miss_penalty = total_miss_penalty / total_batches \\\n",
    "        if total_batches > 0 else 0\n",
    "    return avg_actual_penalty, avg_miss_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def validate_model_on_dataset(model, val_words, char_frequency, \\\n",
    "    max_word_length, device, max_attempts=6, normalize=True, \\\n",
    "        number_of_games=1000):\n",
    "    total_wins, total_attempts, total_games = 0, 0, 0\n",
    "    word_stats = {}\n",
    "    word_length_stats = defaultdict(lambda: {\"wins\": 0, \\\n",
    "        \"losses\": 0, \"total_attempts\": 0, \"games\": 0})\n",
    "\n",
    "    for word in val_words:\n",
    "        if total_games >= number_of_games:\n",
    "            break\n",
    "\n",
    "        word_length = len(word)\n",
    "        masked_word = \"_\" * word_length\n",
    "        won, final_word, attempts = play_game_with_a_word(model, word, \\\n",
    "            char_frequency, max_word_length, device, max_attempts, normalize)\n",
    "\n",
    "        # Update word-specific stats\n",
    "        word_stats[word] = {\n",
    "            \"won\": won,\n",
    "            \"final_word\": final_word,\n",
    "            \"attempts_used\": attempts\n",
    "        }\n",
    "\n",
    "        # Update word length-specific stats\n",
    "        word_length_stats[word_length][\"games\"] += 1\n",
    "        word_length_stats[word_length][\"total_attempts\"] += attempts\n",
    "        if won:\n",
    "            word_length_stats[word_length][\"wins\"] += 1\n",
    "        else:\n",
    "            word_length_stats[word_length][\"losses\"] += 1\n",
    "\n",
    "        # Update overall stats\n",
    "        total_wins += int(won)\n",
    "        total_attempts += attempts\n",
    "        total_games += 1\n",
    "\n",
    "    win_rate = total_wins / total_games if total_games > 0 else 0\n",
    "    avg_attempts = total_attempts / total_games if total_games > 0 else 0\n",
    "\n",
    "    # Calculating detailed statistics for each word length\n",
    "    for length, stats in word_length_stats.items():\n",
    "        stats[\"win_rate\"] = stats[\"wins\"] / stats[\"games\"]\n",
    "        stats[\"avg_attempts\"] = stats[\"total_attempts\"] / stats[\"games\"]\n",
    "\n",
    "    return {\n",
    "        \"win_rate\": win_rate,\n",
    "        \"average_attempts\": avg_attempts,\n",
    "        \"total_games\": total_games,\n",
    "        \"total_wins\": total_wins,\n",
    "        \"total_losses\": total_games - total_wins,\n",
    "        \"word_stats\": word_stats,\n",
    "        \"word_length_stats\": dict(word_length_stats)  # Convert defaultdict to dict for readability\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def calculate_character_metrics(final_word, original_word):\n",
    "    true_positives, false_positives, false_negatives = defaultdict(int), \\\n",
    "        defaultdict(int), defaultdict(int)\n",
    "\n",
    "    for char in set(original_word):\n",
    "        if char in final_word:  # If the char is in the guessed word\n",
    "            if char in original_word:  # If the char is also in the original word\n",
    "                true_positives[char] += 1\n",
    "            else:\n",
    "                false_positives[char] += 1\n",
    "        else:\n",
    "            if char in original_word:  # If the char is in the original word but not in the guess\n",
    "                false_negatives[char] += 1\n",
    "\n",
    "    return true_positives, false_positives, false_negatives\n",
    "\n",
    "\n",
    "def validate_model_on_game(model, val_words, char_frequency, max_word_length, \\\n",
    "    device, max_attempts=6, normalize=True, number_of_games=1000):\n",
    "    total_wins, total_attempts, total_games = 0, 0, 0\n",
    "    word_length_stats = defaultdict(lambda: {\"wins\": 0, \"losses\": 0, \\\n",
    "            \"total_attempts\": 0, \"games\": 0})\n",
    "    word_stats = {}\n",
    "\n",
    "    for word in val_words:\n",
    "        if total_games >= number_of_games:\n",
    "            break\n",
    "\n",
    "        word_length = len(word)\n",
    "        won, final_word, attempts = play_game_with_a_word(model, word, \\\n",
    "            char_frequency, max_word_length, device, max_attempts, normalize)\n",
    "\n",
    "        # Update word-specific stats\n",
    "        word_stats[word] = {\n",
    "            \"won\": won,\n",
    "            \"final_word\": final_word,\n",
    "            \"attempts_used\": attempts\n",
    "        }\n",
    "\n",
    "        # Update word length-specific stats\n",
    "        word_length_stats[word_length][\"games\"] += 1\n",
    "        word_length_stats[word_length][\"total_attempts\"] += attempts\n",
    "        \n",
    "        if won:\n",
    "            word_length_stats[word_length][\"wins\"] += 1\n",
    "        else:\n",
    "            word_length_stats[word_length][\"losses\"] += 1\n",
    "\n",
    "        # Update overall stats\n",
    "        total_wins += int(won)\n",
    "        total_attempts += attempts\n",
    "        total_games += 1\n",
    "\n",
    "    win_rate = total_wins / total_games if total_games > 0 else 0\n",
    "    avg_attempts = total_attempts / total_games if total_games > 0 else 0\n",
    "\n",
    "    # Calculating detailed statistics for each word length\n",
    "    for length, stats in word_length_stats.items():\n",
    "        stats[\"win_rate\"] = stats[\"wins\"] / stats[\"games\"]\n",
    "        stats[\"avg_attempts\"] = stats[\"total_attempts\"] / stats[\"games\"]\n",
    "\n",
    "    return {\n",
    "        \"win_rate\": win_rate,\n",
    "        \"average_attempts\": avg_attempts,\n",
    "        \"total_games\": total_games,\n",
    "        \"total_wins\": total_wins,\n",
    "        \"total_losses\": total_games - total_wins,\n",
    "        \"word_stats\": word_stats,\n",
    "        \"word_length_stats\": dict(word_length_stats)  # Convert defaultdict to dict for readability\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Performence testing of Untrain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scr.plot_utils import plot_word_stats\n",
    "\n",
    "# validation_on_dataset = validate_model_on_dataset(model, val_words, \\\n",
    "#     char_frequency, max_word_length, device, max_attempts=6, \\\n",
    "#         normalize=True, number_of_games=1000)\n",
    "\n",
    "# # Example usage\n",
    "# # epoch_number = 1\n",
    "# save_path = 'plots/untrain_model_stats.png'  # Example custom path\n",
    "# plot_word_stats(validation_on_dataset['word_length_stats'], save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(num_epochs), desc='Epochs'):\n",
    "\n",
    "    epoch_performance_metrics = {}\n",
    "    total_actual_penalty, total_miss_penalty = 0, 0\n",
    "    total_batches = 0  # Counter for the total number of batches\n",
    "\n",
    "    for pkl_file in tqdm(pkl_files, desc='PKL Files', leave=False):\n",
    "        try:\n",
    "            with open(pkl_file, 'rb') as file:\n",
    "                train_dataset = pickle.load(file)\n",
    "\n",
    "            sampler = PerformanceBasedSampler(train_dataset, initial_performance_metrics)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, \\\n",
    "                sampler=sampler, collate_fn=collate_fn)\n",
    "\n",
    "            for batch in train_loader:\n",
    "                avg_actual_penalty, avg_miss_penalty = train_on_batch(model, batch, device)\n",
    "                total_actual_penalty += avg_actual_penalty\n",
    "                total_miss_penalty += avg_miss_penalty\n",
    "                total_batches += 1  # Increment the batch counter\n",
    "\n",
    "            # Aggregate metrics for the current .pkl file\n",
    "            pkl_file_name = pkl_file.stem\n",
    "            epoch_performance_metrics[pkl_file_name] = {\n",
    "                'avg_actual_penalty': avg_actual_penalty,\n",
    "                'avg_miss_penalty': avg_miss_penalty\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"Error processing {pkl_file.stem}: {e}\")\n",
    "\n",
    "    # Calculate average penalties for the entire epoch\n",
    "    avg_epoch_actual_penalty = total_actual_penalty / total_batches if total_batches > 0 else 0\n",
    "    avg_epoch_miss_penalty = total_miss_penalty / total_batches if total_batches > 0 else 0\n",
    "\n",
    "    # Validation step and other epoch-wise processing\n",
    "    # ...\n",
    "\n",
    "    all_epochs_performance_metrics[epoch] = epoch_performance_metrics\n",
    "\n",
    "# Continue with validation, scheduler update, and other steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import gc\n",
    "from scr.utils import load_dataset_pickle\n",
    "from scr.custom_sampler import PerformanceBasedSampler, update_sampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from scr.dataset import  HangmanDataset, collate_fn\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Assuming the existence of necessary functions, model setup, and collate_fn\n",
    "\n",
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "shuffle = True\n",
    "\n",
    "initial_performance_metrics = {}\n",
    "\n",
    "# Initialize the scheduler for the optimizer\n",
    "scheduler = ReduceLROnPlateau(model.optimizer, mode='max', factor=0.5, \\\n",
    "    patience=2, verbose=True)\n",
    "\n",
    "# # Define the base directory for the dataset\n",
    "# base_dataset_dir = Path('dataset/pkl')\n",
    "\n",
    "\n",
    "# # Debugging: Print the directory and number of .pkl files found\n",
    "# print(f\"Dataset directory: {base_dataset_dir}\")\n",
    "# print(f\"Number of .pkl files found: {len(pkl_files)}\")\n",
    "\n",
    "# Dictionary to store performance metrics for each epoch and .pkl file\n",
    "all_epochs_performance_metrics = {}\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc='Epochs'):\n",
    "    # # print(f'Epoch {epoch+1}:')\n",
    "    epoch_performance_metrics = {}\n",
    "    # print(epoch_performance_metrics)\n",
    "\n",
    "    # print(initial_performance_metrics)\n",
    "\n",
    "    total_actual_penalty, total_miss_penalty = 0, 0\n",
    "\n",
    "    for pkl_file in tqdm(pkl_files, desc='PKL Files', leave=False):\n",
    "        batch_performence_etriccs = ()\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            # Load the dataset from the .pkl file\n",
    "            with open(pkl_file, 'rb') as file:\n",
    "                train_dataset = pickle.load(file)\n",
    "\n",
    "            # # Initialize sampler for each .pkl file\n",
    "            # print('sampler')\n",
    "            sampler = PerformanceBasedSampler(train_dataset, \\\n",
    "                initial_performance_metrics)\n",
    "\n",
    "            # # Initialize DataLoader with the sampler\n",
    "            # print('train')\n",
    "            train_loader = DataLoader(train_dataset, \\\n",
    "                batch_size=batch_size, sampler=sampler, collate_fn=collate_fn)\n",
    "\n",
    "            # Training step\n",
    "            avg_actual_penalty, avg_miss_penalty = train_on_batch(model, \\\n",
    "                train_loader, device)\n",
    "\n",
    "            # Accumulate penalties\n",
    "            total_actual_penalty += avg_actual_penalty\n",
    "            total_miss_penalty += avg_miss_penalty\n",
    "\n",
    "            # Debug lines to print out the penalties for each .pkl file\n",
    "            # print(f\"File: {pkl_file.stem} - Epoch {epoch+1}: Avg Actual Penalty: \n",
    "            # {avg_actual_penalty}, Avg Miss Penalty: {avg_miss_penalty}\")\n",
    "\n",
    "            # Update metrics for the current .pkl file\n",
    "            pkl_file_name = pkl_file.stem\n",
    "            \n",
    "            batch_performance_metrics[pkl_file_name] = {\n",
    "                'avg_actual_penalty': avg_actual_penalty,\n",
    "                'avg_miss_penalty': avg_miss_penalty\n",
    "            }\n",
    "\n",
    "            end_time = time.time()\n",
    "            processing_time = end_time - start_time\n",
    "            # tqdm.write(f\"File: {pkl_file.stem} - Epoch {epoch+1}: \n",
    "            # Processed in {processing_time:.2f} seconds\")\n",
    "\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"Error processing {pkl_file.stem}: {e}\")\n",
    "\n",
    "    \n",
    "\n",
    "    # Calculate average penalties for the epoch\n",
    "    avg_epoch_actual_penalty = total_actual_penalty / len(pkl_files)\n",
    "    avg_epoch_miss_penalty = total_miss_penalty / len(pkl_files)\n",
    "\n",
    "    # Validation step\n",
    "    # Store metrics for the epoch\n",
    "    all_epochs_performance_metrics[epoch] = epoch_performance_metrics\n",
    "\n",
    "    validation_results = validate_model_on_dataset(model, val_words, \\\n",
    "        char_frequency, max_word_length, device, max_attempts=6, normalize=True, \\\n",
    "            number_of_games=10000)\n",
    "\n",
    "    plot_word_stats(validation_results['word_length_stats'], epoch)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"Epoch {epoch+1}: Avg Actual Penalty: {avg_epoch_actual_penalty}, Avg Miss Penalty: {avg_epoch_miss_penalty}\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Validation - Win Rate: {validation_results['win_rate']}\")\n",
    "\n",
    "    # Update learning rate\n",
    "    scheduler.step(validation_results['win_rate'])\n",
    "\n",
    "    # Update initial_performance_metrics for the next epoch\n",
    "    initial_performance_metrics.update(validation_results['word_length_stats'])\n",
    "\n",
    "    print(initial_performance_metrics)\n",
    "\n",
    "    _ = gc.collect()\n",
    "\n",
    "print('Training completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "from scr.model import RNN\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from scr.utils import *\n",
    "from scr.early_stopping import EarlyStopping\n",
    "import optuna\n",
    "\n",
    "N_GAMES_PER_EPOCH = 10 ** 3\n",
    "MAX_ATTEMPTS = 6\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "def objective(trial, dataset, static_config, num_epochs):\n",
    "    dynamic_config = optuna_dynamic_hyperparameters(trial)\n",
    "    config = {**static_config, **dynamic_config}\n",
    "    # print(f\"Trial {trial.number}: Configuration - {config}\")\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True)\n",
    "    aggregated_metrics = []\n",
    "\n",
    "    best_objective_value = float('-inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "        # print(f\"Starting Fold {fold + 1}\")\n",
    "        train_loader, val_loader = get_data_loaders(dataset, train_idx, val_idx)\n",
    "        model, optimizer = initialize_model(config)\n",
    "\n",
    "        scheduler = StepLR(optimizer, step_size=trial.suggest_int(\"step_size\", 5, 20), \\\n",
    "            gamma=trial.suggest_float(\"gamma\", 0.1, 0.5))\n",
    "        \n",
    "        early_stopping = EarlyStopping(patience=10, delta=0.001)  # Early stopping instance\n",
    "\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            _, _ = train_one_epoch(model, train_loader)\n",
    "\n",
    "            scheduler.step()\n",
    "            win_rate, average_attempts, win_rate_by_length = simulate_games(\n",
    "                    model=model,\n",
    "                    word_list=None,  # Not using a word list in this scenario\n",
    "                    char_to_idx=char_to_idx, \n",
    "                    idx_to_char=idx_to_char,\n",
    "                    char_frequency=char_frequency, \n",
    "                    max_word_length=max_word_length, \n",
    "                    device=device, \n",
    "                    val_loader=val_loader,  # Pass the validation DataLoader\n",
    "                    max_games_per_epoch=N_GAMES_PER_EPOCH,  # Number of games for validation\n",
    "                    normalize=True, \n",
    "                    max_attempts=MAX_ATTEMPTS\n",
    "            \n",
    "            )\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "    # Training step\n",
    "    avg_actual_penalty, avg_miss_penalty = train_one_epoch(model, train_loader, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Training data - Avg Actual Penalty: {avg_actual_penalty}, Avg Miss Penalty: {avg_miss_penalty}\")\n",
    "\n",
    "    # Validation step\n",
    "\n",
    "    # win_rate, average_attempts, win_rate_by_length \\\n",
    "    #     = simulate_hangman_games(model, char_to_idx, idx_to_char, \\\n",
    "    #         char_frequency, max_word_length, device, word_list=None, \\\n",
    "    #     val_loader=test_loader, num_games=1000, max_attempts=6, normalize=True)\n",
    "\n",
    "    \n",
    "    avg_actual_penalty, avg_miss_penalty = train_one_epoch(model, train_loader, device)\n",
    "\n",
    "\n",
    "    win_rate, average_attempts, win_rate_by_length \\\n",
    "        = simulate_hangman_games(model, char_to_idx, idx_to_char, \\\n",
    "            char_frequency, max_word_length, device, word_list=None, \\\n",
    "        val_loader=test_loader, num_games=1000, max_attempts=6, normalize=True)\n",
    "\n",
    "    #         win_rate, average_attempts, win_rate_by_length = validate_one_epoch(model, \\\n",
    "    #             val_loader, char_to_idx, idx_to_char, char_frequency, max_word_length, device)\n",
    "\n",
    "            aggregated_metrics.append((win_rate, average_attempts, win_rate_by_length))\n",
    "\n",
    "            objective_value = calculate_objective_value(win_rate, \\\n",
    "                average_attempts, win_rate_by_length)\n",
    "            \n",
    "            trial.report(objective_value, epoch)\n",
    "\n",
    "            if objective_value > best_objective_value:\n",
    "                best_objective_value = objective_value\n",
    "                best_model_state = model.state_dict()  # Update best model state\n",
    "\n",
    "            # Check early stopping\n",
    "            if early_stopping(objective_value):\n",
    "                break  # Stop the current fold if early stopping criteria are met\n",
    "\n",
    "            # Pruning check\n",
    "            if trial.should_prune():\n",
    "                return process_aggregated_metrics(aggregated_metrics)\n",
    "\n",
    "    # Save the best model at the end of the trial\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        model.save_model()  # Save the model using your custom method\n",
    "\n",
    "    final_objective_value = process_aggregated_metrics(aggregated_metrics)\n",
    "    \n",
    "    return final_objective_value\n",
    "\n",
    "\n",
    "def calculate_objective_value(win_rate_percentage, avg_attempts_per_game, \\\n",
    "    win_rate_by_word_length):\n",
    "    # Define weights for each metric\n",
    "    weight_for_win_rate = 0.7  # Higher weight for win rate\n",
    "    weight_for_average_attempts = 0.3  # Lower weight for average attempts\n",
    "\n",
    "    # Normalize win rate (converting percentage to a range of 0 to 1)\n",
    "    normalized_win_rate = win_rate_percentage / 100\n",
    "\n",
    "    # Normalize average attempts (assuming max attempts per game is known)\n",
    "    max_attempts_per_game = 6  # Example: maximum number of attempts allowed\n",
    "    normalized_avg_attempts = avg_attempts_per_game / max_attempts_per_game\n",
    "\n",
    "    # Normalize win rate by word length\n",
    "    normalized_win_rate_by_length = normalize_win_rate_by_length(win_rate_by_word_length)\n",
    "\n",
    "    # Combine metrics into a single objective value\n",
    "    objective_value = (weight_for_win_rate * normalized_win_rate) - \\\n",
    "                      (weight_for_average_attempts * normalized_avg_attempts) + \\\n",
    "                      normalized_win_rate_by_length\n",
    "    return objective_value\n",
    "\n",
    "def normalize_win_rate_by_length(win_rate_by_length_dict):\n",
    "    # Example logic for normalization\n",
    "    max_possible_win_rate = 1  # Maximum win rate (100% as a decimal)\n",
    "    normalized_scores = {length: win_rate / max_possible_win_rate for \\\n",
    "        length, win_rate in win_rate_by_length_dict.items()}\n",
    "    # Average the normalized win rates across all word lengths\n",
    "    average_normalized_score = sum(normalized_scores.values()) / len(normalized_scores)\n",
    "    return average_normalized_score\n",
    "\n",
    "def process_aggregated_metrics(aggregated_metrics):\n",
    "    # Initialize sums for each metric\n",
    "    sum_win_rate = 0\n",
    "    sum_average_attempts = 0\n",
    "    sum_win_rate_by_length = {}\n",
    "\n",
    "    # Process each set of metrics\n",
    "    for win_rate, average_attempts, win_rate_by_length in aggregated_metrics:\n",
    "        sum_win_rate += win_rate\n",
    "        sum_average_attempts += average_attempts\n",
    "        for length, rate in win_rate_by_length.items():\n",
    "            sum_win_rate_by_length[length] = sum_win_rate_by_length.get(length, 0) + rate\n",
    "\n",
    "    # Calculate averages\n",
    "    num_entries = len(aggregated_metrics)\n",
    "    avg_win_rate = sum_win_rate / num_entries\n",
    "    avg_average_attempts = sum_average_attempts / num_entries\n",
    "    avg_win_rate_by_length = {length: rate / num_entries for length, \\\n",
    "        rate in sum_win_rate_by_length.items()}\n",
    "\n",
    "    # Now calculate the final objective value using these averages\n",
    "    final_objective_value = calculate_objective_value(avg_win_rate, \\\n",
    "        avg_average_attempts, avg_win_rate_by_length)\n",
    "    return final_objective_value\n",
    "\n",
    "\n",
    "# Utility functions (for cleaner code)\n",
    "def get_data_loaders(dataset, train_idx, val_idx):\n",
    "    train_subset = Subset(dataset, train_idx)\n",
    "    val_subset = Subset(dataset, val_idx)\n",
    "    train_loader = DataLoader(train_subset, batch_size=32, \\\n",
    "        shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_subset, batch_size=32, \\\n",
    "        shuffle=False, collate_fn=collate_fn)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def initialize_model(config):\n",
    "    model = RNN(config)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    return model, optimizer\n",
    "\n",
    "# Utility functions\n",
    "def optuna_dynamic_hyperparameters(trial):\n",
    "    # Define and return dynamic hyperparameters based on the trial\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-3, log=True)\n",
    "    hidden_dim = trial.suggest_categorical('hidden_dim', [128, 256, 512])\n",
    "    embedding_dim = trial.suggest_categorical('embedding_dim', [50, 100, 150])\n",
    "    output_mid_features = trial.suggest_categorical('output_mid_features', [50, 100, 200])\n",
    "    miss_linear_dim = trial.suggest_categorical('miss_linear_dim', [50, 100, 150])\n",
    "    dropout = trial.suggest_float('dropout', 0.2, 0.5)\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "\n",
    "    return {\n",
    "        'lr': lr,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'embedding_dim': embedding_dim,\n",
    "        'output_mid_features': output_mid_features,\n",
    "        'miss_linear_dim': miss_linear_dim,\n",
    "        'dropout': dropout,\n",
    "        'num_layers': num_layers\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define your models directory path\n",
    "models_dir = Path('models/notebook_2')\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Assuming missed_chars_tensor is a list of tensors for missed characters\n",
    "# dataset = HangmanDataset(features, \\\n",
    "#     labels, missed_chars, original_words)\n",
    "\n",
    "# Static configuration\n",
    "static_config = {\n",
    "    'rnn': 'LSTM',\n",
    "    'vocab_size': 27,  # 26 English alphabets + 1 (e.g., for underscore)\n",
    "    'use_embedding': True,  # Typically a design choice\n",
    "    'input_feature_size': 5,  # Based on your feature engineering strategy\n",
    "    'models': str(models_dir)\n",
    "}\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define num_epochs for training in each fold\n",
    "num_epochs = 4 # Adjust as needed\n",
    "N_TRIAL = 3\n",
    "\n",
    "# ====================================================== #\n",
    "# Define the direction for the objective: 'maximize' or 'minimize'\n",
    "direction = 'maximize'  # Adjust based on your objective function\n",
    "\n",
    "study = optuna.create_study(direction=direction)\n",
    "study.optimize(lambda trial: objective(trial, dataset, \\\n",
    "    static_config, num_epochs), n_trials=N_TRIAL)\n",
    "# ====================================================== #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "# Output the best hyperparameters\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"Value: {trial.value}\")\n",
    "print(\"Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = study.best_trial\n",
    "print(f\"Best trial number: {best_trial.number}\")\n",
    "\n",
    "# Assuming model saving includes the trial number in the filename\n",
    "best_model_filename = f\"models/trial_{best_trial.number+1}/LSTM.pth\"\n",
    "best_model = RNN.load_model(RNN, best_model_filename, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dictionaries to form a single configuration\n",
    "config = {**static_config, **best_params}\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dictionaries to form a single configuration\n",
    "config = {**static_config, **best_params}\n",
    "\n",
    "# Initialize the RNN model with the combined configuration\n",
    "model = RNN(config)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# model.load_model(config['LSTM'], 2, 256, trial_number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing on unknown data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from scr.game import predict_next_character, simulate_game\n",
    "from scr.model import RNN\n",
    "import random\n",
    "# random.seed(400)\n",
    "# Your existing code for initializing the model, etc.\n",
    "\n",
    "import random\n",
    "\n",
    "def play_multiple_games(model, num_games, word_list, \\\n",
    "    char_to_idx, idx_to_char, char_frequency, max_word_length, device):\n",
    "    game_results = []\n",
    "    \n",
    "    sampled_words = random.sample(word_list, num_games)  # Select unique words\n",
    "\n",
    "    for random_word in sampled_words:\n",
    "        with torch.no_grad():\n",
    "            won, final_word, attempts_used = simulate_game(\n",
    "                model, \n",
    "                random_word, \n",
    "                char_to_idx, \n",
    "                idx_to_char, \n",
    "                char_frequency, \n",
    "                max_word_length, \n",
    "                device, \n",
    "                normalize=True, \n",
    "                max_attempts=6\n",
    "            )\n",
    "        game_results.append((won, final_word, attempts_used))\n",
    "\n",
    "    return game_results\n",
    "\n",
    "# Example usage\n",
    "num_games = 10**3\n",
    "results = play_multiple_games(model, num_games, \\\n",
    "    word_list, char_to_idx, idx_to_char, \\\n",
    "        char_frequency, max_word_length, device)\n",
    "\n",
    "# Analyzing results\n",
    "total_wins = sum(result[0] for result in results)\n",
    "win_rate = (total_wins / num_games) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optiver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
