{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "import sys\n",
    "# Custom library paths\n",
    "sys.path.extend(['../', './scr'])\n",
    "\n",
    "from scr.utils import set_seed\n",
    "from scr.utils import read_words\n",
    "from pathlib import Path\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from scr.feature_engineering import \\\n",
    "    calculate_char_frequencies, calculate_word_frequencies\n",
    "from scr.utils import read_words, save_words_to_file\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from scr.dataset import *\n",
    "from scr.game import *\n",
    "from scr.plot_utils import *\n",
    "\n",
    "import gc\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "from scr.utils import print_scenarios\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Read and Shuffle Word List\n",
    "word_list = read_words('data/words_250000_train.txt') # , limit=10000)\n",
    "# word_list = read_words('data/250k.txt', limit=10000)\n",
    "random.shuffle(word_list)\n",
    "\n",
    "# base_dataset_dir = Path('dataset/pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 181840 train words from /media/sayem/510B93E12554BBD1/dataset/250000/train_words.txt\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "NUM_STRATIFIED_SAMPLES = 250_000\n",
    "# # # Define the base directory\n",
    "\n",
    "base_dataset_dir = Path(f\"/media/sayem/510B93E12554BBD1/dataset/{NUM_STRATIFIED_SAMPLES}\")\n",
    "\n",
    "\n",
    "parquet_file_path = base_dataset_dir / \"HangmanData.parquet\"\n",
    "\n",
    "# Paths to the words files\n",
    "train_words_file_path = base_dataset_dir / 'train_words.txt'\n",
    "test_words_file_path = base_dataset_dir / 'test_words.txt'\n",
    "\n",
    "# Read the words from the files\n",
    "try:\n",
    "    train_words = read_words(train_words_file_path)\n",
    "    print(f\"Loaded {len(train_words)} train words from {train_words_file_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {train_words_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/media/sayem/510B93E12554BBD1/dataset/250000')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dataset_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For inference\n",
    "from scr.feature_engineering import *\n",
    "\n",
    "word_frequencies = calculate_word_frequencies(word_list)\n",
    "char_frequency = calculate_char_frequencies(word_list)\n",
    "max_word_length = max(len(word) for word in word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.simple_model import SimpleLSTM\n",
    "from scr.base_model import BaseModel\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from scr.feature_engineering import *\n",
    "\n",
    "# max_word_length = 29 # TODO will remove later\n",
    "# Instantiate and test the model\n",
    "config = {\n",
    "    'embedding_dim': 200,\n",
    "    'hidden_dim': 256,\n",
    "    'num_layers': 2,\n",
    "    'vocab_size': 27,\n",
    "    'max_word_length': max_word_length,\n",
    "    'input_feature_size': 5,\n",
    "    'use_embedding': True,\n",
    "    'miss_linear_dim': 150,\n",
    "    'lr': 0.0001,\n",
    "    'optimizer_type': 'Adam'\n",
    "}\n",
    "\n",
    "model = SimpleLSTM(config)\n",
    "# optimizer = model.optimizer\n",
    "\n",
    "# Assuming 'model' is your trained model instance\n",
    "model.save_model(file_path='models/model_.pth') ## TODO: _ will remove later\n",
    "\n",
    "\n",
    "# Assuming the saved model file is 'models/model.pth'\n",
    "model_file_path = 'models/model_.pth' ## TODO: _ will remove later\n",
    "\n",
    "# Specify the device to load the model onto\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Load the model\n",
    "# loaded_model = BaseModel.load_model(SimpleLSTM, model_file_path)\n",
    "# # Now `loaded_model` is an instance of `SimpleLSTM` with the state and config loaded\n",
    "\n",
    "# model = loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adam'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.optimizer).__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset Loading and train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from scr.dataset import HangmanDataset # , custom_collate_fn\n",
    "\n",
    "from scr.feature_engineering import process_batch_of_games\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "hangman_dataset = HangmanDataset(parquet_file_path)  # Replace with your Parquet file path\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, valid_dataset = train_test_split(hangman_dataset, \\\n",
    "    test_size=0.20, random_state=42)\n",
    "\n",
    "# Now, you can use train_dataset for training and valid_dataset for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'game_id': 9533801,\n",
       " 'word': 'preacknowledgement',\n",
       " 'initial_state': ['___ack____________'],\n",
       " 'final_state': 'p__ack____________',\n",
       " 'guessed_states': ['___ack____________',\n",
       "  '___ack____________',\n",
       "  '___ack____________',\n",
       "  '___ack____________',\n",
       "  '___ack____________',\n",
       "  'p__ack____________',\n",
       "  'p__ack____________'],\n",
       " 'guessed_letters': ['i', 'f', 'u', 'y', 'p', 'b', 'v'],\n",
       " 'game_state': 'quarterRevealed',\n",
       " 'difficulty': 'hard',\n",
       " 'outcome': 'win',\n",
       " 'word_length': 18,\n",
       " 'won': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hangman_dataset[10 ** 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(hangman_dataset, batch_size=32, \\\n",
    "    collate_fn=custom_collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of batch_features: torch.Size([32, 17, 145])\n",
      "Shape of batch_missed_chars: torch.Size([32, 17, 27])\n"
     ]
    }
   ],
   "source": [
    "for batch in data_loader:\n",
    "    states = batch['guessed_states']\n",
    "    guesses = batch['guessed_letters']\n",
    "    max_seq_length = batch['max_seq_len']\n",
    "    original_seq_lengths = batch['original_seq_lengths']\n",
    "\n",
    "    # Preprocess the batch data\n",
    "    batch_features, batch_missed_chars = process_batch_of_games(\n",
    "        states, guesses, char_frequency, max_word_length, max_seq_length)\n",
    "\n",
    "    # Move the tensors to the specified device\n",
    "    batch_features = batch_features.to(device)\n",
    "    batch_missed_chars = batch_missed_chars.to(device)\n",
    "\n",
    "    # Print the shapes\n",
    "    print(\"Shape of batch_features:\", batch_features.shape)\n",
    "    print(\"Shape of batch_missed_chars:\", batch_missed_chars.shape)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['e__e__e', 'k'], 'entente')\n"
     ]
    }
   ],
   "source": [
    "from scr.dataset import *\n",
    "\n",
    "val_samples = create_validation_samples(valid_dataset)\n",
    "print(val_samples[0])  # This will print the list of validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e__e__e k\n",
      "torch.Size([1, 1, 145])\n",
      "tensor([[[1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]])\n",
      "k\n"
     ]
    }
   ],
   "source": [
    "for data in val_samples:\n",
    "    state, guess = data[0][0], data[0][1]\n",
    "    word = data[1]\n",
    "    print(state, guess)\n",
    "\n",
    "    fets_, missed_char_ = process_batch_of_games([state],\n",
    "                           [guess],\n",
    "                           char_frequency,\n",
    "                           max_word_length,\n",
    "                           1)\n",
    "\n",
    "    label = pad_and_reshape_labels\n",
    "\n",
    "    print(fets_.shape)\n",
    "\n",
    "    print(missed_char_)\n",
    "\n",
    "    print(guess)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'STOP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mSTOP\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'STOP' is not defined"
     ]
    }
   ],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "# import random\n",
    "\n",
    "# # Define the maximum number of games you want to play per epoch\n",
    "# max_games_per_epoch = 1000  # Example value, adjust as needed\n",
    "\n",
    "# # Assuming train_data_loader is your DataLoader for training data\n",
    "# unique_words_set = set()\n",
    "# for _, _, _, batch_full_words in val_loader:\n",
    "#     unique_words_set.update(batch_full_words)\n",
    "\n",
    "# # Group words by their lengths\n",
    "# words_by_length = defaultdict(list)\n",
    "# for word in unique_words_set:\n",
    "#     words_by_length[len(word)].append(word)\n",
    "\n",
    "# # Calculate the number of words to select from each length group\n",
    "# num_words_per_length = max_games_per_epoch // len(words_by_length)\n",
    "\n",
    "# selected_words = []\n",
    "# for length, words in words_by_length.items():\n",
    "#     random.shuffle(words)\n",
    "#     selected_words.extend(words[:num_words_per_length])\n",
    "\n",
    "# # # # Now, use 'selected_words' in place of 'unique_words' for game simulation\n",
    "# # selected_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # Initialize DataLoader outside the loop\n",
    "# batch_size = 64\n",
    "# train_loader = DataLoader(train_data, batch_size=batch_size, \\\n",
    "#         collate_fn=processed_dataset.custom_collate_fn)\n",
    "# # epochs = 10\n",
    "# # # model.train()\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     train_loader = DataLoader(train_data, batch_size=batch_size, \\\n",
    "#         collate_fn=processed_dataset.custom_collate_fn)\n",
    "\n",
    "#     train_loss, train_miss_penalty = train_on_data_loader(model, train_loader, device)\n",
    "#     print(f\"Epoch {epoch}: Training Loss: {train_loss}, Miss Penalty: {train_miss_penalty}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Untrained Model Performence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.model_training import validate_hangman\n",
    "# Now call the validate_hangman function with this set\n",
    "validation_results = validate_hangman(model, val_loader, \\\n",
    "    char_frequency, max_word_length, device, selected_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.plot_utils import *\n",
    "\n",
    "print(f'~Untrained model performence~')\n",
    "# # Print results for character-level validation\n",
    "# print(\"Character Level Validation:\")\n",
    "print(f\"Average Loss: {validation_results['avg_loss']}\")\n",
    "print(f\"Miss Penalty: {validation_results['avg_miss_penalty']}\")\n",
    "\n",
    "game_simulation_results = validation_results[\"game_simulation\"]\n",
    "\n",
    "save_path = Path(f\"plots/{NUM_STRATIFIED_SAMPLES}_untrained_model_performence_word_stats_plot.png\")\n",
    "plot_word_stats(game_simulation_results[\"length_stats\"], save_path)\n",
    "\n",
    "# # Print results for game simulation\n",
    "# print(\"\\nGame Simulation:\")\n",
    "print(f\"Win Rate: {game_simulation_results['win_rate']}\")\n",
    "print(f\"Average Attempts: {game_simulation_results['average_attempts']}\")\n",
    "print(f\"Total Games: {game_simulation_results['total_games']}\")\n",
    "print(f\"Total Wins: {game_simulation_results['total_wins']}\")\n",
    "print(f\"Total Losses: {game_simulation_results['total_losses']}\")\n",
    "# print(\"Word Stats:\", game_simulation_results[\"game_stats\"])\n",
    "# print(\"Word Length Stats:\", game_simulation_results[\"length_stats\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_performance_dict = game_simulation_results[\"length_stats\"]\n",
    "\n",
    "# init_performance_dict = {\n",
    "#     length: {\"wins\": 1, \"losses\": 1, \"total_attempts\": 2, \"games\": 2}\n",
    "#     for length in range(1, max_word_length + 1)\n",
    "# }\n",
    "\n",
    "init_performance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 64  # Adjust as needed\n",
    "# custom_sampler = PerformanceBasedSampler(train_data, init_performance_dict)\n",
    "\n",
    "# # # Check sampler output\n",
    "# # print(\"Sampler output check:\")\n",
    "# # for i, idx in enumerate(custom_sampler):\n",
    "# #     print(f\"Index {i}: {idx}\")\n",
    "# #     if i >= 10:  # Adjust for more checks\n",
    "# #         break\n",
    "\n",
    "# # DataLoader with the custom sampler\n",
    "# train_loader = DataLoader(train_data, batch_size=128, \\\n",
    "#     sampler=custom_sampler, collate_fn=processed_dataset.custom_collate_fn)\n",
    "\n",
    "# # Check DataLoader output\n",
    "# print(\"\\nDataLoader output check:\")\n",
    "# for i, batch in enumerate(train_loader):\n",
    "#     game_states, seq_lengths, missed_chars, indices, info = batch\n",
    "#     # print(f\"\\nBatch {i} details:\")\n",
    "#     # print(\"Game States Tensor:\", game_states.shape)\n",
    "#     # print(\"Sequence Lengths:\", seq_lengths.shape)\n",
    "#     # print(\"Missed Characters Tensor:\", missed_chars.shape)\n",
    "#     # print(\"Indices Tensor:\", indices)\n",
    "#     # print(\"Information List:\", info)\n",
    "#     # if i >= 1:  # Adjust for more checks\n",
    "#     #     break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CyclicLR  # Import CyclicLR or other schedulers\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_model(model, train_data, init_performance_dict, val_loader, \n",
    "                num_epochs, batch_size, selected_words, device, scheduler_type='CyclicLR'):\n",
    "    best_val_loss = float('inf')\n",
    "    n_epochs_stop = 10\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    # Define the scheduler\n",
    "    if scheduler_type == 'CyclicLR':\n",
    "        scheduler = CyclicLR(model.optimizer, base_lr=0.00001, max_lr=0.001, step_size_up=5, \n",
    "                             mode='triangular', cycle_momentum=False)\n",
    "                             \n",
    "    elif scheduler_type == 'ReduceLROnPlateau':\n",
    "        scheduler = ReduceLROnPlateau(model.optimizer, mode='min', factor=0.1, patience=5)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Recalculate sampler for each epoch\n",
    "        custom_sampler = PerformanceBasedSampler(train_data, init_performance_dict)\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, sampler=custom_sampler, \n",
    "                                  collate_fn=processed_dataset.custom_collate_fn)\n",
    "\n",
    "        model.train()\n",
    "        train_loss, train_miss_penalty = train_on_data_loader(model, train_loader, device)\n",
    "\n",
    "        print(f\"Epoch {epoch}: Training Loss: {train_loss}, Miss Penalty: {train_miss_penalty}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            validation_results = validate_hangman(model, val_loader, char_frequency, \n",
    "                                                  max_word_length, device, selected_words)\n",
    "            val_loss = validation_results['avg_loss']\n",
    "            val_miss_penalty = validation_results[\"avg_miss_penalty\"]\n",
    "            init_performance_dict = validation_results[\"game_simulation\"][\"length_stats\"]\n",
    "\n",
    "        # Scheduler stepping\n",
    "        if scheduler_type == 'ReduceLROnPlateau':\n",
    "            scheduler.step(val_loss)\n",
    "        elif scheduler_type == 'CyclicLR':\n",
    "            scheduler.step()\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == n_epochs_stop:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "        print(f\"Epoch {epoch}: Validation Loss: {val_loss}, Validation Miss Penalty: {val_miss_penalty}\")\n",
    "        print(f\"Win Rate: {validation_results['game_simulation']['win_rate']}\")\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 1024  # Define your batch size\n",
    "model = SimpleLSTM(config)\n",
    "# optimizer = model.optimizer\n",
    "# Training the model\n",
    "train_model(model, train_data, init_performance_dict, val_loader, num_epochs, batch_size, \n",
    "            selected_words, device, scheduler_type='ReduceLROnPlateau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.optim.lr_scheduler import ReduceLROnPlateau, CyclicLR  # Import CyclicLR or other schedulers\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# def train_model(model, train_data, init_performance_dict, val_loader, \\\n",
    "#     num_epochs, batch_size, selected_words, scheduler=None, device=device):\n",
    "#     best_val_loss = float('inf')\n",
    "#     n_epochs_stop = 10\n",
    "#     epochs_no_improve = 0\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         custom_sampler = PerformanceBasedSampler(train_data, init_performance_dict)\n",
    "#         train_loader = DataLoader(train_data, batch_size=batch_size, sampler=custom_sampler, \\\n",
    "#             collate_fn=processed_dataset.custom_collate_fn)\n",
    "\n",
    "#         # train_loader = DataLoader(train_data, batch_size=batch_size, \\\n",
    "#         #     collate_fn=processed_dataset.custom_collate_fn)\n",
    "\n",
    "#         model.train()\n",
    "#         train_loss, train_miss_penalty = train_on_data_loader(model, \\\n",
    "#             train_loader, device)\n",
    "\n",
    "#         print(f\"Epoch {epoch}: Training Loss: {train_loss}, Miss Penalty: {train_miss_penalty}\")\n",
    "\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             validation_results = validate_hangman(model, val_loader, char_frequency, \\\n",
    "#                 max_word_length, device, selected_words)\n",
    "#             val_loss = validation_results['avg_loss']\n",
    "#             val_miss_penalty = validation_results[\"avg_miss_penalty\"]\n",
    "#             init_performance_dict = validation_results[\"game_simulation\"][\"length_stats\"]\n",
    "\n",
    "#         if scheduler:\n",
    "#             scheduler.step(val_loss)  # Assuming the scheduler is ReduceLROnPlateau or similar\n",
    "#             # scheduler.step(val_loss)\n",
    "\n",
    "#         if val_loss < best_val_loss:\n",
    "#             best_val_loss = val_loss\n",
    "#             epochs_no_improve = 0\n",
    "#         else:\n",
    "#             epochs_no_improve += 1\n",
    "#             if epochs_no_improve == n_epochs_stop:\n",
    "#                 print(\"Early stopping triggered\")\n",
    "#                 break\n",
    "\n",
    "#         print(f\"Epoch {epoch}: val loss: {val_loss}, val miss penalty: {val_miss_penalty}\")\n",
    "#         print(f\"Win Rate: {validation_results['game_simulation']['win_rate']}\")\n",
    "#         print()\n",
    "\n",
    "\n",
    "# num_epochs = 10\n",
    "# batch_size = 64 # hyperparams\n",
    "\n",
    "# # Example of calling train_model with a CyclicLR scheduler, disabling cycle_momentum\n",
    "# scheduler = CyclicLR(model.optimizer, base_lr=0.0001, max_lr=0.01, step_size_up=5, \\\n",
    "#     mode='triangular', cycle_momentum=False)\n",
    "    \n",
    "# train_model(model, train_data, init_performance_dict, \\\n",
    "#     val_loader, num_epochs, batch_size, selected_words, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# import torch\n",
    "# from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# def k_fold_cross_validate(model, dataset, k, num_epochs, optimizer, scheduler_class, device):\n",
    "#     kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "#     for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "#         print(f\"Fold {fold}\")\n",
    "#         train_subset = Subset(dataset, train_idx)\n",
    "#         val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "#         # Initialize a new model for each fold\n",
    "#         model = SimpleLSTM(config)\n",
    "#         model.to(device)\n",
    "#         optimizer = model.optimizer\n",
    "#         scheduler = scheduler_class(optimizer)\n",
    "\n",
    "#         train_subset = Subset(dataset, train_idx)\n",
    "#         val_subset = Subset(dataset, val_idx)\n",
    "#         train_model(model, train_subset, val_subset, num_epochs, optimizer, scheduler, device)\n",
    "\n",
    "\n",
    "#         train_model(model, train_subset, val_subset, num_epochs, optimizer, scheduler, device)\n",
    "\n",
    "# # Usage example\n",
    "# num_epochs = 10\n",
    "# batch_size = 64\n",
    "# scheduler_class = torch.optim.lr_scheduler.ReduceLROnPlateau  # Example scheduler class\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# k_fold_cross_validate(model, processed_dataset, \\\n",
    "#     5, num_epochs, optimizer, scheduler_class, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trained Model Performence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = processed_dataset.create_val_loader(val_data)\n",
    "\n",
    "\n",
    "# Call the validation function\n",
    "validation_results = validate_hangman(model, val_loader, \\\n",
    "    char_frequency, max_word_length, device)\n",
    "\n",
    "# Access the results\n",
    "character_level_results = validation_results[\"character_level\"]\n",
    "game_simulation_results = validation_results[\"game_simulation\"]\n",
    "\n",
    "from scr.plot_utils import *\n",
    "\n",
    "save_path = Path(f\"plots/{NUM_STRATIFIED_SAMPLES}_trained_model_performence_word_stats_plot.png\")\n",
    "plot_word_stats(game_simulation_results[\"length_stats\"], save_path)\n",
    "\n",
    "# # Print results for character-level validation\n",
    "# print(\"Character Level Validation:\")\n",
    "print(f\"Average Loss: {character_level_results['avg_loss']}\")\n",
    "print(f\"Miss Penalty: {character_level_results['avg_miss_penalty']}\")\n",
    "# print(f\"Character Accuracy: {character_level_results['char_accuracy']}\")\n",
    "# print(f\"Word Accuracy: {character_level_results['word_accuracy']}\")\n",
    "# print(\"Word Statistics:\", character_level_results[\"word_stats\"])  # Updated key\n",
    "\n",
    "# # Print results for game simulation\n",
    "# print(\"\\nGame Simulation:\")\n",
    "print(f\"Win Rate: {game_simulation_results['win_rate']}\")\n",
    "print(f\"Average Attempts: {game_simulation_results['average_attempts']}\")\n",
    "print(f\"Total Games: {game_simulation_results['total_games']}\")\n",
    "print(f\"Total Wins: {game_simulation_results['total_wins']}\")\n",
    "print(f\"Total Losses: {game_simulation_results['total_losses']}\")\n",
    "# print(\"Word Stats:\", game_simulation_results[\"game_stats\"])\n",
    "# print(\"Word Length Stats:\", game_simulation_results[\"length_stats\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Word Stats:\", game_simulation_results[\"game_stats\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_features_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_features_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, device):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "    total_miss_penalty = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        if batch[0] is None:\n",
    "            continue  # Skip empty batches\n",
    "\n",
    "        game_states_batch, lengths_batch, missed_chars_batch, labels_batch = batch\n",
    "        game_states_batch, lengths_batch, missed_chars_batch = \\\n",
    "            game_states_batch.to(device), lengths_batch, missed_chars_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(game_states_batch, lengths_batch, missed_chars_batch)\n",
    "        model_output_shape = outputs.shape\n",
    "        reshaped_labels = pad_and_reshape_labels(labels_batch, model_output_shape).to(device)\n",
    "\n",
    "        loss, miss_penalty = model.calculate_loss(outputs, reshaped_labels, \\\n",
    "                                                  lengths_batch, missed_chars_batch, 27)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_miss_penalty += miss_penalty.item()  # Accumulate miss penalty\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    avg_miss_penalty = total_miss_penalty / len(data_loader)\n",
    "    return avg_loss, avg_miss_penalty  # Return average loss and miss penalty\n",
    "\n",
    "\n",
    "\n",
    "def validate_epoch(model, data_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    total_miss_penalty = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            if batch[0] is None:\n",
    "                continue  # Skip empty batches\n",
    "\n",
    "\n",
    "            game_states_batch, lengths_batch, missed_chars_batch, labels_batch = batch\n",
    "            game_states_batch, lengths_batch, missed_chars_batch = \\\n",
    "                game_states_batch.to(device), lengths_batch, missed_chars_batch.to(device)\n",
    "\n",
    "            outputs = model(game_states_batch, lengths_batch, missed_chars_batch)\n",
    "            model_output_shape = outputs.shape\n",
    "            reshaped_labels = pad_and_reshape_labels(labels_batch, model_output_shape).to(device)\n",
    "\n",
    "            loss, miss_penalty = model.calculate_loss(outputs, reshaped_labels, \\\n",
    "                                                      lengths_batch, missed_chars_batch, 27)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            total_miss_penalty += miss_penalty.item()  # Accumulate miss penalty\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    avg_miss_penalty = total_miss_penalty / len(data_loader)\n",
    "    return avg_loss, avg_miss_penalty  # \n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "#     val_loss = validate_epoch(model, val_loader, device)\n",
    "    \n",
    "#     print(f\"Epoch {epoch}: Training Loss: {train_loss}, Validation Loss: {val_loss}\")\n",
    "#     # You can add code to save model checkpoints if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "def train_model(model, train_data, val_data, num_epochs, optimizer, scheduler, device):\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, \\\n",
    "        collate_fn=custom_collate_fn)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, \\\n",
    "        collate_fn=custom_collate_fn)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_miss_penalty = train_epoch(model, train_loader, \\\n",
    "            optimizer, device)\n",
    "        val_loss, val_miss_penalty = validate_epoch(model, \\\n",
    "            val_loader, device)\n",
    "\n",
    "        scheduler.step(val_loss)  # Adjust LR based on validation loss\n",
    "\n",
    "        print(f\"Epoch {epoch}: Training Loss: {train_loss}, Miss Penalty: \\\n",
    "            {train_miss_penalty}, Validation Loss: {val_loss}, Validation Miss Penalty: {val_miss_penalty}\")\n",
    "        # Save model checkpoints if needed\n",
    "\n",
    "def k_fold_cross_validate(model, dataset, k, num_epochs, optimizer, scheduler_class, device):\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "        print(f\"Fold {fold}\")\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "        # Initialize a new model for each fold\n",
    "        model = SimpleLSTM(config)\n",
    "        model.to(device)\n",
    "        optimizer = model.optimizer\n",
    "        scheduler = scheduler_class(optimizer)\n",
    "\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "        train_model(model, train_subset, val_subset, num_epochs, optimizer, scheduler, device)\n",
    "\n",
    "\n",
    "        train_model(model, train_subset, val_subset, num_epochs, optimizer, scheduler, device)\n",
    "\n",
    "# Usage example\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "scheduler_class = torch.optim.lr_scheduler.ReduceLROnPlateau  # Example scheduler class\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "k_fold_cross_validate(model, processed_dataset, \\\n",
    "    5, num_epochs, optimizer, scheduler_class, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.dataset import ProcessedHangmanDataset\n",
    "from scr.custom_sampler import PerformanceBasedSampler\n",
    "\n",
    "\n",
    "print(f\"Total number of data points in the dataset: {len(processed_dataset)}\")\n",
    "\n",
    "# Initialize the sampler\n",
    "sampler = PerformanceBasedSampler(\n",
    "    processed_dataset, \n",
    "    performance_metrics,\n",
    "    max_word_length=max_word_length\n",
    ")\n",
    "\n",
    "print(f\"Sampler created with {len(sampler)} indices.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices = list(sampler)[:10]  # Get the first 10 sampled indices\n",
    "print(\"Sampled indices:\", sample_indices)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    data_point = processed_dataset[idx]\n",
    "    print(f\"Data at index {idx}: {data_point}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.utils import print_scenarios\n",
    "\n",
    "def process_pkl_files(base_dir):\n",
    "    pkl_list = []\n",
    "\n",
    "    # Iterate over all batch directories\n",
    "    for batch_dir in sorted(base_dir.iterdir(), key=lambda x: int(x.name) if x.name.isdigit() else float('inf')):\n",
    "        if batch_dir.is_dir():\n",
    "            # List all .pkl files in the current batch directory\n",
    "            pkl_files = list(batch_dir.glob(\"*.pkl\"))\n",
    "\n",
    "            for pkl_file in pkl_files:\n",
    "                try:\n",
    "                    with open(pkl_file, 'rb') as file:\n",
    "                        game_data = pickle.load(file)\n",
    "                except IOError as e:\n",
    "                    print(f\"Error reading file {pkl_file}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                # Processing each pickle file\n",
    "                pkl_list.extend(process_pkl_file(pkl_file, game_data))\n",
    "\n",
    "    return pkl_list\n",
    "\n",
    "def process_pkl_file(pkl_file, game_data):\n",
    "    file_scenarios = []\n",
    "    for data in game_data:\n",
    "        game_won, guesses = data\n",
    "        word, initial_state, difficulty, outcome = extract_info_from_filename(pkl_file)\n",
    "        \n",
    "        # Create a scenario dictionary for each data tuple\n",
    "        scenario = {\n",
    "            'word': word,\n",
    "            'difficulty': difficulty,\n",
    "            'outcome': outcome,\n",
    "            'data': (game_won, guesses)\n",
    "        }\n",
    "        file_scenarios.append((pkl_file, scenario))  # Add scenario to the list\n",
    "\n",
    "    return file_scenarios\n",
    "\n",
    "def extract_info_from_filename(pkl_file):\n",
    "    parts = pkl_file.stem.split('_from_')\n",
    "    word_and_state = parts[0].split('_')\n",
    "    word = '_'.join(word_and_state[:-1])\n",
    "    initial_state = word_and_state[-1]\n",
    "    difficulty, outcome = parts[1].split('_')[-2:]\n",
    "    return word, initial_state, difficulty, outcome\n",
    "\n",
    "# def print_scenarios(scenarios):\n",
    "#     # Assuming this function is defined elsewhere\n",
    "#     pass\n",
    "\n",
    "# Process all pickle files\n",
    "pkl_list = process_pkl_files(base_dataset_dir)\n",
    "\n",
    "# Accessing an individual pickle file's content by index\n",
    "index_to_access = 0  # Change this index to access different files\n",
    "if index_to_access < len(pkl_list):\n",
    "    file_path, scenario = pkl_list[index_to_access]\n",
    "    print(f\"Contents of {file_path}:\")\n",
    "    print_scenarios([scenario])  # Wrap scenario in a list for the function\n",
    "else:\n",
    "    print(f\"No pickle file at index {index_to_access}\")\n",
    "\n",
    "No pickle file at index 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_list = []\n",
    "\n",
    "# Iterate over all batch directories\n",
    "for batch_dir in sorted(base_dataset_dir.iterdir(), \\\n",
    "    key=lambda x: int(x.name) if x.name.isdigit() else float('inf')):\n",
    "    if batch_dir.is_dir():\n",
    "        # List all .pkl files in the current batch directory\n",
    "        pkl_files = list(batch_dir.glob(\"*.pkl\"))\n",
    "\n",
    "        for pkl_file in pkl_files:\n",
    "            with open(pkl_file, 'rb') as file:\n",
    "                game_data = pickle.load(file)\n",
    "                # Extract information from file name\n",
    "                parts = pkl_file.stem.split('_from_')\n",
    "                word_and_statet = parts[0].split('_')\n",
    "                word = '_'.join(word_and_state[:-1])\n",
    "                initial_state = word_and_state[-1]\n",
    "                difficulty, outcome = parts[1].split('_')[-2:]\n",
    "\n",
    "                # Assuming game_data is a list of tuples (game_won, guesses)\n",
    "                for data in game_data:\n",
    "                    game_won, guesses = data\n",
    "                    # Create a scenario dictionary for each data tuple\n",
    "                    scenario = {\n",
    "                        'word': word,\n",
    "                        'difficulty': difficulty,\n",
    "                        'outcome': outcome,\n",
    "                        'data': (game_won, guesses)\n",
    "                    }\n",
    "                    pkl_list.append((pkl_file, scenario))  # Add scenario to the list\n",
    "\n",
    "# Accessing an individual pickle file's content by index\n",
    "index_to_access = 0  # Change this index to access different files\n",
    "if index_to_access < len(pkl_list):\n",
    "    file_path, scenario = pkl_list[index_to_access]\n",
    "    print(f\"Contents of {file_path}:\")\n",
    "    print_scenarios([scenario])  # Wrap scenario in a list for the function\n",
    "else:\n",
    "    print(f\"No pickle file at index {index_to_access}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optiver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
