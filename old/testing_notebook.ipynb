{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "import sys\n",
    "# Custom library paths\n",
    "sys.path.extend(['../'])\n",
    "\n",
    "from scr.utils import set_seed\n",
    "from scr.utils import read_words\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from scr.feature_engineering import *\n",
    "from scr.rnn import *\n",
    "from scr.model_checkpoint_manager import *\n",
    "from scr.utils import *\n",
    "from scr.game import  *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model reading with best hypers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Assuming models_dir is a Path object pointing to your main models directory\n",
    "models_dir = Path('models')  # Replace with actual path\n",
    "\n",
    "# Paths\n",
    "best_model_dir = models_dir / 'best_model'\n",
    "config_file_path = best_model_dir / 'config.yml'\n",
    "\n",
    "# Load the configuration\n",
    "with open(config_file_path, 'r') as file:\n",
    "    loaded_config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "# Assuming RNN is your model class and loaded_config is the configuration dictionary\n",
    "model = RNN(loaded_config)\n",
    "# Path to the saved model state\n",
    "final_model_path = best_model_dir / 'final_model.pth'\n",
    "\n",
    "# Load the model's state dictionary\n",
    "model.load_state_dict(torch.load(final_model_path)) # , map_location=torch.device('cuda')))\n",
    "# model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the number of words to a smaller number for debugging\n",
    "train = word_list = read_words('/home/sayem/Desktop/Hangman/words_250000_train.txt', limit=None)\n",
    "\n",
    "test = unseen_words = read_words('/home/sayem/Desktop/Hangman/20k.txt', limit=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Playing games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary functions\n",
    "from scr.feature_engineering import \\\n",
    "    process_single_word, get_missed_characters\n",
    "    \n",
    "from scr.game import predict_next_character, simulate_game\n",
    "from scr.rnn import RNN\n",
    "import random\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "char_frequency = calculate_char_frequencies(word_list) # dont change\n",
    "max_word_length = max(len(word) for word in word_list) # dont change\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "def play_multiple_games(model, num_games, word_list, \\\n",
    "    char_to_idx, idx_to_char, char_frequency, max_word_length, device):\n",
    "    game_results = []\n",
    "    for _ in range(num_games):\n",
    "        random_word = random.choice(word_list)\n",
    "        with torch.no_grad():\n",
    "            won, final_word, attempts_used = simulate_game(\n",
    "                model, \n",
    "                random_word, \n",
    "                char_to_idx, \n",
    "                idx_to_char, \n",
    "                char_frequency, \n",
    "                max_word_length, \n",
    "                device,\n",
    "                if_init_guess=False,\n",
    "                normalize=True, \n",
    "                max_attempts=6\n",
    "            )\n",
    "        game_results.append((won, final_word, attempts_used))\n",
    "    return game_results\n",
    "\n",
    "num_games = 1000\n",
    "\n",
    "results = play_multiple_games(model, num_games, \\\n",
    "    unseen_words, char_to_idx, idx_to_char, \\\n",
    "        char_frequency, max_word_length, device)\n",
    "\n",
    "# Analyzing results\n",
    "total_wins = sum(result[0] for result in results)\n",
    "\n",
    "( total_wins / num_games) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_missed_characters('___', set(), char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optiver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
