{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "import sys\n",
    "# Custom library paths\n",
    "sys.path.extend(['../', './scr'])\n",
    "\n",
    "from scr.utils import set_seed\n",
    "from scr.utils import read_words\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Reading and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.feature_engineering import build_feature_set, \\\n",
    "    process_single_word_inference\n",
    "from scr.utils import *\n",
    "\n",
    "import random\n",
    "\n",
    "# MASK_PROB = 0.5\n",
    "\n",
    "# Limit the number of words to a smaller number for debugging\n",
    "word_list = read_words('/home/sayem/Desktop/Hangman/words_250000_train.txt', limit=10**4)\n",
    "\n",
    "# # # Randomly select 1000 words\n",
    "# # unseen_words = random.sample(word_list, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aaa'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scr.feature_engineering import add_features_for_training, calculate_char_frequencies\n",
    "import random\n",
    "# Initialize lists for features, labels, missed characters, and original words\n",
    "all_features, all_labels, all_missed_chars, original_words = [], [], [], []\n",
    "\n",
    "char_frequency = calculate_char_frequencies(word_list)\n",
    "max_word_length = max(len(word) for word in word_list)\n",
    "MASK_PROB = 0.5\n",
    "NGRAM_N = 2\n",
    "\n",
    "feature_set, label, missed_chars = add_features_for_training(\n",
    "        word_list[0], char_frequency, max_word_length, MASK_PROB, NGRAM_N)\n",
    "\n",
    "all_features, all_labels, all_missed_chars, original_words = [], [], [], []\n",
    "\n",
    "for word in word_list:\n",
    "    # Process each word to get its features, label, and missed characters\n",
    "    feature_set, label, missed_chars = add_features_for_training(\n",
    "        word, char_frequency, max_word_length, MASK_PROB, NGRAM_N\n",
    "    )\n",
    "\n",
    "    # Add features and labels to the lists without squeezing\n",
    "    all_features.append(feature_set)\n",
    "    all_labels.append(torch.tensor(label, dtype=torch.float))\n",
    "    all_missed_chars.append(missed_chars)\n",
    "    original_words.append(word)  # Store the original word\n",
    "\n",
    "# Convert lists to tensors\n",
    "all_features_tensor = [features.squeeze(0) for features in all_features]  # Remove batch dimension\n",
    "labels_tensor = [label.squeeze(0) for label in all_labels]  # Remove batch dimension\n",
    "missed_chars_tensor = [missed_chars.squeeze(0) for missed_chars in all_missed_chars]  # Remove batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1200, 0.0000, 0.0000, 1.0000],\n",
       "        [0.0000, 0.1200, 1.0000, 0.0000, 1.0000],\n",
       "        [1.0000, 0.1200, 2.0000, 0.1791, 1.0000]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.feature_engineering import process_single_word_inference\n",
    "\n",
    "def process_inference_word(word, char_frequency, max_word_length, ngram_n=2):\n",
    "    feature_set, missed_chars = process_single_word_inference(word, \\\n",
    "        char_frequency, max_word_length, ngram_n=ngram_n)\n",
    "    return feature_set.squeeze(0), missed_chars.squeeze(0)  # Remove batch dimension\n",
    "\n",
    "# Example usage\n",
    "inference_word = \"_a_\"\n",
    "inference_features, inference_missed_chars = \\\n",
    "    process_inference_word(inference_word, char_frequency, max_word_length, ngram_n=NGRAM_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1200, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.1200, 1.0000, 0.1791, 1.0000],\n",
       "        [0.0000, 0.1200, 2.0000, 0.0000, 1.0000]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_missed_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.dataset import HangmanDataset, collate_fn\n",
    "\n",
    "dataset = HangmanDataset(all_features_tensor, \\\n",
    "    labels_tensor, missed_chars_tensor, original_words)\n",
    "\n",
    "# dataset[100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of iterating over the DataLoader\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# data_loader = DataLoader(dataset, batch_size=32, \\\n",
    "#         shuffle=True, collate_fn=collate_fn)\n",
    "# i = 0\n",
    "# for i, batch in enumerate(data_loader):\n",
    "#     inputs, labels, miss_chars, lengths, original_words = batch\n",
    "#     print(f\"Batch {i}: Inputs Shape: {inputs.shape}, Labels Shape: {labels.shape}, \\\n",
    "# Lengths: {lengths}, Miss Chars: {miss_chars}, Original Words: {original_words}\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In your main script or Jupyter Notebook\n",
    "from scr.model import RNN\n",
    "from scr.feature_engineering import process_single_word_inference, \\\n",
    "    char_to_idx, idx_to_char, calculate_char_frequencies, \\\n",
    "        get_missed_characters\n",
    "from scr.game import simulate_game, \\\n",
    "    predict_next_character\n",
    "\n",
    "# Configuration for the RNN model\n",
    "# Configuration for the RNN model\n",
    "config = {\n",
    "    'rnn': 'LSTM',\n",
    "    'vocab_size': 27,  # Assuming 26 letters + 1 for underscore\n",
    "    'hidden_dim': 128,\n",
    "    'num_layers': 2,\n",
    "    'embedding_dim': 150,\n",
    "    'output_mid_features': 100,\n",
    "    'miss_linear_dim': 50,\n",
    "    'dropout': 0.5,\n",
    "    'use_embedding': True,\n",
    "    'lr': 0.0001,\n",
    "    'input_feature_size': 5 # Number of features excluding the embedding dimension\n",
    "}\n",
    "\n",
    "# Initialize RNN model\n",
    "model = RNN(config)\n",
    "model = model.to(device)\n",
    "\n",
    "model.save_model('models/model.pth') \n",
    "\n",
    "# Prepare your dataset, train the model, etc.\n",
    "\n",
    "# # Example of using predict_next_character in a game scenario\n",
    "# word = \"apple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.load_model(RNN, filename='models/model.pth', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_masked_word = \"_ppl_\"\n",
    "\n",
    "# missed_chars = get_missed_characters(word, char_to_idx)\n",
    "\n",
    "predicted_char = predict_next_character(model, current_masked_word, \\\n",
    "    char_frequency, max_word_length)\n",
    "\n",
    "# predicted_index = predict_next_character_beam_search(model, current_masked_word, \\\n",
    "#     missed_chars, \\\n",
    "#     char_frequency, max_word_length, \\\n",
    "#     device, normalize=True, beam_width=3)\n",
    "        \n",
    "# predicted_char = idx_to_char[predicted_index]\n",
    "\n",
    "predicted_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Import the necessary functions\n",
    "# from scr.feature_engineering import \\\n",
    "#     process_single_word, get_missed_characters\n",
    "\n",
    "from scr.game import predict_next_character, simulate_game\n",
    "from scr.model import RNN\n",
    "import random\n",
    "# random.seed(400)\n",
    "# Your existing code for initializing the model, etc.\n",
    "\n",
    "def play_multiple_games(model, num_games, word_list, \\\n",
    "    char_to_idx, idx_to_char, char_frequency, max_word_length, device):\n",
    "    game_results = []\n",
    "    for _ in range(num_games):\n",
    "        random_word = random.choice(word_list)\n",
    "        with torch.no_grad():\n",
    "            won, final_word, attempts_used = simulate_game(\n",
    "                model, \n",
    "                random_word, \n",
    "                char_to_idx, \n",
    "                idx_to_char, \n",
    "                char_frequency, \n",
    "                max_word_length, \n",
    "                device, \n",
    "                normalize=True, \n",
    "                max_attempts=6\n",
    "            )\n",
    "        game_results.append((won, final_word, attempts_used))\n",
    "        \n",
    "    return game_results\n",
    "\n",
    "num_games = 1000\n",
    "results = play_multiple_games(model, num_games, \\\n",
    "    word_list, char_to_idx, idx_to_char, \\\n",
    "        char_frequency, max_word_length, device)\n",
    "\n",
    "# Analyzing results\n",
    "total_wins = sum(result[0] for result in results)\n",
    "\n",
    "(total_wins / num_games) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "def train_one_epoch(model, data_loader, optimizer, device=device):\n",
    "    total_actual_penalty = 0\n",
    "    total_miss_penalty = 0\n",
    "    total_batches = 0\n",
    "\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        inputs, labels, miss_chars, lengths, _ = batch\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        miss_chars = miss_chars.to(device)\n",
    "        lengths = lengths # .to(device)\n",
    "\n",
    "        # print(f\"Batch {i}: Inputs Shape: {inputs.shape}, Labels Shape: {labels.shape}, \\\n",
    "        # Lengths: {lengths.shape}, Miss Chars: {miss_chars.shape}\")\n",
    "\n",
    "        # Run the model\n",
    "        outputs = model(inputs, lengths, miss_chars)\n",
    "        # print(f'NN output: {outputs.shape}')\n",
    "\n",
    "        # # Flatten output for loss calculation (if necessary)\n",
    "        # outputs = outputs.view(-1, outputs.shape[-1])\n",
    "        # print(f'NN output (view): {outputs.shape}')\n",
    "\n",
    "        # labels = labels.view(-1).long()\n",
    "\n",
    "        # print(labels.shape)\n",
    "\n",
    "        # Calculate the custom loss\n",
    "        actual_penalty, miss_penalty = model.calculate_loss(outputs, \\\n",
    "            labels, lengths, miss_chars, vocab_size=27, use_cuda=True)\n",
    "\n",
    "        # print(actual_penalty)\n",
    "        # print(miss_penalty)\n",
    "\n",
    "        total_actual_penalty += actual_penalty.item()\n",
    "        total_miss_penalty += miss_penalty.item()\n",
    "        total_batches += 1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        actual_penalty.backward()  # Backpropagation for the actual_penalty\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_actual_penalty = total_actual_penalty / total_batches if total_batches > 0 else 0\n",
    "    avg_miss_penalty = total_miss_penalty / total_batches if total_batches > 0 else 0\n",
    "    return avg_actual_penalty, avg_miss_penalty\n",
    "\n",
    "\n",
    "\n",
    "# import random\n",
    "\n",
    "# def validate_one_epoch(model, val_loader, device=device, max_games_per_epoch=1000):\n",
    "#     model.eval()\n",
    "#     total_wins = 0\n",
    "#     total_games = 0\n",
    "\n",
    "#     # Collect all words from the validation loader\n",
    "#     all_words = []\n",
    "#     for batch in val_loader:\n",
    "#         batch_original_words = batch[-1]  # Adjust according to your batch structure\n",
    "#         all_words.extend(batch_original_words)\n",
    "\n",
    "#     # Randomly sample a set number of words for this epoch's validation\n",
    "#     selected_words = random.sample(all_words, min(max_games_per_epoch, len(all_words)))\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for word in selected_words:\n",
    "#             won, final_word, attempts_used = simulate_game(\n",
    "#                 model, \n",
    "#                 word, \n",
    "#                 char_to_idx, \n",
    "#                 idx_to_char, \n",
    "#                 char_frequency, \n",
    "#                 max_word_length, \n",
    "#                 device, \n",
    "#                 normalize=True, \n",
    "#                 max_attempts=6\n",
    "#             )\n",
    "#             total_wins += int(won)\n",
    "#             total_games += 1\n",
    "\n",
    "#     accuracy_percentage = (total_wins / total_games) \\\n",
    "#         * 100 if total_games > 0 else 0\n",
    "        \n",
    "#     return accuracy_percentage\n",
    "\n",
    "import random\n",
    "import collections\n",
    "\n",
    "def validate_one_epoch(model, val_loader, char_to_idx, idx_to_char, \\\n",
    "    char_frequency, max_word_length, device, max_games_per_epoch=1000):\n",
    "    model.eval()\n",
    "    total_wins = 0\n",
    "    total_attempts = 0\n",
    "    total_games = 0\n",
    "\n",
    "    win_count_by_length = collections.defaultdict(int)\n",
    "    game_count_by_length = collections.defaultdict(int)\n",
    "\n",
    "    # Collect all words from the validation loader\n",
    "    all_words = []\n",
    "    for batch in val_loader:\n",
    "        batch_original_words = batch[-1]  # Adjust according to your batch structure\n",
    "        all_words.extend(batch_original_words)\n",
    "\n",
    "    # Randomly sample a set number of words for this epoch's validation\n",
    "    selected_words = random.sample(all_words, min(max_games_per_epoch, len(all_words)))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for word in selected_words:\n",
    "            won, final_word, attempts_used = simulate_game(\n",
    "                model, \n",
    "                word, \n",
    "                char_to_idx, \n",
    "                idx_to_char, \n",
    "                char_frequency, \n",
    "                max_word_length, \n",
    "                device, \n",
    "                normalize=True, \n",
    "                max_attempts=6\n",
    "            )\n",
    "            total_wins += int(won)\n",
    "            total_attempts += attempts_used\n",
    "            total_games += 1\n",
    "\n",
    "            word_length = len(word)\n",
    "            win_count_by_length[word_length] += int(won)\n",
    "            game_count_by_length[word_length] += 1\n",
    "\n",
    "    accuracy_percentage = (total_wins / total_games) * 100 if total_games > 0 else 0\n",
    "    average_attempts = total_attempts / total_games if total_games > 0 else 0\n",
    "    win_rate_by_length = {length: (win_count_by_length[length] / game_count_by_length[length]) \n",
    "                          for length in game_count_by_length}\n",
    "\n",
    "    return accuracy_percentage, average_attempts, win_rate_by_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from scr.model import RNN\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "from scr.utils import  *\n",
    "\n",
    "\n",
    "pruner = MedianPruner()\n",
    "\n",
    "# from scr.game import validate_one_epoch\n",
    "# from scr.utils import EarlyStopping # , train_one_epoch  \n",
    "# # Assuming these are in scr.utils\n",
    "\n",
    "def objective(trial, dataset, static_config, num_epochs):\n",
    "    # Dynamic hyperparameters\n",
    "    dynamic_config = optuna_dynamic_hyperparameters(trial)\n",
    "    \n",
    "    # Merge configurations\n",
    "    config = {**static_config, **dynamic_config}\n",
    "\n",
    "    # # Initialize ModelCheckpointManager\n",
    "    # model_checkpoint_manager = ModelCheckpointManager(config)\n",
    "\n",
    "    print(f\"Trial {trial.number}: Configuration - {config}\")  # Debug print\n",
    "\n",
    "\n",
    "    # k-Fold Cross-Validation setup\n",
    "    kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    val_accuracies = []\n",
    "    average_attempts_list = []\n",
    "    win_rate_by_length_list = []\n",
    "\n",
    "    best_accuracy = 0  # Initialize best accuracy for model saving\n",
    "    \n",
    "    best_actual_penalty = None\n",
    "    best_miss_penalty = None\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "        print(f\"Starting Fold {fold+1}\")  # Debug print\n",
    "        train_loader, val_loader = get_data_loaders(dataset, train_idx, val_idx)\n",
    "\n",
    "        # Model initialization and training\n",
    "        model, optimizer = initialize_model(config)\n",
    "        early_stopping = EarlyStopping(patience=10, delta=0.001)\n",
    "\n",
    "        # Initialize the learning rate scheduler\n",
    "        scheduler = StepLR(optimizer, step_size=trial.suggest_int(\"step_size\", 5, 20), \\\n",
    "            gamma=trial.suggest_float(\"gamma\", 0.1, 0.5))\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            avg_actual_penalty, avg_miss_penalty = train_one_epoch(model, train_loader, optimizer)\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Fold {fold+1}: Avg. Actual Penalty - {avg_actual_penalty}, Avg. Miss Penalty - {avg_miss_penalty}\")  # Debug print\n",
    "            \n",
    "            scheduler.step()\n",
    "\n",
    "            validation_metrics = validate_one_epoch(model, val_loader, char_to_idx, idx_to_char, \\\n",
    "                char_frequency, max_word_length, device)\n",
    "\n",
    "            validation_accuracy, average_attempts, win_rate_by_length = validation_metrics\n",
    "\n",
    "            val_accuracies.append(validation_accuracy)\n",
    "            average_attempts_list.append(average_attempts)\n",
    "            win_rate_by_length_list.append(win_rate_by_length)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}: Validation Accuracy - {validation_accuracy}\")\n",
    "            trial.report(validation_accuracy, epoch)\n",
    "\n",
    "            # Save the model if it is the best so far\n",
    "            if validation_accuracy > best_accuracy:\n",
    "                best_accuracy = validation_accuracy\n",
    "\n",
    "                print(f\"New best model found: Accuracy - {best_accuracy}\")  # Debug print\n",
    "\n",
    "                best_actual_penalty = avg_actual_penalty\n",
    "                best_miss_penalty = avg_miss_penalty\n",
    "                \n",
    "                model.save_model()\n",
    "\n",
    "            if early_stopping(validation_accuracy):\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")  # Debug print\n",
    "                break\n",
    "\n",
    "            # Check if the trial should be pruned\n",
    "            if trial.should_prune():\n",
    "                print(\"Trial pruned.\")  # Debug print\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "\n",
    "        val_accuracies.append(validation_accuracy)\n",
    "        average_attempt = \n",
    "\n",
    "    average_accuracy = sum(val_accuracies) / len(val_accuracies)\n",
    "    \n",
    "    print(f\"Average accuracy over folds: {average_accuracy}\")  # Debug print\n",
    "    \n",
    "    return average_accuracy\n",
    "\n",
    "\n",
    "# Utility functions (for cleaner code)\n",
    "def get_data_loaders(dataset, train_idx, val_idx):\n",
    "    train_subset = Subset(dataset, train_idx)\n",
    "    val_subset = Subset(dataset, val_idx)\n",
    "    train_loader = DataLoader(train_subset, batch_size=32, \\\n",
    "        shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_subset, batch_size=32, \\\n",
    "        shuffle=False, collate_fn=collate_fn)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def initialize_model(config):\n",
    "    model = RNN(config)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    return model, optimizer\n",
    "\n",
    "# Utility functions\n",
    "def optuna_dynamic_hyperparameters(trial):\n",
    "    # Define and return dynamic hyperparameters based on the trial\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-3, log=True)\n",
    "    hidden_dim = trial.suggest_categorical('hidden_dim', [128, 256, 512])\n",
    "    embedding_dim = trial.suggest_categorical('embedding_dim', [50, 100, 150])\n",
    "    output_mid_features = trial.suggest_categorical('output_mid_features', [50, 100, 200])\n",
    "    miss_linear_dim = trial.suggest_categorical('miss_linear_dim', [50, 100, 150])\n",
    "    dropout = trial.suggest_float('dropout', 0.2, 0.5)\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "\n",
    "    return {\n",
    "        'lr': lr,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'embedding_dim': embedding_dim,\n",
    "        'output_mid_features': output_mid_features,\n",
    "        'miss_linear_dim': miss_linear_dim,\n",
    "        'dropout': dropout,\n",
    "        'num_layers': num_layers\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-16 01:05:29,568] A new study created in memory with name: no-name-fa1adeef-4cf8-41b2-b42f-fc4393879305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0: Configuration - {'rnn': 'LSTM', 'vocab_size': 27, 'use_embedding': True, 'input_feature_size': 5, 'models': 'models', 'lr': 0.0008684798330525045, 'hidden_dim': 256, 'embedding_dim': 50, 'output_mid_features': 200, 'miss_linear_dim': 50, 'dropout': 0.4314557296794439, 'num_layers': 3}\n",
      "Starting Fold 1\n",
      "Epoch 1/2, Fold 1: Avg. Actual Penalty - 0.08094604259729385, Avg. Miss Penalty - -3.7455215272903444\n",
      "Epoch 1: Validation Accuracy - 3.6999999999999997\n",
      "New best model found: Accuracy - 3.6999999999999997\n",
      "Epoch 2/2, Fold 1: Avg. Actual Penalty - 0.07475450190901756, Avg. Miss Penalty - -4.132945240020752\n",
      "Epoch 2: Validation Accuracy - 4.7\n",
      "New best model found: Accuracy - 4.7\n",
      "Starting Fold 2\n",
      "Epoch 1/2, Fold 2: Avg. Actual Penalty - 0.08042967519164085, Avg. Miss Penalty - -3.74269801235199\n",
      "Epoch 1: Validation Accuracy - 4.2\n",
      "Epoch 2/2, Fold 2: Avg. Actual Penalty - 0.07409329175949096, Avg. Miss Penalty - -4.130918335914612\n",
      "Epoch 2: Validation Accuracy - 2.4\n",
      "Starting Fold 3\n",
      "Epoch 1/2, Fold 3: Avg. Actual Penalty - 0.08090178808569908, Avg. Miss Penalty - -3.7289788208007812\n",
      "Epoch 1: Validation Accuracy - 4.6\n",
      "Epoch 2/2, Fold 3: Avg. Actual Penalty - 0.07516194896399975, Avg. Miss Penalty - -4.085890714645386\n",
      "Epoch 2: Validation Accuracy - 3.5999999999999996\n",
      "Starting Fold 4\n",
      "Epoch 1/2, Fold 4: Avg. Actual Penalty - 0.080871760815382, Avg. Miss Penalty - -3.7171745748519895\n",
      "Epoch 1: Validation Accuracy - 3.1\n",
      "Epoch 2/2, Fold 4: Avg. Actual Penalty - 0.07525183111429215, Avg. Miss Penalty - -4.07236871623993\n",
      "Epoch 2: Validation Accuracy - 3.6999999999999997\n",
      "Starting Fold 5\n",
      "Epoch 1/2, Fold 5: Avg. Actual Penalty - 0.08062976160645485, Avg. Miss Penalty - -3.7393607664108277\n",
      "Epoch 1: Validation Accuracy - 3.9\n",
      "Epoch 2/2, Fold 5: Avg. Actual Penalty - 0.07419655641913414, Avg. Miss Penalty - -4.157618386268616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-16 01:07:07,189] Trial 0 finished with value: 3.6 and parameters: {'lr': 0.0008684798330525045, 'hidden_dim': 256, 'embedding_dim': 50, 'output_mid_features': 200, 'miss_linear_dim': 50, 'dropout': 0.4314557296794439, 'num_layers': 3, 'step_size': 13, 'gamma': 0.15451273875184893}. Best is trial 0 with value: 3.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Validation Accuracy - 3.5999999999999996\n",
      "Average accuracy over folds: 3.6\n",
      "Trial 1: Configuration - {'rnn': 'LSTM', 'vocab_size': 27, 'use_embedding': True, 'input_feature_size': 5, 'models': 'models', 'lr': 9.000202955636949e-05, 'hidden_dim': 128, 'embedding_dim': 100, 'output_mid_features': 200, 'miss_linear_dim': 150, 'dropout': 0.28252560244380076, 'num_layers': 1}\n",
      "Starting Fold 1\n",
      "Epoch 1/2, Fold 1: Avg. Actual Penalty - 0.08673496228456497, Avg. Miss Penalty - -3.2235816831588746\n",
      "Epoch 1: Validation Accuracy - 3.3000000000000003\n",
      "New best model found: Accuracy - 3.3000000000000003\n",
      "Epoch 2/2, Fold 1: Avg. Actual Penalty - 0.07925721889734268, Avg. Miss Penalty - -3.726433588027954\n",
      "Epoch 2: Validation Accuracy - 4.3\n",
      "New best model found: Accuracy - 4.3\n",
      "Starting Fold 2\n",
      "Epoch 1/2, Fold 2: Avg. Actual Penalty - 0.08700583252310753, Avg. Miss Penalty - -3.1996726665496826\n",
      "Epoch 1: Validation Accuracy - 4.0\n",
      "Epoch 2/2, Fold 2: Avg. Actual Penalty - 0.07891854158043861, Avg. Miss Penalty - -3.7310169200897216\n",
      "Epoch 2: Validation Accuracy - 3.8\n",
      "Starting Fold 3\n",
      "Epoch 1/2, Fold 3: Avg. Actual Penalty - 0.08669864708185196, Avg. Miss Penalty - -3.2345193243026733\n",
      "Epoch 1: Validation Accuracy - 3.5999999999999996\n",
      "Epoch 2/2, Fold 3: Avg. Actual Penalty - 0.07932001909613609, Avg. Miss Penalty - -3.716931962013245\n",
      "Epoch 2: Validation Accuracy - 4.1000000000000005\n",
      "Starting Fold 4\n",
      "Epoch 1/2, Fold 4: Avg. Actual Penalty - 0.08736651560664177, Avg. Miss Penalty - -3.1934067554473877\n",
      "Epoch 1: Validation Accuracy - 3.1\n",
      "Epoch 2/2, Fold 4: Avg. Actual Penalty - 0.07939961186051368, Avg. Miss Penalty - -3.7251082983016968\n",
      "Epoch 2: Validation Accuracy - 2.7\n",
      "Starting Fold 5\n",
      "Epoch 1/2, Fold 5: Avg. Actual Penalty - 0.08684257379174233, Avg. Miss Penalty - -3.2238252410888673\n",
      "Epoch 1: Validation Accuracy - 4.3\n",
      "Epoch 2/2, Fold 5: Avg. Actual Penalty - 0.07913773131370544, Avg. Miss Penalty - -3.724242994308472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-16 01:08:12,595] Trial 1 finished with value: 3.8 and parameters: {'lr': 9.000202955636949e-05, 'hidden_dim': 128, 'embedding_dim': 100, 'output_mid_features': 200, 'miss_linear_dim': 150, 'dropout': 0.28252560244380076, 'num_layers': 1, 'step_size': 5, 'gamma': 0.20047126915997204}. Best is trial 1 with value: 3.8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Validation Accuracy - 4.1000000000000005\n",
      "Average accuracy over folds: 3.8\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define your models directory path\n",
    "models_dir = Path('models')\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Assuming missed_chars_tensor is a list of tensors for missed characters\n",
    "dataset = HangmanDataset(all_features_tensor, \\\n",
    "    labels_tensor, missed_chars_tensor, original_words)\n",
    "\n",
    "# Static configuration\n",
    "static_config = {\n",
    "    'rnn': 'LSTM',\n",
    "    'vocab_size': 27,  # 26 English alphabets + 1 (e.g., for underscore)\n",
    "    'use_embedding': True,  # Typically a design choice\n",
    "    'input_feature_size': 5,  # Based on your feature engineering strategy\n",
    "    'models': str(models_dir)\n",
    "}\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define num_epochs for training in each fold\n",
    "num_epochs = 2 # Adjust as needed\n",
    "N_TRIAL = 2\n",
    "\n",
    "# ====================================================== #\n",
    "# Create Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, dataset, \\\n",
    "    static_config, num_epochs), n_trials=N_TRIAL)\n",
    "# ====================================================== #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "Value: 3.8\n",
      "Params: \n",
      "    lr: 9.000202955636949e-05\n",
      "    hidden_dim: 128\n",
      "    embedding_dim: 100\n",
      "    output_mid_features: 200\n",
      "    miss_linear_dim: 150\n",
      "    dropout: 0.28252560244380076\n",
      "    num_layers: 1\n",
      "    step_size: 5\n",
      "    gamma: 0.20047126915997204\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "# Output the best hyperparameters\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"Value: {trial.value}\")\n",
    "print(\"Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 9.000202955636949e-05,\n",
       " 'hidden_dim': 128,\n",
       " 'embedding_dim': 100,\n",
       " 'output_mid_features': 200,\n",
       " 'miss_linear_dim': 150,\n",
       " 'dropout': 0.28252560244380076,\n",
       " 'num_layers': 1,\n",
       " 'step_size': 5,\n",
       " 'gamma': 0.20047126915997204}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rnn': 'LSTM',\n",
       " 'vocab_size': 27,\n",
       " 'use_embedding': True,\n",
       " 'input_feature_size': 5,\n",
       " 'models': 'models',\n",
       " 'lr': 9.000202955636949e-05,\n",
       " 'hidden_dim': 128,\n",
       " 'embedding_dim': 100,\n",
       " 'output_mid_features': 200,\n",
       " 'miss_linear_dim': 150,\n",
       " 'dropout': 0.28252560244380076,\n",
       " 'num_layers': 1,\n",
       " 'step_size': 5,\n",
       " 'gamma': 0.20047126915997204}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two dictionaries to form a single configuration\n",
    "config = {**static_config, **best_params}\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dictionaries to form a single configuration\n",
    "config = {**static_config, **best_params}\n",
    "\n",
    "# Initialize the RNN model with the combined configuration\n",
    "model = RNN(config)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# model.load_model(config['LSTM'], 2, 256, trial_number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'STOP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/sayem/Desktop/Hangman/notebook.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sayem/Desktop/Hangman/notebook.ipynb#Y102sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m STOP\n",
      "\u001b[0;31mNameError\u001b[0m: name 'STOP' is not defined"
     ]
    }
   ],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing on unknown data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the necessary functions\n",
    "# from scr.feature_engineering import \\\n",
    "#     process_single_word, get_missed_characters\n",
    "\n",
    "from scr.game import predict_next_character, simulate_game\n",
    "from scr.model import RNN\n",
    "import random\n",
    "# random.seed(400)\n",
    "# Your existing code for initializing the model, etc.\n",
    "\n",
    "def play_multiple_games(model, num_games, word_list, \\\n",
    "    char_to_idx, idx_to_char, char_frequency, max_word_length, device):\n",
    "    game_results = []\n",
    "    for _ in range(num_games):\n",
    "        random_word = random.choice(word_list)\n",
    "        with torch.no_grad():\n",
    "            won, final_word, attempts_used = simulate_game(\n",
    "                model, \n",
    "                random_word, \n",
    "                char_to_idx, \n",
    "                idx_to_char, \n",
    "                char_frequency, \n",
    "                max_word_length, \n",
    "                device, \n",
    "                normalize=True, \n",
    "                max_attempts=6\n",
    "            )\n",
    "        game_results.append((won, final_word, attempts_used))\n",
    "        \n",
    "    return game_results\n",
    "\n",
    "num_games = 1000\n",
    "results = play_multiple_games(model, num_games, \\\n",
    "    word_list, char_to_idx, idx_to_char, \\\n",
    "        char_frequency, max_word_length, device)\n",
    "\n",
    "# Analyzing results\n",
    "total_wins = sum(result[0] for result in results)\n",
    "\n",
    "(total_wins / num_games) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optiver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
