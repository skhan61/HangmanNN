{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "import sys\n",
    "# Custom library paths\n",
    "sys.path.extend(['../', './scr'])\n",
    "\n",
    "from scr.utils import set_seed\n",
    "from scr.utils import read_words\n",
    "from pathlib import Path\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from scr.feature_engineering import \\\n",
    "    calculate_char_frequencies, calculate_word_frequencies\n",
    "from scr.utils import read_words, save_words_to_file\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from scr.dataset import *\n",
    "from scr.game import *\n",
    "from scr.plot_utils import *\n",
    "\n",
    "import gc\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "from scr.utils import print_scenarios\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Read and Shuffle Word List\n",
    "word_list = read_words('data/words_250000_train.txt') # , limit=10000)\n",
    "# word_list = read_words('data/250k.txt', limit=10000)\n",
    "random.shuffle(word_list)\n",
    "\n",
    "# base_dataset_dir = Path('dataset/pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 181840 train words from /media/sayem/510B93E12554BBD1/dataset/50000/train_words.txt\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "NUM_STRATIFIED_SAMPLES = 50000\n",
    "# # # Define the base directory\n",
    "# base_dataset_dir = Path(f'./dataset/{NUM_STRATIFIED_SAMPLES}')\n",
    "base_dataset_dir = Path(f\"/media/sayem/510B93E12554BBD1/dataset/{NUM_STRATIFIED_SAMPLES}\")\n",
    "\n",
    "# Ensuring the base directory and 'pkl' subdirectory exist\n",
    "base_dataset_dir.mkdir(parents=True, exist_ok=True)\n",
    "pkls_dir = base_dataset_dir / 'pkl'\n",
    "pkls_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Paths to the words files\n",
    "train_words_file_path = base_dataset_dir / 'train_words.txt'\n",
    "test_words_file_path = base_dataset_dir / 'test_words.txt'\n",
    "\n",
    "# Read the words from the files\n",
    "try:\n",
    "    train_words = read_words(train_words_file_path)\n",
    "    print(f\"Loaded {len(train_words)} train words from {train_words_file_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {train_words_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/media/sayem/510B93E12554BBD1/dataset/50000')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dataset_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For inference\n",
    "from scr.feature_engineering import *\n",
    "\n",
    "word_frequencies = calculate_word_frequencies(word_list)\n",
    "char_frequency = calculate_char_frequencies(word_list)\n",
    "max_word_length = max(len(word) for word in word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.simple_model import SimpleLSTM\n",
    "from scr.base_model import BaseModel\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from scr.feature_engineering import *\n",
    "\n",
    "# max_word_length = 29 # TODO will remove later\n",
    "# Instantiate and test the model\n",
    "config = {\n",
    "    'embedding_dim': 200,\n",
    "    'hidden_dim': 256,\n",
    "    'num_layers': 2,\n",
    "    'vocab_size': 27,\n",
    "    'max_word_length': max_word_length,\n",
    "    'input_feature_size': 5,\n",
    "    'use_embedding': True,\n",
    "    'miss_linear_dim': 50,\n",
    "    'lr': 0.001\n",
    "}\n",
    "\n",
    "model = SimpleLSTM(config)\n",
    "optimizer = model.optimizer\n",
    "\n",
    "# Assuming 'model' is your trained model instance\n",
    "model.save_model(file_path='models/model.pth') ## TODO: _ will remove later\n",
    "\n",
    "\n",
    "# Assuming the saved model file is 'models/model.pth'\n",
    "model_file_path = 'models/model.pth' ## TODO: _ will remove later\n",
    "\n",
    "# Specify the device to load the model onto\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Load the model\n",
    "# loaded_model = BaseModel.load_model(SimpleLSTM, model_file_path)\n",
    "# # Now `loaded_model` is an instance of `SimpleLSTM` with the state and config loaded\n",
    "\n",
    "# model = loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset Loading and train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/media/sayem/510B93E12554BBD1/dataset/50000/pkl')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkls_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100726\n"
     ]
    }
   ],
   "source": [
    "from scr.dataset import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "from scr.model_training import *\n",
    "\n",
    "# # Load the dataset\n",
    "processed_dataset = ProcessedHangmanDataset(pkls_dir, \\\n",
    "    char_frequency, max_word_length, files_limit=None)\n",
    "    \n",
    "print(len(processed_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['___b____e', 'a_aba___e', 'anaba__ne', 'anaba_ine'],\n",
       " ['a', 'n', 'i', 's'],\n",
       " {'word': 'anabasine',\n",
       "  'initial_state': '___b_____',\n",
       "  'game_state': 'early',\n",
       "  'difficulty': 'easy',\n",
       "  'outcome': 'win',\n",
       "  'word_length': '9'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PyTorch dataset to a list for train_test_split\n",
    "dataset_list = [processed_dataset[i] for i in range(len(processed_dataset))]\n",
    "\n",
    "# Perform an 80%-20% train-test split\n",
    "train_data, val_data = train_test_split(dataset_list, \\\n",
    "    test_size=0.2, random_state=42)\n",
    "\n",
    "val_loader = processed_dataset.create_val_loader(val_data)\n",
    "\n",
    "del dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "# Define the maximum number of games you want to play per epoch\n",
    "max_games_per_epoch = 1000  # Example value, adjust as needed\n",
    "\n",
    "# Assuming train_data_loader is your DataLoader for training data\n",
    "unique_words_set = set()\n",
    "for _, _, _, batch_full_words in val_loader:\n",
    "    unique_words_set.update(batch_full_words)\n",
    "\n",
    "# Group words by their lengths\n",
    "words_by_length = defaultdict(list)\n",
    "for word in unique_words_set:\n",
    "    words_by_length[len(word)].append(word)\n",
    "\n",
    "# Calculate the number of words to select from each length group\n",
    "num_words_per_length = max_games_per_epoch // len(words_by_length)\n",
    "\n",
    "selected_words = []\n",
    "for length, words in words_by_length.items():\n",
    "    random.shuffle(words)\n",
    "    selected_words.extend(words[:num_words_per_length])\n",
    "\n",
    "# # # Now, use 'selected_words' in place of 'unique_words' for game simulation\n",
    "# selected_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Initialize DataLoader outside the loop\n",
    "# batch_size = 64\n",
    "# # train_loader = DataLoader(train_data, \\\n",
    "# #     batch_size=batch_size, \\\n",
    "# #         collate_fn=processed_dataset.custom_collate_fn)\n",
    "# epochs = 10\n",
    "# # model.train()\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     train_loader = DataLoader(train_data, batch_size=batch_size, \\\n",
    "#         collate_fn=processed_dataset.custom_collate_fn)\n",
    "\n",
    "#     train_loss, train_miss_penalty = train_on_data_loader(model, train_loader, device, optimizer)\n",
    "#     print(f\"Epoch {epoch}: Training Loss: {train_loss}, Miss Penalty: {train_miss_penalty}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Untrained Model Performence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.model_training import validate_hangman\n",
    "# Now call the validate_hangman function with this set\n",
    "validation_results = validate_hangman(model, val_loader, \\\n",
    "    char_frequency, max_word_length, device, selected_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~Untrained model performence~\n",
      "Average Loss: 18.828806423899568\n",
      "Miss Penalty: 0.41289582541733083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win Rate: 0.054317548746518104\n",
      "Average Attempts: 5.908077994428969\n",
      "Total Games: 718\n",
      "Total Wins: 39\n",
      "Total Losses: 679\n"
     ]
    }
   ],
   "source": [
    "from scr.plot_utils import *\n",
    "\n",
    "print(f'~Untrained model performence~')\n",
    "# # Print results for character-level validation\n",
    "# print(\"Character Level Validation:\")\n",
    "print(f\"Average Loss: {validation_results['avg_loss']}\")\n",
    "print(f\"Miss Penalty: {validation_results['avg_miss_penalty']}\")\n",
    "\n",
    "\n",
    "game_simulation_results = validation_results[\"game_simulation\"]\n",
    "\n",
    "save_path = Path(f\"plots/{NUM_STRATIFIED_SAMPLES}_untrained_model_performence_word_stats_plot.png\")\n",
    "plot_word_stats(game_simulation_results[\"length_stats\"], save_path)\n",
    "\n",
    "# # Print results for game simulation\n",
    "# print(\"\\nGame Simulation:\")\n",
    "print(f\"Win Rate: {game_simulation_results['win_rate']}\")\n",
    "print(f\"Average Attempts: {game_simulation_results['average_attempts']}\")\n",
    "print(f\"Total Games: {game_simulation_results['total_games']}\")\n",
    "print(f\"Total Wins: {game_simulation_results['total_wins']}\")\n",
    "print(f\"Total Losses: {game_simulation_results['total_losses']}\")\n",
    "# print(\"Word Stats:\", game_simulation_results[\"game_stats\"])\n",
    "# print(\"Word Length Stats:\", game_simulation_results[\"length_stats\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: {'wins': 1, 'losses': 34, 'total_attempts': 208, 'games': 35},\n",
       " 21: {'wins': 2, 'losses': 20, 'total_attempts': 129, 'games': 22},\n",
       " 15: {'wins': 1, 'losses': 34, 'total_attempts': 209, 'games': 35},\n",
       " 22: {'wins': 3, 'losses': 10, 'total_attempts': 72, 'games': 13},\n",
       " 11: {'wins': 2, 'losses': 33, 'total_attempts': 207, 'games': 35},\n",
       " 19: {'wins': 3, 'losses': 32, 'total_attempts': 206, 'games': 35},\n",
       " 3: {'wins': 0, 'losses': 35, 'total_attempts': 210, 'games': 35},\n",
       " 24: {'wins': 2, 'losses': 3, 'total_attempts': 27, 'games': 5},\n",
       " 9: {'wins': 0, 'losses': 35, 'total_attempts': 210, 'games': 35},\n",
       " 18: {'wins': 3, 'losses': 32, 'total_attempts': 203, 'games': 35},\n",
       " 20: {'wins': 6, 'losses': 29, 'total_attempts': 202, 'games': 35},\n",
       " 2: {'wins': 1, 'losses': 34, 'total_attempts': 208, 'games': 35},\n",
       " 17: {'wins': 1, 'losses': 34, 'total_attempts': 208, 'games': 35},\n",
       " 14: {'wins': 0, 'losses': 35, 'total_attempts': 210, 'games': 35},\n",
       " 12: {'wins': 1, 'losses': 34, 'total_attempts': 209, 'games': 35},\n",
       " 10: {'wins': 2, 'losses': 33, 'total_attempts': 207, 'games': 35},\n",
       " 13: {'wins': 1, 'losses': 34, 'total_attempts': 207, 'games': 35},\n",
       " 16: {'wins': 4, 'losses': 31, 'total_attempts': 204, 'games': 35},\n",
       " 4: {'wins': 2, 'losses': 33, 'total_attempts': 207, 'games': 35},\n",
       " 8: {'wins': 0, 'losses': 35, 'total_attempts': 210, 'games': 35},\n",
       " 6: {'wins': 1, 'losses': 34, 'total_attempts': 208, 'games': 35},\n",
       " 7: {'wins': 0, 'losses': 35, 'total_attempts': 210, 'games': 35},\n",
       " 23: {'wins': 2, 'losses': 3, 'total_attempts': 24, 'games': 5},\n",
       " 29: {'wins': 0, 'losses': 1, 'total_attempts': 6, 'games': 1},\n",
       " 28: {'wins': 0, 'losses': 1, 'total_attempts': 6, 'games': 1},\n",
       " 25: {'wins': 0, 'losses': 2, 'total_attempts': 12, 'games': 2},\n",
       " 27: {'wins': 1, 'losses': 1, 'total_attempts': 11, 'games': 2},\n",
       " 1: {'wins': 0, 'losses': 2, 'total_attempts': 12, 'games': 2}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_performance_dict = game_simulation_results[\"length_stats\"]\n",
    "\n",
    "# init_performance_dict = {\n",
    "#     length: {\"wins\": 1, \"losses\": 1, \"total_attempts\": 2, \"games\": 2}\n",
    "#     for length in range(1, max_word_length + 1)\n",
    "# }\n",
    "\n",
    "init_performance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # Initialize DataLoader outside the loop\n",
    "# # from scr.dataset import *\n",
    "# batch_size = 256\n",
    "\n",
    "# custom_sampler = PerformanceBasedSampler(train_data, batch_size, init_performance_dict)\n",
    "# train_loader = DataLoader(train_data, sampler=custom_sampler, \\\n",
    "#     collate_fn=processed_dataset.custom_collate_fn)\n",
    "\n",
    "# # # train_loader = DataLoader(train_data, batch_size=batch_size, \\\n",
    "# # #     collate_fn=processed_dataset.custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%capture\n",
    "\n",
    "# for i, batch in enumerate(train_loader):\n",
    "#     # print(batch)\n",
    "#     # break\n",
    "#     # # if i == 10:\n",
    "#     # #     break\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training Loss: 3.855369137903791, Miss Penalty: 0.03661621908795757\n",
      "Epoch 0: val loss: 16.51804387825212, val miss penalty 0.03594462970351736\n",
      "Win Rate: 0.16991643454038996\n",
      "\n",
      "Epoch 1: Training Loss: 3.805361223895434, Miss Penalty: 0.03633534110903976\n",
      "Epoch 1: val loss: 18.221619068958095, val miss penalty 0.029768001999721787\n",
      "Win Rate: 0.15598885793871867\n",
      "\n",
      "Epoch 2: Training Loss: 3.7744552142433663, Miss Penalty: 0.03614896926103736\n",
      "Epoch 2: val loss: 21.366754138046083, val miss penalty 0.03709219447231691\n",
      "Win Rate: 0.22562674094707522\n",
      "\n",
      "Epoch 3: Training Loss: 3.7642798807754883, Miss Penalty: 0.03612618157926593\n",
      "Epoch 3: val loss: 31.96382179610007, val miss penalty 0.02984225980421366\n",
      "Win Rate: 0.201949860724234\n",
      "\n",
      "Epoch 4: Training Loss: 3.7651465017869783, Miss Penalty: 0.03619539079153814\n",
      "Epoch 4: val loss: 30.995442114458694, val miss penalty 0.0347942233198908\n",
      "Win Rate: 0.1977715877437326\n",
      "\n",
      "Epoch 5: Training Loss: 3.765891452828049, Miss Penalty: 0.03619203050981422\n",
      "Epoch 5: val loss: 43.787542561901205, val miss penalty 0.033714499983143964\n",
      "Win Rate: 0.20612813370473537\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_model(model, train_data, init_performance_dict, \\\n",
    "    val_loader, num_epochs, optimizer, batch_size, \\\n",
    "    unique_words_set, scheduler=None, device=device):\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    n_epochs_stop = 10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Initialize DataLoader outside the loop\n",
    "        custom_sampler = PerformanceBasedSampler(train_data, batch_size, init_performance_dict)\n",
    "        train_loader = DataLoader(train_data, sampler=custom_sampler, \\\n",
    "            collate_fn=processed_dataset.custom_collate_fn)\n",
    "\n",
    "        # # Update only the sampler for each epoch\n",
    "        # custom_sampler = PerformanceBasedSampler(train_data, batch_size, \\\n",
    "        #     init_performance_dict)\n",
    "        # train_loader.sampler = custom_sampler\n",
    "\n",
    "        model.train()\n",
    "        train_loss, train_miss_penalty = train_on_data_loader(model, \\\n",
    "            train_loader, device, optimizer)\n",
    "        print(f\"Epoch {epoch}: Training Loss: {train_loss}, \\\n",
    "Miss Penalty: {train_miss_penalty}\")\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            validation_results = validate_hangman(model, val_loader, \\\n",
    "                char_frequency, max_word_length, device, unique_words_set)\n",
    "            val_loss = validation_results['avg_loss']\n",
    "            val_miss_penalty = validation_results[\"avg_miss_penalty\"]\n",
    "            init_performance_dict = validation_results[\"game_simulation\"][\"length_stats\"]\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == n_epochs_stop:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "        print(f\"Epoch {epoch}: val loss: {val_loss}, val miss penalty {val_miss_penalty}\")\n",
    "        print(f\"Win Rate: {validation_results['game_simulation']['win_rate']}\")\n",
    "        print()\n",
    "\n",
    "# Rest of the code to call train_model\n",
    "\n",
    "# # Assuming model, init_train_data, val_loader, num_epochs, optimizer, batch_size are already defined\n",
    "# init_performance_dict = {length: {\"wins\": 0, \"losses\": 0, \"total_attempts\": 0, \"games\": 0} \\\n",
    "#     for length in range(1, max_word_length + 1)}\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.1, verbose=True)\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 256 # hyperparams\n",
    "\n",
    "train_model(model, train_data, init_performance_dict, \\\n",
    "    val_loader, num_epochs, optimizer, batch_size, selected_words, scheduler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# import torch\n",
    "# from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# def train_model(model, train_data, val_data, num_epochs, optimizer, scheduler, device):\n",
    "#     train_loader = DataLoader(train_data, batch_size=batch_size, \\\n",
    "#         collate_fn=custom_collate_fn)\n",
    "#     val_loader = DataLoader(val_data, batch_size=batch_size, \\\n",
    "#         collate_fn=custom_collate_fn)\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         train_loss, train_miss_penalty = train_epoch(model, train_loader, \\\n",
    "#             optimizer, device)\n",
    "#         val_loss, val_miss_penalty = validate_epoch(model, \\\n",
    "#             val_loader, device)\n",
    "\n",
    "#         scheduler.step(val_loss)  # Adjust LR based on validation loss\n",
    "\n",
    "#         print(f\"Epoch {epoch}: Training Loss: {train_loss}, Miss Penalty: \\\n",
    "#             {train_miss_penalty}, Validation Loss: {val_loss}, Validation Miss Penalty: {val_miss_penalty}\")\n",
    "#         # Save model checkpoints if needed\n",
    "\n",
    "# def k_fold_cross_validate(model, dataset, k, num_epochs, optimizer, scheduler_class, device):\n",
    "#     kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "#     for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "#         print(f\"Fold {fold}\")\n",
    "#         train_subset = Subset(dataset, train_idx)\n",
    "#         val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "#         # Initialize a new model for each fold\n",
    "#         model = SimpleLSTM(config)\n",
    "#         model.to(device)\n",
    "#         optimizer = model.optimizer\n",
    "#         scheduler = scheduler_class(optimizer)\n",
    "\n",
    "#         train_subset = Subset(dataset, train_idx)\n",
    "#         val_subset = Subset(dataset, val_idx)\n",
    "#         train_model(model, train_subset, val_subset, num_epochs, optimizer, scheduler, device)\n",
    "\n",
    "\n",
    "#         train_model(model, train_subset, val_subset, num_epochs, optimizer, scheduler, device)\n",
    "\n",
    "# # Usage example\n",
    "# num_epochs = 10\n",
    "# batch_size = 64\n",
    "# scheduler_class = torch.optim.lr_scheduler.ReduceLROnPlateau  # Example scheduler class\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# k_fold_cross_validate(model, processed_dataset, \\\n",
    "#     5, num_epochs, optimizer, scheduler_class, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trained Model Performence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = processed_dataset.create_val_loader(val_data)\n",
    "\n",
    "\n",
    "# Call the validation function\n",
    "validation_results = validate_hangman(model, val_loader, \\\n",
    "    char_frequency, max_word_length, device)\n",
    "\n",
    "# Access the results\n",
    "character_level_results = validation_results[\"character_level\"]\n",
    "game_simulation_results = validation_results[\"game_simulation\"]\n",
    "\n",
    "from scr.plot_utils import *\n",
    "\n",
    "save_path = Path(f\"plots/{NUM_STRATIFIED_SAMPLES}_trained_model_performence_word_stats_plot.png\")\n",
    "plot_word_stats(game_simulation_results[\"length_stats\"], save_path)\n",
    "\n",
    "# # Print results for character-level validation\n",
    "# print(\"Character Level Validation:\")\n",
    "print(f\"Average Loss: {character_level_results['avg_loss']}\")\n",
    "print(f\"Miss Penalty: {character_level_results['avg_miss_penalty']}\")\n",
    "# print(f\"Character Accuracy: {character_level_results['char_accuracy']}\")\n",
    "# print(f\"Word Accuracy: {character_level_results['word_accuracy']}\")\n",
    "# print(\"Word Statistics:\", character_level_results[\"word_stats\"])  # Updated key\n",
    "\n",
    "# # Print results for game simulation\n",
    "# print(\"\\nGame Simulation:\")\n",
    "print(f\"Win Rate: {game_simulation_results['win_rate']}\")\n",
    "print(f\"Average Attempts: {game_simulation_results['average_attempts']}\")\n",
    "print(f\"Total Games: {game_simulation_results['total_games']}\")\n",
    "print(f\"Total Wins: {game_simulation_results['total_wins']}\")\n",
    "print(f\"Total Losses: {game_simulation_results['total_losses']}\")\n",
    "# print(\"Word Stats:\", game_simulation_results[\"game_stats\"])\n",
    "# print(\"Word Length Stats:\", game_simulation_results[\"length_stats\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Word Stats:\", game_simulation_results[\"game_stats\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_features_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_features_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, device):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "    total_miss_penalty = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        if batch[0] is None:\n",
    "            continue  # Skip empty batches\n",
    "\n",
    "        game_states_batch, lengths_batch, missed_chars_batch, labels_batch = batch\n",
    "        game_states_batch, lengths_batch, missed_chars_batch = \\\n",
    "            game_states_batch.to(device), lengths_batch, missed_chars_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(game_states_batch, lengths_batch, missed_chars_batch)\n",
    "        model_output_shape = outputs.shape\n",
    "        reshaped_labels = pad_and_reshape_labels(labels_batch, model_output_shape).to(device)\n",
    "\n",
    "        loss, miss_penalty = model.calculate_loss(outputs, reshaped_labels, \\\n",
    "                                                  lengths_batch, missed_chars_batch, 27)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_miss_penalty += miss_penalty.item()  # Accumulate miss penalty\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    avg_miss_penalty = total_miss_penalty / len(data_loader)\n",
    "    return avg_loss, avg_miss_penalty  # Return average loss and miss penalty\n",
    "\n",
    "\n",
    "\n",
    "def validate_epoch(model, data_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    total_miss_penalty = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            if batch[0] is None:\n",
    "                continue  # Skip empty batches\n",
    "\n",
    "\n",
    "            game_states_batch, lengths_batch, missed_chars_batch, labels_batch = batch\n",
    "            game_states_batch, lengths_batch, missed_chars_batch = \\\n",
    "                game_states_batch.to(device), lengths_batch, missed_chars_batch.to(device)\n",
    "\n",
    "            outputs = model(game_states_batch, lengths_batch, missed_chars_batch)\n",
    "            model_output_shape = outputs.shape\n",
    "            reshaped_labels = pad_and_reshape_labels(labels_batch, model_output_shape).to(device)\n",
    "\n",
    "            loss, miss_penalty = model.calculate_loss(outputs, reshaped_labels, \\\n",
    "                                                      lengths_batch, missed_chars_batch, 27)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            total_miss_penalty += miss_penalty.item()  # Accumulate miss penalty\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    avg_miss_penalty = total_miss_penalty / len(data_loader)\n",
    "    return avg_loss, avg_miss_penalty  # \n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "#     val_loss = validate_epoch(model, val_loader, device)\n",
    "    \n",
    "#     print(f\"Epoch {epoch}: Training Loss: {train_loss}, Validation Loss: {val_loss}\")\n",
    "#     # You can add code to save model checkpoints if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "def train_model(model, train_data, val_data, num_epochs, optimizer, scheduler, device):\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, \\\n",
    "        collate_fn=custom_collate_fn)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, \\\n",
    "        collate_fn=custom_collate_fn)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_miss_penalty = train_epoch(model, train_loader, \\\n",
    "            optimizer, device)\n",
    "        val_loss, val_miss_penalty = validate_epoch(model, \\\n",
    "            val_loader, device)\n",
    "\n",
    "        scheduler.step(val_loss)  # Adjust LR based on validation loss\n",
    "\n",
    "        print(f\"Epoch {epoch}: Training Loss: {train_loss}, Miss Penalty: \\\n",
    "            {train_miss_penalty}, Validation Loss: {val_loss}, Validation Miss Penalty: {val_miss_penalty}\")\n",
    "        # Save model checkpoints if needed\n",
    "\n",
    "def k_fold_cross_validate(model, dataset, k, num_epochs, optimizer, scheduler_class, device):\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "        print(f\"Fold {fold}\")\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "        # Initialize a new model for each fold\n",
    "        model = SimpleLSTM(config)\n",
    "        model.to(device)\n",
    "        optimizer = model.optimizer\n",
    "        scheduler = scheduler_class(optimizer)\n",
    "\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "        train_model(model, train_subset, val_subset, num_epochs, optimizer, scheduler, device)\n",
    "\n",
    "\n",
    "        train_model(model, train_subset, val_subset, num_epochs, optimizer, scheduler, device)\n",
    "\n",
    "# Usage example\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "scheduler_class = torch.optim.lr_scheduler.ReduceLROnPlateau  # Example scheduler class\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "k_fold_cross_validate(model, processed_dataset, \\\n",
    "    5, num_epochs, optimizer, scheduler_class, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.dataset import ProcessedHangmanDataset\n",
    "from scr.custom_sampler import PerformanceBasedSampler\n",
    "\n",
    "\n",
    "print(f\"Total number of data points in the dataset: {len(processed_dataset)}\")\n",
    "\n",
    "# Initialize the sampler\n",
    "sampler = PerformanceBasedSampler(\n",
    "    processed_dataset, \n",
    "    performance_metrics,\n",
    "    max_word_length=max_word_length\n",
    ")\n",
    "\n",
    "print(f\"Sampler created with {len(sampler)} indices.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices = list(sampler)[:10]  # Get the first 10 sampled indices\n",
    "print(\"Sampled indices:\", sample_indices)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    data_point = processed_dataset[idx]\n",
    "    print(f\"Data at index {idx}: {data_point}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.utils import print_scenarios\n",
    "\n",
    "def process_pkl_files(base_dir):\n",
    "    pkl_list = []\n",
    "\n",
    "    # Iterate over all batch directories\n",
    "    for batch_dir in sorted(base_dir.iterdir(), key=lambda x: int(x.name) if x.name.isdigit() else float('inf')):\n",
    "        if batch_dir.is_dir():\n",
    "            # List all .pkl files in the current batch directory\n",
    "            pkl_files = list(batch_dir.glob(\"*.pkl\"))\n",
    "\n",
    "            for pkl_file in pkl_files:\n",
    "                try:\n",
    "                    with open(pkl_file, 'rb') as file:\n",
    "                        game_data = pickle.load(file)\n",
    "                except IOError as e:\n",
    "                    print(f\"Error reading file {pkl_file}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                # Processing each pickle file\n",
    "                pkl_list.extend(process_pkl_file(pkl_file, game_data))\n",
    "\n",
    "    return pkl_list\n",
    "\n",
    "def process_pkl_file(pkl_file, game_data):\n",
    "    file_scenarios = []\n",
    "    for data in game_data:\n",
    "        game_won, guesses = data\n",
    "        word, initial_state, difficulty, outcome = extract_info_from_filename(pkl_file)\n",
    "        \n",
    "        # Create a scenario dictionary for each data tuple\n",
    "        scenario = {\n",
    "            'word': word,\n",
    "            'difficulty': difficulty,\n",
    "            'outcome': outcome,\n",
    "            'data': (game_won, guesses)\n",
    "        }\n",
    "        file_scenarios.append((pkl_file, scenario))  # Add scenario to the list\n",
    "\n",
    "    return file_scenarios\n",
    "\n",
    "def extract_info_from_filename(pkl_file):\n",
    "    parts = pkl_file.stem.split('_from_')\n",
    "    word_and_state = parts[0].split('_')\n",
    "    word = '_'.join(word_and_state[:-1])\n",
    "    initial_state = word_and_state[-1]\n",
    "    difficulty, outcome = parts[1].split('_')[-2:]\n",
    "    return word, initial_state, difficulty, outcome\n",
    "\n",
    "# def print_scenarios(scenarios):\n",
    "#     # Assuming this function is defined elsewhere\n",
    "#     pass\n",
    "\n",
    "# Process all pickle files\n",
    "pkl_list = process_pkl_files(base_dataset_dir)\n",
    "\n",
    "# Accessing an individual pickle file's content by index\n",
    "index_to_access = 0  # Change this index to access different files\n",
    "if index_to_access < len(pkl_list):\n",
    "    file_path, scenario = pkl_list[index_to_access]\n",
    "    print(f\"Contents of {file_path}:\")\n",
    "    print_scenarios([scenario])  # Wrap scenario in a list for the function\n",
    "else:\n",
    "    print(f\"No pickle file at index {index_to_access}\")\n",
    "\n",
    "No pickle file at index 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_list = []\n",
    "\n",
    "# Iterate over all batch directories\n",
    "for batch_dir in sorted(base_dataset_dir.iterdir(), \\\n",
    "    key=lambda x: int(x.name) if x.name.isdigit() else float('inf')):\n",
    "    if batch_dir.is_dir():\n",
    "        # List all .pkl files in the current batch directory\n",
    "        pkl_files = list(batch_dir.glob(\"*.pkl\"))\n",
    "\n",
    "        for pkl_file in pkl_files:\n",
    "            with open(pkl_file, 'rb') as file:\n",
    "                game_data = pickle.load(file)\n",
    "                # Extract information from file name\n",
    "                parts = pkl_file.stem.split('_from_')\n",
    "                word_and_statet = parts[0].split('_')\n",
    "                word = '_'.join(word_and_state[:-1])\n",
    "                initial_state = word_and_state[-1]\n",
    "                difficulty, outcome = parts[1].split('_')[-2:]\n",
    "\n",
    "                # Assuming game_data is a list of tuples (game_won, guesses)\n",
    "                for data in game_data:\n",
    "                    game_won, guesses = data\n",
    "                    # Create a scenario dictionary for each data tuple\n",
    "                    scenario = {\n",
    "                        'word': word,\n",
    "                        'difficulty': difficulty,\n",
    "                        'outcome': outcome,\n",
    "                        'data': (game_won, guesses)\n",
    "                    }\n",
    "                    pkl_list.append((pkl_file, scenario))  # Add scenario to the list\n",
    "\n",
    "# Accessing an individual pickle file's content by index\n",
    "index_to_access = 0  # Change this index to access different files\n",
    "if index_to_access < len(pkl_list):\n",
    "    file_path, scenario = pkl_list[index_to_access]\n",
    "    print(f\"Contents of {file_path}:\")\n",
    "    print_scenarios([scenario])  # Wrap scenario in a list for the function\n",
    "else:\n",
    "    print(f\"No pickle file at index {index_to_access}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optiver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
